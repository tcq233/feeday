<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>feeday</title><link>https://feeday.cn</link><description>BB Work No Money</description><copyright>feeday</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://feeday.cn</link></image><lastBuildDate>Sun, 22 Feb 2026 03:41:15 +0000</lastBuildDate><managingEditor>feeday</managingEditor><ttl>60</ttl><webMaster>feeday</webMaster><item><title>åˆ é™¤é‡å¤å›¾åƒ</title><link>https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</link><description>åˆ é™¤é‡å¤å›¾åƒ-GPU
```
import os
import sys
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed

# ========== è‡ªåŠ¨å®‰è£…ä¾èµ–ï¼ˆé˜¿é‡Œæºï¼‰ ==========
def auto_install(pkg):
    try:
        __import__(pkg)
    except ImportError:
        print(f'ğŸ“¦ æœªå®‰è£… {pkg}ï¼Œæ­£åœ¨å®‰è£…ï¼ˆé˜¿é‡Œæºï¼‰...')
        subprocess.check_call([
            sys.executable, '-m', 'pip', 'install', pkg,
            '-i', 'https://mirrors.aliyun.com/pypi/simple'
        ])

auto_install('PIL')              # pillow
auto_install('imagehash')
auto_install('opencv-python')
auto_install('numpy')
auto_install('scikit-image')


import cv2
import numpy as np
from PIL import Image
import imagehash
from skimage.metrics import structural_similarity as ssim


# ============ é…ç½® ============
FOLDER = r'C:\Users\Puck\Desktop\xz\cp'
EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.webp'}

PHASH_THRESHOLD = 5     # phash æœ€å¤§å·®è·
DHASH_THRESHOLD = 5     # dhash æœ€å¤§å·®è·
SSIM_THRESHOLD = 0.95   # fast-ssim æœ€ç»ˆç¡®è®¤é˜ˆå€¼

THREADS = 8
# =============================


def load_image(path):
    '''è¯»å›¾ï¼ˆOpenCV æ ¼å¼ + Original Sizeï¼‰'''
    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR)
    return img


def fast_ssim(img1, img2):
    '''ç¼©å°åˆ° 64Ã—64ï¼Œå†è®¡ç®— SSIMï¼ˆé«˜é€Ÿ + ä¸è¯¯åˆ¤ï¼‰'''
    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    h = min(gray1.shape[0], gray2.shape[0])
    w = min(gray1.shape[1], gray2.shape[1])

    g1 = cv2.resize(gray1, (64, 64))
    g2 = cv2.resize(gray2, (64, 64))

    value, _ = ssim(g1, g2, full=True)
    return value


def calc_hashes(path):
    '''è®¡ç®— pHash + dHash'''
    try:
        img = Image.open(path).convert('RGB')
        ph = imagehash.phash(img)
        dh = imagehash.dhash(img)
        return (path, ph, dh)
    except:
        return (path, None, None)


def main():
    print('ğŸ“Œ æ‰«ææ–‡ä»¶ä¸­...')

    file_list = []
    for root, _, files in os.walk(FOLDER):
        for f in files:
            if os.path.splitext(f)[1].lower() in EXTS:
                file_list.append(os.path.join(root, f))

    print(f'ğŸ“¸ æ‰¾åˆ° {len(file_list)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹å¤šçº¿ç¨‹ hash...')

    # ========== å¤šçº¿ç¨‹ hash ==========
    hashes = []
    with ThreadPoolExecutor(max_workers=THREADS) as exe:
        futures = [exe.submit(calc_hashes, p) for p in file_list]
        for f in as_completed(futures):
            hashes.append(f.result())

    # ========== åŠ è½½ OpenCV å›¾åƒ &amp; åˆ†è¾¨ç‡ ==========
    print('ğŸ“· åŠ è½½å›¾åƒç”¨äº SSIM...')

    imgs = {}
    resolutions = {}

    for path, _, _ in hashes:
        img = load_image(path)
        if img is None:
            continue
        imgs[path] = img
        h, w = img.shape[:2]
        resolutions[path] = w * h

    print('ğŸš€ å¼€å§‹ä¸¥æ ¼å»é‡ï¼ˆä¸‰é‡åˆ¤å®šï¼Œä¸è¯¯åˆ ï¼‰...')

    delete = set()
    kept = []

    n = len(hashes)

    for i in range(n):
        p1, ph1, dh1 = hashes[i]
        if p1 in delete:
            continue

        kept.append(p1)

        for j in range(i + 1, n):
            p2, ph2, dh2 = hashes[j]
            if p2 in delete:
                continue

            # --- 1) pHash ç²—ç­› ---
            if ph1 - ph2 &gt; PHASH_THRESHOLD:
                continue

            # --- 2) dHash ç²—ç­› ---
            if dh1 - dh2 &gt; DHASH_THRESHOLD:
                continue

            # --- 3) fast SSIM æœ€ç»ˆç¡®è®¤ ---
            s = fast_ssim(imgs[p1], imgs[p2])

            if s &gt;= SSIM_THRESHOLD:
                # ä¿ç•™åˆ†è¾¨ç‡æœ€é«˜
                if resolutions[p2] &gt; resolutions[p1]:
                    print(f'ğŸ”„ æ›¿æ¢ä¿ç•™ â†’ {p2}ï¼ˆæ›´é«˜æ¸…ï¼‰')
                    delete.add(p1)
                    kept[-1] = p2
                    p1 = p2
                else:
                    print(f'ğŸ—‘ åˆ é™¤ï¼š{p2}ï¼ˆSSIM={s:.3f}ï¼‰')
                    delete.add(p2)

    print(f'\nğŸ—‘ åˆ é™¤ {len(delete)} å¼ é‡å¤å›¾ç‰‡...')

    # æœ€ç»ˆåˆ é™¤
    for p in delete:
        try:
            os.remove(p)
        except:
            pass

    print('âœ¨ å®Œæˆï¼')


if __name__ == '__main__':
    main()

```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</guid><pubDate>Mon, 24 Nov 2025 13:48:48 +0000</pubDate></item><item><title>é…ç½®æ–‡ä»¶</title><link>https://feeday.cn/post/pei-zhi-wen-jian.html</link><description>```
{
  'title': 'feeday',
  'subTitle': 'BB Work No Money',
  'homeUrl': 'https://feeday.cn/feeday',
  'avatarUrl': 'https://github.githubassets.com/favicons/favicon.svg',
  'bottomText': 'â¤ï¸ è½¬è½½æ–‡ç« è¯·æ³¨æ˜å‡ºå¤„ï¼Œè°¢è°¢ï¼â¤ï¸',
  'script': '&lt;script src='/gmeek/GmeekTOC.js'&gt;&lt;/script&gt;',
  'allHead': '&lt;script src='/gmeek/GmeekVercount.js'&gt;&lt;/script&gt;',
  'head': '&lt;script async src=\'https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1964437526797765\' crossorigin=\'anonymous\'&gt;&lt;/script&gt;\n&lt;!-- blog119 --&gt;\n&lt;ins class=\'adsbygoogle\' style=\'display:inline-block;width:728px;height:90px\' data-ad-client=\'ca-pub-1964437526797765\' data-ad-slot=\'6408697538\'&gt;&lt;/ins&gt;\n&lt;script&gt;\n     (adsbygoogle = window.adsbygoogle || []).push({});\n&lt;/script&gt;',
  'iconList': {
    'add': 'M8 1C8.4 1 8.7 1.3 8.7 1.7V7.3H14.3C14.7 7.3 15 7.6 15 8C15 8.4 14.7 8.7 14.3 8.7H8.7V14.3C8.7 14.7 8.4 15 8 15C7.6 15 7.3 14.7 7.3 14.3V8.7H1.7C1.3 8.7 1 8.4 1 8C1 7.6 1.3 7.3 1.7 7.3H7.3V1.7C7.3 1.3 7.6 1 8 1Z'
  },
  'exlink': {
    'add': 'https://github.com/tcq233/feeday/issues/new'
  },

  'GMEEK_VERSION': 'last'
}
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/pei-zhi-wen-jian.html</guid><pubDate>Sat, 22 Nov 2025 19:10:41 +0000</pubDate></item><item><title>windows-å¼€å§‹èœå•ç›®å½•</title><link>https://feeday.cn/post/windows--kai-shi-cai-dan-mu-lu.html</link><description>åˆ é™¤å¼€å§‹èœå•åº”ç”¨åˆ—è¡¨ï¼Œæ‰¾å¯¹åº”æ–‡ä»¶å¤¹åˆ é™¤ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/windows--kai-shi-cai-dan-mu-lu.html</guid><pubDate>Sat, 15 Nov 2025 07:21:39 +0000</pubDate></item><item><title>imguré•œåƒç«™æµ‹è¯•</title><link>https://feeday.cn/post/imgur-jing-xiang-zhan-ce-shi.html</link><description>
æ£€æŸ¥ imgur å›¾ç‰‡åœ¨å¤šä¸ªé•œåƒç«™æ˜¯å¦å¯ç”¨

- https://shiquda.link/load-imgur-images/
```
import requests
import time

# æµ‹è¯•è¶…æ—¶ï¼ˆç§’ï¼‰
TIMEOUT = 10

# æµ‹è¯•çš„é•œåƒç«™æ¨¡å¼
MIRRORS = {
    'StackImgur':      'https://i.stack.imgur.com/{id}',
    'ImgurPics':       'https://imgur.pics/{id}',
    'ImgVue':          'https://imgvue.com/images/{id}',
    'RisuAI':          'https://risuai.com/imgur/{id}',  # å¤‡é€‰
}

def check_url(url):
    '''HEAD æ–¹å¼æ£€æŸ¥ URL æ˜¯å¦å¯è®¿é—®'''
    try:
        r = requests.head(url, timeout=TIMEOUT)
        return r.status_code in (200, 301, 302)
    except:
        return False


def test_imgur_id(img_id, ext='jpg'):
    '''æ£€æµ‹å•ä¸ª imgur ID çš„å¯ç”¨é•œåƒ'''
    print(f'\n===== æµ‹è¯• ID: {img_id} =====')

    results = {}

    # æ‹¼æ¥æ–‡ä»¶å
    full = f'{img_id}.{ext}'

    for name, pattern in MIRRORS.items():
        url = pattern.format(id=full)

        ok = check_url(url)
        results[name] = ok

        status = 'âœ” å¯ç”¨' if ok else 'âœ˜ ä¸å¯ç”¨'
        print(f'{name:12s} â†’ {status}  ({url})')

        time.sleep(0.2)

    return results


if __name__ == '__main__':
    # ç¤ºä¾‹ IDï¼Œå¯æ¢æˆçœŸå® ID
    test_list = [
        'qHxM2',  # ä½ æä¾›çš„
        '9xndJ',
        'ciycE',
        'AFFHn',
    ]

    for img_id in test_list:
        test_imgur_id(img_id)
```

## æ•°æ®é›†ä¸‹è½½æµ‹è¯•
```
# -*- coding: utf-8 -*-
'''
é€è¡Œä¸‹è½½ ORIGINAL å’Œ PS å›¾ç‰‡ï¼Œå¹¶æŒ‰æŒ‡å®šæ ¼å¼é‡å‘½åï¼š
Original: {id}_{imgurID}_original.ext
PS:       {originalID}_{id_variant}_{imgurID}_ps.ext
'''

import os
import csv
import requests
import time

# ===== ä»£ç†åŸŸå =====
PROXY_DOMAIN = 'https://img.noobzone.ru/getimg.php?url='

def proxy_url(url):
    return f'{PROXY_DOMAIN}{url}'

# ===== è¾“å…¥æ–‡ä»¶è·¯å¾„ =====
ORIGINAL_TSV = '/home/data/originals.tsv'
PS_TSV = '/home/data/photoshops.tsv'

# ===== è¾“å‡ºç›®å½• =====
SAVE_ROOT = '/home/data/output'
ORIG_DIR = os.path.join(SAVE_ROOT, 'original')
PS_DIR = os.path.join(SAVE_ROOT, 'photoshop')
FAILED_LOG = os.path.join(SAVE_ROOT, 'failed.txt')

os.makedirs(ORIG_DIR, exist_ok=True)
os.makedirs(PS_DIR, exist_ok=True)

def extract_imgur_id(url: str):
    '''ä» imgur é“¾æ¥æå–å›¾ç‰‡ ID'''
    return url.split('/')[-1].split('.')[0]


def download(line_no, url, save_path, retry=3):
    '''ä¸‹è½½å‡½æ•°ï¼ˆå¸¦ä»£ç† + æ‰“å°è¡Œå·ï¼‰'''
    for attempt in range(1, retry + 1):
        try:
            purl = proxy_url(url)
            print(f'\n==== è¡Œ {line_no} (å°è¯• {attempt}/{retry}) ====')
            print(f'åŸå§‹ URL: {url}')
            print(f'ä»£ç† URL: {purl}')

            r = requests.get(purl, timeout=20, stream=True)
            print(f'çŠ¶æ€ç : {r.status_code}')

            if r.status_code == 200:
                with open(save_path, 'wb') as f:
                    for chunk in r.iter_content(8192):
                        f.write(chunk)
                print(f'âœ” æˆåŠŸ â†’ {save_path}')
                return True
            else:
                print(f'âŒ é”™è¯¯çŠ¶æ€ç  {r.status_code}')
                err = f'{url}\tstatus {r.status_code}\n'

        except Exception as e:
            print(f'ğŸ’¥ å‡ºé”™: {e}')
            err = f'{url}\terror {e}\n'

        time.sleep(1)

    with open(FAILED_LOG, 'a', encoding='utf-8') as f:
        f.write(err)

    print('âŒ ä¸‰æ¬¡å°è¯•å¤±è´¥ï¼')
    return False


# ========== é€è¡Œäº¤æ›¿å¤„ç† ==========

def read_tsv(path):
    data = []
    with open(path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f, delimiter='\t')
        for row in reader:
            data.append(row)
    return data


print('ğŸ“„ æ­£åœ¨è¯»å– TSVâ€¦')
orig_rows = read_tsv(ORIGINAL_TSV)
ps_rows = read_tsv(PS_TSV)

max_len = max(len(orig_rows), len(ps_rows))

print(f'åŸå›¾ {len(orig_rows)} è¡Œï¼ŒPS {len(ps_rows)} è¡Œ')
print('\nğŸš€ å¼€å§‹é€è¡Œä¸‹è½½â€¦')

for i in range(max_len):
    line_no = i + 1

    # ===== ORIGINAL =====
    if i &lt; len(orig_rows):
        row = orig_rows[i]
        id_or = row.get('id')
        url_or = row.get('url')
        ext_or = (row.get('end') or 'jpg').lstrip('.')

        imgurID_or = extract_imgur_id(url_or)

        filename_or = f'{id_or}_{imgurID_or}_original.{ext_or}'
        save_or = os.path.join(ORIG_DIR, filename_or)

        download(line_no, url_or, save_or)

    # ===== PS =====
    if i &lt; len(ps_rows):
        row = ps_rows[i]
        id_variant = row.get('id_variant') or row.get('id')
        id_original = row.get('original')
        url_ps = row.get('url')
        ext_ps = (row.get('end') or 'jpg').lstrip('.')

        imgurID_ps = extract_imgur_id(url_ps)

        # å‘½åæ ¼å¼ï¼š
        # 10092l_c69axf4_0_xIJ4z_ps.png
        filename_ps = f'{id_original}_{id_variant}_{imgurID_ps}_ps.{ext_ps}'
        save_ps = os.path.join(PS_DIR, filename_ps)

        download(line_no, url_ps, save_ps)

print('\nğŸ‰ å®Œæˆï¼')
print(f'ğŸ“ è¾“å‡ºç›®å½•: {SAVE_ROOT}')
print(f'ğŸ“ å¤±è´¥æ—¥å¿—: {FAILED_LOG}')
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/imgur-jing-xiang-zhan-ce-shi.html</guid><pubDate>Sat, 15 Nov 2025 06:20:28 +0000</pubDate></item><item><title>Jupyter</title><link>https://feeday.cn/post/Jupyter.html</link><description>åœ¨ VS Code ä¸­å®‰è£…å’Œä½¿ç”¨ ipynbï¼ˆJupyter Notebookï¼‰ å¾ˆç®€å•ï¼Œåªéœ€è¦å®‰è£…ä¸¤ä¸ªå®˜æ–¹æ‰©å±•å³å¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Jupyter.html</guid><pubDate>Sat, 15 Nov 2025 05:30:12 +0000</pubDate></item><item><title>Pico-Banana-400K</title><link>https://feeday.cn/post/Pico-Banana-400K.html</link><description>è‹¹æœå‘å¸ƒçš„é¦™è•‰å›¾åƒç¼–è¾‘æ•°æ®é›†
- [https://github.com/apple/pico-banana-400k](https://github.com/apple/pico-banana-400k)

é€è¡Œè¯»å– JSONL æ–‡ä»¶ï¼Œä¸‹è½½ open_image å’Œ output_imageã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Pico-Banana-400K.html</guid><pubDate>Sun, 09 Nov 2025 15:11:10 +0000</pubDate></item><item><title>é¼ æ ‡è‡ªåŠ¨ä¸Šæ»‘è„šæœ¬</title><link>https://feeday.cn/post/shu-biao-zi-dong-shang-hua-jiao-ben.html</link><description>
åŠŸèƒ½ï¼š1. å®æ—¶æ˜¾ç¤ºé¼ æ ‡åæ ‡
2. æŒ‰ Enter é”å®šåæ ‡å¹¶å¼€å§‹å¾ªç¯æ‰§è¡Œï¼š
 â†’ ç§»åŠ¨åˆ°åæ ‡ â†’ æŒ‰ä½å·¦é”® â†’ å…‰æ ‡ä¸Šç§»30åƒç´  + æ»šè½®ä¸Šæ»‘10æ¬¡ â†’ æ¾å¼€å·¦é”®
3. æŒ‰ Esc éšæ—¶åœæ­¢é€€å‡º


```
import time
import sys
import subprocess

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
required_packages = ['pyautogui', 'pynput']
for pkg in required_packages:
    try:
        __import__(pkg)
    except ImportError:
        print(f'ğŸ“¦ æœªæ‰¾åˆ° {pkg}ï¼Œæ­£åœ¨å®‰è£…...')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-i', 'https://pypi.tuna.tsinghua.edu.cn/simple'])

import pyautogui
from pynput import keyboard
from pynput.mouse import Controller as MouseController, Button

# ===== é…ç½®å‚æ•° =====
SCROLL_TIMES = 10       # æ»šè½®ä¸Šæ»‘æ¬¡æ•°
SCROLL_STEP = -1        # æ¯æ¬¡æ»šè½®æ»šåŠ¨å¹…åº¦ï¼ˆè´Ÿæ•° = å†…å®¹å¾€ä¸Šï¼‰
DRAG_OFFSET = 80        # é¼ æ ‡æŒ‰ä½åä¸Šç§»çš„åƒç´ 
INTERVAL = 0.1          # æ¯è½®å¾ªç¯é—´éš”æ—¶é—´
MOVE_DURATION = 0.1     # é¼ æ ‡ç§»åŠ¨åŠ¨ç”»æ—¶é•¿

mouse = MouseController()
running = False
stop_flag = False


# ===== é”®ç›˜ç›‘å¬ =====
def on_press(key):
    global running, stop_flag
    try:
        if key == keyboard.Key.enter:
            if not running:
                print('\nğŸš€ å¼€å§‹æ‰§è¡Œå¾ªç¯ï¼ˆæŒ‰ Esc åœæ­¢ï¼‰')
                running = True
            else:
                print('âš™ å·²åœ¨è¿è¡Œä¸­')
        elif key == keyboard.Key.esc:
            print('\nâ¹ æ£€æµ‹åˆ° Escï¼Œå‡†å¤‡é€€å‡º...')
            stop_flag = True
            return False
    except Exception:
        pass


# ===== å®æ—¶æ˜¾ç¤ºé¼ æ ‡åæ ‡ =====
def show_mouse_position():
    print('ğŸ“ å®æ—¶åæ ‡æ˜¾ç¤ºä¸­...ï¼ˆæŒ‰ Enter é”å®šåæ ‡å¹¶å¼€å§‹ï¼ŒEsc é€€å‡ºï¼‰')
    while not running and not stop_flag:
        x, y = pyautogui.position()
        print(f'\rğŸ–±ï¸ å½“å‰åæ ‡: ({x}, {y})', end='', flush=True)
        time.sleep(0.1)


# ===== ä¸»æ‰§è¡Œé€»è¾‘ =====
def perform_loop(x, y):
    global stop_flag
    i = 0
    while not stop_flag:
        i += 1

        # ç§»åŠ¨åˆ°æŒ‡å®šåæ ‡
        pyautogui.moveTo(x, y, duration=MOVE_DURATION)
        time.sleep(0.05)

        # æŒ‰ä½å·¦é”®
        mouse.press(Button.left)
        time.sleep(0.05)

        # å…‰æ ‡ä¸Šç§»æŒ‡å®šåƒç´ ï¼ˆæ¨¡æ‹Ÿæ‹–æ‹½ï¼‰
        pyautogui.moveTo(x, y - DRAG_OFFSET, duration=0.15)

        # åŒæ—¶æ»šè½®ä¸Šæ»‘è‹¥å¹²æ¬¡
        for _ in range(SCROLL_TIMES):
            mouse.scroll(0, SCROLL_STEP)
            time.sleep(0.05)

        # æ¾å¼€å·¦é”®
        mouse.release(Button.left)

        print(f'\râœ… ç¬¬ {i} æ¬¡æ‹–æ‹½+ä¸Šæ»‘å®Œæˆ ({x},{y-DRAG_OFFSET})', end='', flush=True)
        time.sleep(INTERVAL)


# ===== ä¸»ç¨‹åºå…¥å£ =====
if __name__ == '__main__':
    listener = keyboard.Listener(on_press=on_press)
    listener.start()

    show_mouse_position()

    if stop_flag:
        print('\nğŸ‘‹ å·²é€€å‡ºã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shu-biao-zi-dong-shang-hua-jiao-ben.html</guid><pubDate>Sun, 09 Nov 2025 13:01:33 +0000</pubDate></item><item><title>GIthubåŒæ­¥é¡¹ç›®åˆ°æœåŠ¡å™¨è„šæœ¬</title><link>https://feeday.cn/post/GIthub-tong-bu-xiang-mu-dao-fu-wu-qi-jiao-ben.html</link><description>åŒæ­¥ä»£ç é¡¹ç›®è„šæœ¬
```
#!/bin/bash
# ==========================================
# auto_git_update.sh
# æ¯å¤©è‡ªåŠ¨æ›´æ–°å¤šä¸ª Git ä»“åº“åˆ°æŒ‡å®šç›®å½•
# ä½œè€…: ChatGPT
# ==========================================

# ===== åŸºæœ¬é…ç½® =====
BASE_DIR='/home/git'          # æ‰€æœ‰ä»“åº“å­˜æ”¾çš„ç›®å½•
LOG_FILE='/home/git_update.log'

# ===== ä»“åº“åˆ—è¡¨ï¼ˆå¯æ·»åŠ å¤šä¸ªï¼‰ =====
GIT_URLS=(
  'https://github.com/tcq20256/feeday.git'
  'https://github.com/tcq20256/tcq20256.github.io.git'
)

# ===== å‡½æ•°ï¼šæ›´æ–°æˆ–å…‹éš†ä»“åº“ =====
update_repo() {
  local GIT_URL='$1'
  local REPO_NAME=$(basename '$GIT_URL' .git)
  local REPO_DIR='${BASE_DIR}/${REPO_NAME}'

  echo '----------------------------------------' | tee -a '$LOG_FILE'
  echo 'ğŸ•’ $(date '+%F %T') å¼€å§‹å¤„ç†ä»“åº“ï¼š$REPO_NAME' | tee -a '$LOG_FILE'

  # ç¡®ä¿ç›®å½•å­˜åœ¨
  mkdir -p '$BASE_DIR'

  # å…‹éš†æˆ–æ›´æ–°
  if [ ! -d '$REPO_DIR/.git' ]; then
    echo 'ğŸ“¦ ç¬¬ä¸€æ¬¡ clone ä»“åº“ï¼š$GIT_URL' | tee -a '$LOG_FILE'
    git clone '$GIT_URL' '$REPO_DIR' &gt;&gt; '$LOG_FILE' 2&gt;&amp;1
  else
    echo 'ğŸ”„ æ›´æ–°ä»“åº“ï¼š$REPO_NAME' | tee -a '$LOG_FILE'
    cd '$REPO_DIR' || { echo 'âŒ æ— æ³•è¿›å…¥ç›®å½•ï¼š$REPO_DIR' | tee -a '$LOG_FILE'; return; }
    git reset --hard HEAD &gt;&gt; '$LOG_FILE' 2&gt;&amp;1
    git pull &gt;&gt; '$LOG_FILE' 2&gt;&amp;1
  fi

  if [ $? -eq 0 ]; then
    echo 'âœ… å®Œæˆæ›´æ–°ï¼š$REPO_NAME' | tee -a '$LOG_FILE'
  else
    echo 'âš ï¸ æ›´æ–°å¤±è´¥ï¼š$REPO_NAME' | tee -a '$LOG_FILE'
  fi
}

# ===== ä¸»é€»è¾‘ï¼šå¾ªç¯å¤„ç†æ¯ä¸ªä»“åº“ =====
echo '========================================' | tee -a '$LOG_FILE'
echo 'ğŸš€ å¯åŠ¨è‡ªåŠ¨ Git æ›´æ–°ä»»åŠ¡ $(date '+%F %T')' | tee -a '$LOG_FILE'

for url in '${GIT_URLS[@]}'; do
  update_repo '$url'
done

echo 'âœ… æ‰€æœ‰ä»“åº“å¤„ç†å®Œæ¯• $(date '+%F %T')' | tee -a '$LOG_FILE'
echo '========================================' | tee -a '$LOG_FILE'
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GIthub-tong-bu-xiang-mu-dao-fu-wu-qi-jiao-ben.html</guid><pubDate>Sun, 09 Nov 2025 07:19:50 +0000</pubDate></item><item><title>install_centos7.6_conda.sh</title><link>https://feeday.cn/post/install_centos7.6_conda.sh.html</link><description>Centos7.6è€ç‰ˆæœ¬å®‰è£…conda

## å®‰è£…è„šæœ¬
```
#!/bin/bash
# ==========================================
# install_conda_centos7.sh
# é€‚ç”¨äº CentOS 7 çš„ Miniconda è‡ªåŠ¨å®‰è£…è„šæœ¬ï¼ˆå…¼å®¹ glibc 2.17ï¼‰
# ä½œè€…: ChatGPT
# ==========================================

set -e

INSTALL_DIR='/root/miniconda3'
CONDA_SCRIPT='Miniconda3-py38_23.3.1-0-Linux-x86_64.sh'
DOWNLOAD_URL='https://repo.anaconda.com/miniconda/${CONDA_SCRIPT}'

echo 'ğŸ§ æ£€æµ‹ç³»ç»Ÿç‰ˆæœ¬...'
if grep -q 'release 7' /etc/centos-release 2&gt;/dev/null; then
    echo 'âœ… æ£€æµ‹åˆ° CentOS 7ï¼Œä½¿ç”¨å…¼å®¹ç‰ˆ Miniconda (Python 3.8)'
else
    echo 'âš ï¸ æœªæ£€æµ‹åˆ° CentOS 7ï¼Œå°†ä½¿ç”¨æœ€æ–°ç‰ˆ Miniconda å®‰è£…åŒ…'
    CONDA_SCRIPT='Miniconda3-latest-Linux-x86_64.sh'
    DOWNLOAD_URL='https://repo.anaconda.com/miniconda/${CONDA_SCRIPT}'
fi

echo 'ğŸ æ£€æŸ¥ Conda æ˜¯å¦å·²å®‰è£…...'
if command -v conda &gt;/dev/null 2&gt;&amp;1; then
    echo 'âœ… Conda å·²å®‰è£…ï¼Œç‰ˆæœ¬ï¼š$(conda -V)'
    exit 0
fi

echo 'ğŸŒ æ­£åœ¨ä¸‹è½½ Miniconda å®‰è£…è„šæœ¬...'
cd /opt
curl -LO '$DOWNLOAD_URL'

echo 'ğŸ“¦ å®‰è£… Miniconda åˆ°: $INSTALL_DIR ...'
bash '$CONDA_SCRIPT' -b -p '$INSTALL_DIR'

# æ¿€æ´» conda
source '$INSTALL_DIR/bin/activate'

# é…ç½®ç¯å¢ƒå˜é‡
if ! grep -q 'miniconda3/bin/activate' ~/.bashrc; then
    echo 'source $INSTALL_DIR/bin/activate' &gt;&gt; ~/.bashrc
    echo 'âœ… å·²å°† Conda è‡ªåŠ¨åŠ è½½é…ç½®å†™å…¥ ~/.bashrc'
fi

# è®¾ç½®æ¸…åé•œåƒæº
echo 'ğŸ§­ é…ç½® TUNA æ¸…åé•œåƒæº...'
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
conda config --set show_channel_urls yes

# éªŒè¯å®‰è£…
echo 'ğŸ” éªŒè¯ Conda å®‰è£…...'
conda -V
python -V

echo 'ğŸ‰ å®‰è£…å®Œæˆï¼è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ¿€æ´»ç¯å¢ƒï¼š'
echo 'ğŸ‘‰ source ~/.bashrc'
echo 'ğŸ‘‰ conda create -n py310 python=3.10 -y'
echo 'ğŸ‘‰ conda activate py310'
echo 'source /root/miniconda3/bin/activate'
```

## åˆ›å»ºæ¿€æ´»ç¯å¢ƒ
```
source /root/miniconda3/bin/activate
conda create -n py310 python=3.10 -y
conda activate py310
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/install_centos7.6_conda.sh.html</guid><pubDate>Sun, 09 Nov 2025 06:32:05 +0000</pubDate></item><item><title>è§†é¢‘å¢åŠ åˆ°10ç§’</title><link>https://feeday.cn/post/shi-pin-zeng-jia-dao-10-miao.html</link><description>é€’å½’æ‰«æ D:\test\è§†é¢‘ ï¼Œå°†ä¸è¶³10ç§’çš„è§†é¢‘å¤åˆ¶æ‹¼æ¥åˆ°è¶…è¿‡10ç§’
ç”Ÿæˆåç›´æ¥è¦†ç›–åŸè§†é¢‘ï¼Œæ–‡ä»¶åä¸å˜ï¼ˆåŸæ–‡ä»¶è‡ªåŠ¨å¤‡ä»½ä¸º .bakï¼‰

```
import os
import sys
import math
import shutil
import subprocess

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
required_packages = ['moviepy', 'tqdm']
for pkg in required_packages:
    try:
        __import__(pkg.split('-')[0])
    except ImportError:
        print(f'ğŸ“¦ æœªæ‰¾åˆ° {pkg}ï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...')
        subprocess.check_call([
            sys.executable, '-m', 'pip', 'install', pkg, '-i', 'https://pypi.tuna.tsinghua.edu.cn/simple'
        ])

# ===== æ­£å¼é€»è¾‘ =====
from moviepy.editor import VideoFileClip, concatenate_videoclips
from tqdm import tqdm

# å›ºå®šæ‰«æç›®å½•
ROOT_DIR = r'D:\test'
MIN_DURATION = 10  # ç§’
EXTS = ('.mp4', '.mov', '.mkv', '.avi', '.flv', '.webm')


def extend_and_replace(video_path, min_duration=10):
    '''
    å¦‚æœè§†é¢‘æ—¶é•¿å°äº min_durationï¼Œåˆ™æ‹¼æ¥å¤šæ¬¡å¹¶æ›¿æ¢åŸæ–‡ä»¶ï¼ˆå¤‡ä»½åŸå§‹ï¼‰
    '''
    try:
        clip = VideoFileClip(video_path)
        duration = clip.duration
        if duration &gt;= min_duration:
            clip.close()
            return False  # ä¸å¤„ç†

        # è®¡ç®—å€æ•°
        times = math.ceil(min_duration / duration)
        new_clip = concatenate_videoclips([clip] * times)

        # å¤‡ä»½åŸæ–‡ä»¶
        bak_path = video_path + '.bak'
        if not os.path.exists(bak_path):
            shutil.copy2(video_path, bak_path)

        temp_out = video_path + '.temp.mp4'
        print(f'ğŸ¬ {os.path.basename(video_path)} ä»… {duration:.2f}s â†’ å¤åˆ¶ {times} æ¬¡ â†’ æ›¿æ¢åŸæ–‡ä»¶')

        new_clip.write_videofile(temp_out, codec='libx264', audio_codec='aac', verbose=False, logger=None)
        clip.close()
        new_clip.close()

        # æ›¿æ¢åŸè§†é¢‘
        os.remove(video_path)
        os.rename(temp_out, video_path)
        return True

    except Exception as e:
        print(f'âš  æ— æ³•å¤„ç† {video_path}: {e}')
        return False


def process_folder(root_dir, min_duration=10, exts=EXTS):
    '''
    éå†æ–‡ä»¶å¤¹ï¼Œå¤„ç†æ‰€æœ‰è§†é¢‘
    '''
    video_list = []
    for root, _, files in os.walk(root_dir):
        for f in files:
            if f.lower().endswith(exts):
                video_list.append(os.path.join(root, f))

    print(f'ğŸ å…±æ£€æµ‹åˆ° {len(video_list)} ä¸ªè§†é¢‘æ–‡ä»¶\n')
    processed = 0

    for path in tqdm(video_list, desc='å¤„ç†ä¸­'):
        if extend_and_replace(path, min_duration=min_duration):
            processed += 1

    print(f'\nâœ… å·²å¤„ç† {processed} ä¸ªçŸ­è§†é¢‘ï¼ˆè‡ªåŠ¨è¦†ç›–åŸæ–‡ä»¶ï¼ŒåŸå§‹æ–‡ä»¶å·²å¤‡ä»½ä¸º .bakï¼‰')


def main():
    if not os.path.isdir(ROOT_DIR):
        print(f'âŒ ç›®å½•ä¸å­˜åœ¨: {ROOT_DIR}')
        return

    process_folder(ROOT_DIR, min_duration=MIN_DURATION)
    print('\nğŸ“ å¤„ç†å®Œæˆã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-zeng-jia-dao-10-miao.html</guid><pubDate>Tue, 04 Nov 2025 12:19:08 +0000</pubDate></item><item><title>å¾®è½¯æœ¬åœ°æ–‡æœ¬ç”ŸæˆéŸ³é¢‘</title><link>https://feeday.cn/post/wei-ruan-ben-di-wen-ben-sheng-cheng-yin-pin.html</link><description>æŠŠæŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰txtæ–‡ä»¶ï¼Œç”¨Windowsç³»ç»Ÿè‡ªå¸¦è¯­éŸ³å¼•æ“(SAPI)è½¬æ¢ä¸ºwavéŸ³é¢‘ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wei-ruan-ben-di-wen-ben-sheng-cheng-yin-pin.html</guid><pubDate>Tue, 04 Nov 2025 12:17:29 +0000</pubDate></item><item><title>æ§åˆ¶å°ç­›é€‰é“¾æ¥</title><link>https://feeday.cn/post/kong-zhi-tai-shai-xuan-lian-jie.html</link><description>```
const links = document.getElementsByTagName('a');
// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é…çš„ç½‘å€
for (const link of links) {
  const href = link.href;
  // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç±»ä¼¼çš„ç½‘å€
  const urlRegex = /https:\/\/www\.bilibili\.com\/video\/[A-Za-z0-9]+\/?/;
  if (urlRegex.test(href)) {
    console.log('åŒ¹é…åˆ°çš„ç½‘å€: ' + href);
  }
}
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/kong-zhi-tai-shai-xuan-lian-jie.html</guid><pubDate>Sun, 02 Nov 2025 09:51:07 +0000</pubDate></item><item><title>ç»Ÿè®¡ç›®å½•æ–‡ä»¶ä¿¡æ¯</title><link>https://feeday.cn/post/tong-ji-mu-lu-wen-jian-xin-xi.html</link><description>éå† ROOT ç›®å½•ï¼Œå¯¼å‡ºå¸¦åª’ä½“å±æ€§ï¼ˆæ—¶é•¿/åˆ†è¾¨ç‡ï¼‰çš„æ¸…å•åˆ° CSVï¼ˆUTF-8ï¼‰ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tong-ji-mu-lu-wen-jian-xin-xi.html</guid><pubDate>Sun, 02 Nov 2025 09:48:45 +0000</pubDate></item><item><title>md5å‘½åæ–‡ä»¶</title><link>https://feeday.cn/post/md5-ming-ming-wen-jian.html</link><description>ä»¥æ–‡ä»¶ MD5 ä½œä¸ºæ–‡ä»¶åï¼ˆä¿ç•™æ‰©å±•åï¼‰ï¼Œé€’å½’å¤„ç†å­æ–‡ä»¶å¤¹ï¼Œ
å¹¶ç”Ÿæˆä¸€ä¸ª md5_rename_map.csv è®°å½•åŸå§‹æ–‡ä»¶åä¸æ”¹åæ–‡ä»¶ååŠMD5ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/md5-ming-ming-wen-jian.html</guid><pubDate>Sun, 02 Nov 2025 09:47:13 +0000</pubDate></item><item><title>åˆ é™¤DBæ–‡ä»¶</title><link>https://feeday.cn/post/shan-chu-DB-wen-jian.html</link><description>é€’å½’åˆ é™¤æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰ .db æ–‡ä»¶ï¼Œå¹¶ç”Ÿæˆæ—¥å¿—ï¼ˆUTF-8ï¼‰ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-DB-wen-jian.html</guid><pubDate>Sun, 02 Nov 2025 09:45:50 +0000</pubDate></item><item><title>æŒ‰æ–‡æœ¬åŒ¹é…ç§»åŠ¨æ–‡ä»¶</title><link>https://feeday.cn/post/an-wen-ben-pi-pei-yi-dong-wen-jian.html</link><description>æŒ‰ç…§æ–‡æœ¬æ¯è¡ŒåŒ¹é…æ–‡ä»¶å¤åˆ¶åˆ°æŒ‡å®šä½ç½®

## ğŸ§© åŠŸèƒ½ç®€ä»‹

ä»æŒ‡å®šçš„ TXT æ–‡ä»¶ï¼ˆ`txt_file`ï¼‰ä¸­è¯»å–è‹¥å¹²å…³é”®å­—ï¼ˆå»é‡å¹¶æŒ‰å­—å…¸åºæ’åºï¼‰ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/an-wen-ben-pi-pei-yi-dong-wen-jian.html</guid><pubDate>Sun, 02 Nov 2025 09:41:26 +0000</pubDate></item><item><title>é€šç”¨åª’ä½“é“¾æ¥æŸ¥çœ‹å™¨</title><link>https://feeday.cn/post/tong-yong-mei-ti-lian-jie-cha-kan-qi.html</link><description>è¾“å…¥å›¾åƒè§†é¢‘é“¾æ¥æŸ¥çœ‹é¢„è§ˆ
```
&lt;!doctype html&gt;
&lt;html lang='zh-CN'&gt;
&lt;head&gt;
  &lt;meta charset='utf-8' /&gt;
  &lt;meta name='viewport' content='width=device-width, initial-scale=1' /&gt;
  &lt;title&gt;é€šç”¨åª’ä½“æå–å™¨ï¼šå›¾ç‰‡ + è§†é¢‘ + BBCode æ”¯æŒ&lt;/title&gt;
  &lt;style&gt;
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.5;margin:0;padding:24px;background:#0b0c0f;color:#e6e6e6;scroll-behavior:smooth}
    h1{font-size:20px;margin:0 0 12px}
    textarea{width:100%;min-height:160px;padding:12px;border-radius:12px;border:1px solid #2b2f36;background:#12141a;color:#e6e6e6;resize:vertical;margin-bottom:12px}
    button{background:#3b82f6;border:none;color:white;padding:10px 14px;border-radius:10px;cursor:pointer;font-weight:600;margin-right:8px}
    button.secondary{background:#2b2f36;color:#d0d0d0}
    .tip{font-size:12px;color:#9aa0a6;margin:8px 0 16px}
    .grid{display:flex;flex-wrap:wrap;gap:12px}
    figure{margin:0;background:#12141a;border:1px solid #2b2f36;border-radius:14px;overflow:hidden;display:flex;flex-direction:column;align-items:center;justify-content:center;padding:8px;max-width:400px}
    figure&gt;img,figure&gt;video{max-width:100%;height:auto;object-fit:contain;background:#0b0c0f;cursor:pointer;border-radius:10px}
    figcaption{font-size:12px;padding:6px 4px;color:#9aa0a6;word-break:break-all}
    .err{color:#ff8a8a}
    #topBtn{position:fixed;bottom:24px;right:24px;background:#3b82f6;color:white;border:none;border-radius:50%;width:48px;height:48px;font-size:20px;cursor:pointer;display:none;box-shadow:0 4px 10px rgba(0,0,0,0.3)}
    #topBtn:hover{background:#2563eb}
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;h1&gt;é€šç”¨åª’ä½“æå–å™¨ï¼ˆæ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€BBCodeï¼‰&lt;/h1&gt;

  &lt;textarea id='urls' placeholder='å¯ç²˜è´´ä»»æ„æ–‡å­—ï¼Œè‡ªåŠ¨æå–å›¾ç‰‡/è§†é¢‘é“¾æ¥ï¼Œå¦‚ï¼š\n#3 http://x.cn/a.jpg http://x.cn/b.png [img]http://x.cn/c.webp[/img] [url=\'http://x.cn/d.jpg\']http://x.cn/e.jpg[/url]\nhttp://x.cn/f.mp4'&gt;&lt;/textarea&gt;

  &lt;button id='render'&gt;æ˜¾ç¤ºåª’ä½“&lt;/button&gt;
  &lt;button id='clear' class='secondary'&gt;æ¸…ç©º&lt;/button&gt;

  &lt;div class='tip'&gt;è‡ªåŠ¨è¯†åˆ«å¸¸è§å›¾ç‰‡æ ¼å¼ï¼ˆ.jpg/.jpeg/.png/.gif/.webp/.svg/.avif/.tiff/.bmpï¼‰åŠè§†é¢‘æ ¼å¼ï¼ˆ.mp4/.webm/.movï¼‰ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tong-yong-mei-ti-lian-jie-cha-kan-qi.html</guid><pubDate>Sat, 01 Nov 2025 16:49:29 +0000</pubDate></item><item><title>CentOS-WSL</title><link>https://feeday.cn/post/CentOS-WSL.html</link><description># CentOS WSL

[CentOS](https://www.centos.org/) QCOW2 cloud images converted to RootFS for [WSL](https://docs.microsoft.com/en-us/windows/wsl/).

## Current releases:
 - [CentOS 9-stream](https://github.com/mishamosher/CentOS-WSL/releases/tag/9-stream-20230626)
 - [CentOS 8-stream](https://github.com/mishamosher/CentOS-WSL/releases/tag/8-stream-20230626)
 - [CentOS 8](https://github.com/mishamosher/CentOS-WSL/releases/tag/8.4-2105)
 - [CentOS 7](https://github.com/mishamosher/CentOS-WSL/releases/tag/7.9-2211)
 - [CentOS 6](https://github.com/mishamosher/CentOS-WSL/releases/tag/6.10-1907)

# å¸¸ç”¨å‘½ä»¤

åœ¨ PowerShell æˆ– CMDï¼ˆç®¡ç†å‘˜æƒé™ï¼‰ é‡Œæ‰§è¡Œï¼š

```
wsl -l -v
wsl --shutdown
wsl --unregister CentOS7.6
```
ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/CentOS-WSL.html</guid><pubDate>Sat, 01 Nov 2025 16:43:23 +0000</pubDate></item><item><title>YOLOv5</title><link>https://feeday.cn/post/YOLOv5.html</link><description># ğŸ¯ YOLOv5 ä»‹ç»æ–‡æ¡£

## ğŸ§  ä¸€ã€ä»€ä¹ˆæ˜¯ YOLOï¼Ÿ

**YOLOï¼ˆYou Only Look Onceï¼‰** æ˜¯ä¸€ç§ç”¨äº **ç›®æ ‡æ£€æµ‹ï¼ˆObject Detectionï¼‰** çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/YOLOv5.html</guid><pubDate>Sat, 01 Nov 2025 16:42:11 +0000</pubDate></item><item><title>IndexTTS-2</title><link>https://feeday.cn/post/IndexTTS-2.html</link><description>## ç‰ˆæœ¬æ›´æ–°


- **2025/09/08** IndexTTS-2 å‘å¸ƒï¼ˆé¦–ä¸ªæ”¯æŒç²¾ç¡®åˆæˆæ—¶é•¿æ§åˆ¶çš„è‡ªå›å½’é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ï¼‰  
- **2025/05/14** IndexTTS-1.5 å‘å¸ƒï¼ˆæå‡æ¨¡å‹ç¨³å®šæ€§å’Œè‹±æ–‡è¡¨ç°ï¼‰  
- **2025/03/25** IndexTTS-1.0 å‘å¸ƒï¼ˆå¼€æ”¾æƒé‡å’Œæ¨ç†ä»£ç ï¼‰  
- **2025/02/12** è®ºæ–‡æäº¤è‡³ arXivï¼Œå¹¶å‘å¸ƒ Demo ä¸æµ‹è¯•é›†  

---

&lt;div style='text-align:left'&gt;
  &lt;a href='https://arxiv.org/abs/2506.21619'&gt;
    &lt;img src='https://img.shields.io/badge/ArXiv-2506.21619-red?logo=arxiv'/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href='https://github.com/index-tts/index-tts'&gt;
    &lt;img src='https://img.shields.io/badge/GitHub-Code-orange?logo=github'/&gt;
  &lt;/a&gt;
  &lt;a href='https://index-tts.github.io/index-tts2.github.io/'&gt;
    &lt;img src='https://img.shields.io/badge/GitHub-Demo-orange?logo=github'/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href='https://huggingface.co/spaces/IndexTeam/IndexTTS-2-Demo'&gt;
    &lt;img src='https://img.shields.io/badge/HuggingFace-Demo-blue?logo=huggingface'/&gt;
  &lt;/a&gt;
  &lt;a href='https://huggingface.co/IndexTeam/IndexTTS-2'&gt;
    &lt;img src='https://img.shields.io/badge/HuggingFace-Model-blue?logo=huggingface' /&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href='https://modelscope.cn/studios/IndexTeam/IndexTTS-2-Demo'&gt;
    &lt;img src='https://img.shields.io/badge/ModelScope-Demo-purple?logo=modelscope'/&gt;
  &lt;/&gt;
  &lt;a href='https://modelscope.cn/models/IndexTeam/IndexTTS-2'&gt;
    &lt;img src='https://img.shields.io/badge/ModelScope-Model-purple?logo=modelscope'/&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

## æ¨¡å‹ä¸‹è½½

| **HuggingFace**                                          | **ModelScope** |
|----------------------------------------------------------|----------------------------------------------------------|
| [IndexTTS-2](https://huggingface.co/IndexTeam/IndexTTS-2) | [IndexTTS-2](https://modelscope.cn/models/IndexTeam/IndexTTS-2) |
| [IndexTTS-1.5](https://huggingface.co/IndexTeam/IndexTTS-1.5) | [IndexTTS-1.5](https://modelscope.cn/models/IndexTeam/IndexTTS-1.5) |
| [IndexTTS](https://huggingface.co/IndexTeam/Index-TTS) | [IndexTTS](https://modelscope.cn/models/IndexTeam/Index-TTS) |

---


##  ç¤¾åŒºæ”¯æŒ

* QQ ç¾¤ï¼š553460296 (No.1) / 663272642 (No.4)
* Discordï¼š[Join](https://discord.gg/uT32E7KDmy)
* Emailï¼š[indexspeech@bilibili.com](mailto:indexspeech@bilibili.com)
* å®˜æ–¹ä»“åº“ï¼š[https://github.com/index-tts/index-tts](https://github.com/index-tts/index-tts)

---

## è®ºæ–‡æ¦‚è§ˆ

IndexTTS2ï¼šæƒ…æ„Ÿè¡¨è¾¾å’ŒæŒç»­æ—¶é—´æ§åˆ¶çš„è‡ªåŠ¨å›å½’é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³çš„çªç ´

[å‘¨æ€æ€¡](https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+S)ï¼Œ [å‘¨ä¹‰å…¨](https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+Y)ï¼Œ [ä½•æ¯…](https://arxiv.org/search/cs?searchtype=author&amp;query=He,+Y)ï¼Œ [å‘¨å‹‹](https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou,+X)ï¼Œ [ç‹é‡‘è¶…](https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+J)ï¼Œ [é‚“ä¼Ÿ](https://arxiv.org/search/cs?searchtype=author&amp;query=Deng,+W)ï¼Œ [èˆ’æ™¯æ™¨](https://arxiv.org/search/cs?searchtype=author&amp;query=Shu,+J)

[v2] 2025 å¹´ 9 æœˆ 3 æ—¥æ˜ŸæœŸä¸‰ 10ï¼š46ï¼š35 UTC ï¼ˆ1,632 KBï¼‰

ç°æœ‰çš„è‡ªå›å½’å¤§è§„æ¨¡æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹åœ¨è¯­éŸ³è‡ªç„¶æ€§æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œä½†å…¶é€ä¸ªæ ‡è®°çš„ç”Ÿæˆæœºåˆ¶ä½¿å¾—åˆæˆè¯­éŸ³çš„æŒç»­æ—¶é—´éš¾ä»¥ç²¾ç¡®æ§åˆ¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/IndexTTS-2.html</guid><pubDate>Sat, 01 Nov 2025 16:41:25 +0000</pubDate></item><item><title>huggingface é•œåƒç«™ PowerShell ä¸‹è½½</title><link>https://feeday.cn/post/huggingface%20-jing-xiang-zhan-%20PowerShell%20-xia-zai.html</link><description>HF Mirror â€”â€” Hugging Face ä¸‹è½½å…¨æ”»ç•¥ï¼ˆå›½å†…å¯ç”¨ï¼‰

&gt; AI å¼€å‘ç»•ä¸è¿‡ä¸€ä¸ªé—®é¢˜ï¼šå¦‚ä½•ä» Hugging Face ç¨³å®šä¸‹è½½æ¨¡å‹æˆ–æ•°æ®é›†ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/huggingface%20-jing-xiang-zhan-%20PowerShell%20-xia-zai.html</guid><pubDate>Sat, 01 Nov 2025 16:11:41 +0000</pubDate></item><item><title>rename_by_md5_with_log.py</title><link>https://feeday.cn/post/rename_by_md5_with_log.py.html</link><description>ä»¥æ–‡ä»¶ MD5 ä½œä¸ºæ–‡ä»¶åï¼ˆä¿ç•™æ‰©å±•åï¼‰ï¼Œé€’å½’å¤„ç†å­æ–‡ä»¶å¤¹ï¼Œ
    å¹¶ç”Ÿæˆä¸€ä¸ª md5_rename_map.csv è®°å½•åŸå§‹æ–‡ä»¶åä¸æ”¹åæ–‡ä»¶ååŠMD5

```
import os
import csv
import hashlib
from pathlib import Path

# ======== å¯ä¿®æ”¹é…ç½® ========
ROOT_DIR = Path(r'C:\test\md')  # è¦å¤„ç†çš„ç›®å½•
OUTPUT_CSV = ROOT_DIR / 'md5_rename_map1025.csv'    # è¾“å‡ºæ˜ å°„è¡¨è·¯å¾„
DRY_RUN = False  # True ä»…é¢„è§ˆä¸æ‰§è¡Œé‡å‘½å
# ===========================


def md5_of_file(file_path, chunk_size=8192):
    '''è®¡ç®—æ–‡ä»¶ MD5'''
    md5 = hashlib.md5()
    with open(file_path, 'rb') as f:
        while chunk := f.read(chunk_size):
            md5.update(chunk)
    return md5.hexdigest()


def rename_file_to_md5(file_path: Path, writer):
    '''é‡å‘½åå•ä¸ªæ–‡ä»¶ä¸ºmd5ï¼Œå¹¶å†™å…¥CSV'''
    try:
        md5_val = md5_of_file(file_path)
        new_name = f'{md5_val}{file_path.suffix.lower()}'
        new_path = file_path.with_name(new_name)

        if new_path == file_path:
            # å·²ç»æ˜¯ md5 å‘½å
            return

        if new_path.exists():
            print(f'âš ï¸ å·²å­˜åœ¨ç›¸åŒMD5æ–‡ä»¶ï¼Œè·³è¿‡ï¼š{file_path}')
            return

        if DRY_RUN:
            print(f'[DRY] {file_path} -&gt; {new_path}')
        else:
            file_path.rename(new_path)
            print(f'âœ… {file_path} -&gt; {new_path}')

        # å†™å…¥æ˜ å°„è¡¨
        writer.writerow([str(file_path), str(new_path), md5_val])

    except Exception as e:
        print(f'âŒ {file_path} è®¡ç®—æˆ–é‡å‘½åå¤±è´¥ï¼š{e}')


def main():
    with open(OUTPUT_CSV, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['original_path', 'new_path', 'md5'])

        for file in ROOT_DIR.rglob('*'):
            if file.is_file():
                rename_file_to_md5(file, writer)

    print(f'\nğŸ“„ æ˜ å°„è¡¨å·²ç”Ÿæˆï¼š{OUTPUT_CSV}')


if __name__ == '__main__':
    main()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/rename_by_md5_with_log.py.html</guid><pubDate>Thu, 30 Oct 2025 16:26:17 +0000</pubDate></item><item><title>æ›´æ–°è„šæœ¬</title><link>https://feeday.cn/post/geng-xin-jiao-ben.html</link><description>```
name: auto-author (stub)

on:
  schedule:
    - cron: '0 14 * * *'   # æ¯å¤© 14:00 UTCï¼ˆå¯æ”¹ï¼‰
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'è¯•è·‘ï¼ˆä¸åˆ›å»º Issueï¼‰'
        type: boolean
        default: false

permissions:
  contents: read
  issues: write

jobs:
  stub:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          pip install requests

      - name: Run stub author
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}       # e.g. tcq20256/puck.chat
          SERIES_NAME: ${{ vars.SERIES_NAME }} # å¯é€‰å˜é‡
          DRY_RUN: ${{ inputs.dry_run }}
        run: |
          python - &lt;&lt;'PY'
          import os, sys, requests, datetime, textwrap

          REPO_FULL = os.environ.get('REPO')           # 'owner/repo'
          TOKEN = os.environ.get('GITHUB_TOKEN')
          SERIES = os.environ.get('SERIES_NAME') or 'é›¾é’Ÿå··Â·è¶æ¢¦'
          DRY = str(os.environ.get('DRY_RUN','false')).lower()=='true'
          if not REPO_FULL or not TOKEN:
              print('Missing env REPO/GITHUB_TOKEN', file=sys.stderr); sys.exit(1)

          GH = 'https://api.github.com'
          hdr = {'Authorization': f'token {TOKEN}', 'Accept':'application/vnd.github+json'}

          # ä»Šå¤©æ˜¯å¦å·²å‘ï¼ˆå¸¦ auto æ ‡ç­¾ï¼‰
          today = datetime.datetime.utcnow().date().isoformat()
          r = requests.get(f'{GH}/repos/{REPO_FULL}/issues',
                           headers=hdr, params={'state':'open','labels':'auto'}, timeout=30)
          r.raise_for_status()
          for it in r.json():
              if (it.get('created_at','') or '')[:10] == today:
                  print('Already posted today. Exit.'); sys.exit(0)

          # ç»„è£…å ä½ç¨¿
          cn_now = (datetime.datetime.utcnow()
                    + datetime.timedelta(hours=8)).strftime('%Y-%m-%d %H:%M')
          title = f'{SERIES}ï½œå ä½ç¨¿ {today}'
          body = textwrap.dedent(f'''
          &gt; è¿™æ˜¯è‡ªåŠ¨å†™ä½œå ä½ç¨¿ï¼ˆæ—  API ç‰ˆï¼‰ï¼Œç”¨äºéªŒè¯â€œè‡ªåŠ¨åˆ›å»º Issue â†’ å‘å¸ƒç«™ç‚¹â€çš„æµæ°´çº¿ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/geng-xin-jiao-ben.html</guid><pubDate>Tue, 14 Oct 2025 16:08:20 +0000</pubDate></item><item><title>è±†åŒ… API</title><link>https://feeday.cn/post/dou-bao-%20API.html</link><description>## æ¨¡å‹å®šä»·
- [åœ¨çº¿ç”Ÿæˆ](https://console.volcengine.com/ark/region:ark+cn-beijing/model/detail?Id=doubao-seededit-3-0-i2i)
- [ä½¿ç”¨é‡æŸ¥çœ‹](https://console.volcengine.com/ark/region:ark+cn-beijing/openManagement?LLM=%7B%7D&amp;OpenTokenDrawer=false&amp;tab=ComputerVision)

æ¨¡å‹åç§° | å®šä»·å…ƒ/å¼ 
-- | --
doubao-seedream-4.0 | 0.2
doubao-seedream-3.0-t2i | 0.259
doubao-seededit-3.0-i2i | 0.3


## è±†åŒ…å›¾åƒè¯†åˆ«

```
import os
import sys
import subprocess

# ===== å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

install('openai&gt;=1.0')

from openai import OpenAI

# åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ï¼ˆå»ºè®®æ–¹å¼ï¼šä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
client = OpenAI(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxxx',
)

# è°ƒç”¨æ¨¡å‹
response = client.chat.completions.create(
    model='doubao-1-5-vision-pro-32k-250115',
    messages=[
        {
            'role': 'user',
            'content': [
                {
                    'type': 'image_url',
                    'image_url': {
                        'url': 'https://ark-project.tos-cn-beijing.ivolces.com/images/view.jpeg'
                    },
                },
                {'type': 'text', 'text': 'è¿™æ˜¯å“ªé‡Œï¼Ÿ'},
            ],
        }
    ],
)

print(response.choices[0].message)
```

## è±†åŒ…å›¾åƒä¿®æ”¹

```
import os
import sys
import subprocess

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

install('volcengine-python-sdk[ark]')

# ===== å¯¼å…¥ SDK =====
from volcenginesdkarkruntime import Ark

# åˆå§‹åŒ– Ark å®¢æˆ·ç«¯
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxxx',
)

# è°ƒç”¨å›¾ç‰‡ç”Ÿæˆæ¥å£
imagesResponse = client.images.generate(
    model='doubao-seededit-3-0-i2i-250628',
    prompt='æ”¹æˆçˆ±å¿ƒå½¢çŠ¶çš„æ³¡æ³¡',
    image='https://ark-project.tos-cn-beijing.volces.com/doc_image/seededit_i2i.jpeg',
    seed=123,
    guidance_scale=5.5,
    size='adaptive',
    watermark=True
)

# æ‰“å°è¿”å›å›¾ç‰‡åœ°å€
print(imagesResponse.data[0].url)
```

## è±†åŒ…æ”¹å›¾ä¸‹è½½æœ¬åœ°

```
import os
import sys
import subprocess
import requests

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    install('volcengine-python-sdk[ark]')
    from volcenginesdkarkruntime import Ark

# ===== åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ =====
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key='xxx',  # å»ºè®®æ”¹æˆ os.getenv('ARK_API_KEY')
)

# ===== é…ç½® =====
TXT_FILE = r'c:\prompts.txt'   # æç¤ºè¯æ–‡ä»¶
SAVE_DIR = r'C:\doubao\i2i'   # ä¸‹è½½ä¿å­˜ç›®å½•
os.makedirs(SAVE_DIR, exist_ok=True)

# ===== è¯»å–æç¤ºè¯æ–‡ä»¶å¹¶é€è¡Œè°ƒç”¨ =====
with open(TXT_FILE, 'r', encoding='utf-8') as f:
    prompts = [line.strip() for line in f if line.strip()]

for idx, prompt in enumerate(prompts, start=1):
    try:
        imagesResponse = client.images.generate(
            model='doubao-seededit-3-0-i2i-250628',
            prompt=prompt,  # æ¯è¡Œä½œä¸ºæç¤ºè¯
            image='https://ark-project.tos-cn-beijing.volces.com/doc_image/seededit_i2i.jpeg',
            seed=123,
            guidance_scale=5.5,
            size='adaptive',
            watermark=True
        )
        url = imagesResponse.data[0].url
        print(f'[{idx}] æç¤ºè¯: {prompt} -&gt; å›¾ç‰‡åœ°å€: {url}')

        # ===== ä¸‹è½½å›¾ç‰‡ =====
        resp = requests.get(url, timeout=60)
        if resp.status_code == 200:
            # æ–‡ä»¶åï¼šåºå·_å‰10ä¸ªå­—ç¬¦æç¤ºè¯.jpg
            safe_prompt = ''.join(c for c in prompt if c.isalnum())[:10]
            filename = os.path.join(SAVE_DIR, f'{idx:03d}_{safe_prompt}.jpg')
            with open(filename, 'wb') as f:
                f.write(resp.content)
            print(f'    å·²ä¿å­˜åˆ°: {filename}')
        else:
            print(f'    ä¸‹è½½å¤±è´¥: HTTP {resp.status_code}')

    except Exception as e:
        print(f'[{idx}] æç¤ºè¯: {prompt} -&gt; ç”Ÿæˆå¤±è´¥: {e}')
```

## æœ¬åœ°å›¾ç‰‡æ‰¹é‡ä¿®æ”¹

```
import os
import sys
import subprocess
import base64
import mimetypes
import requests
import re
from time import sleep

# ===== è‡ªåŠ¨å®‰è£…ä¾èµ– =====
def install(package):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', package])

try:
    from volcenginesdkarkruntime import Ark
except ImportError:
    install('volcengine-python-sdk[ark]')
    from volcenginesdkarkruntime import Ark

# ===== å·¥å…·å‡½æ•° =====
def to_data_url(img_path: str) -&gt; str:
    '''æŠŠæœ¬åœ°å›¾ç‰‡è½¬æˆ data URL: data:image/xxx;base64,xxxx'''
    with open(img_path, 'rb') as f:
        b64 = base64.b64encode(f.read()).decode('utf-8')
    mime, _ = mimetypes.guess_type(img_path)
    if not mime:
        mime = 'image/jpeg'
    return f'data:{mime};base64,{b64}'

def download(url: str, out_path: str, timeout: int = 60, retry: int = 3) -&gt; bool:
    for i in range(1, retry + 1):
        try:
            r = requests.get(url, timeout=timeout)
            if r.status_code == 200:
                with open(out_path, 'wb') as f:
                    f.write(r.content)
                return True
            else:
                print(f'    [ä¸‹è½½] HTTP {r.status_code}ï¼ˆ{i}/{retry}ï¼‰')
        except Exception as e:
            print(f'    [ä¸‹è½½] å¼‚å¸¸ï¼š{e}ï¼ˆ{i}/{retry}ï¼‰')
        sleep(1)
    return False

def natural_key(s: str):
    '''è‡ªç„¶æ’åº keyï¼Œç¡®ä¿ 2.jpg &lt; 10.jpg'''
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(r'(\d+)', s)]

# ===== åˆå§‹åŒ– Ark å®¢æˆ·ç«¯ =====
client = Ark(
    base_url='https://ark.cn-beijing.volces.com/api/v3',
    api_key=os.getenv('ARK_API_KEY', 'xxx'),  # æ¨èæ”¹ç”¨ç¯å¢ƒå˜é‡
)

# ===== è·¯å¾„é…ç½® =====
IMG_DIR  = r'C:\doubao\188'     # è¾“å…¥åŸå›¾ç›®å½•
SAVE_DIR = r'C:\doubao\i2i'    # è¾“å‡ºç›®å½•
TXT_FILE = r'C:\prompts.txt'   # æç¤ºè¯æ–‡ä»¶
os.makedirs(SAVE_DIR, exist_ok=True)

# ===== è¯»å–æç¤ºè¯ =====
with open(TXT_FILE, 'r', encoding='utf-8') as f:
    prompts = [line.strip() for line in f if line.strip()]
if not prompts:
    raise RuntimeError('prompts.txt ä¸ºç©ºï¼šè¯·è‡³å°‘æä¾›ä¸€è¡Œæç¤ºè¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/dou-bao-%20API.html</guid><pubDate>Thu, 25 Sep 2025 14:01:00 +0000</pubDate></item><item><title>srt åˆ‡è§†é¢‘éŸ³é¢‘</title><link>https://feeday.cn/post/srt%20-qie-shi-pin-yin-pin.html</link><description>## æŒ‰å­—å¹•åˆ‡å‰²éŸ³é¢‘è§†é¢‘
```
# -*- coding: utf-8 -*-
'''
cut_by_srt_auto.py
- è‡ªåŠ¨ pip å®‰è£…ä¾èµ– (srt, chardet, tqdm)
- è‡ªåŠ¨åŒ¹é…ç½®é¡¶æ–‡ä»¶å¤¹é‡Œçš„åª’ä½“æ–‡ä»¶ (mp4/mp3/wav/mkvç­‰)
- æ‰¾åˆ°å¯¹åº”åŒå .srt æ–‡ä»¶
- æŒ‰å­—å¹•æ—¶é—´åˆ‡ç‰‡ï¼Œå¹¶è¾“å‡ºåˆ° ã€åŸæ–‡ä»¶å_clipsã€‘æ–‡ä»¶å¤¹
'''

import os
import sys
import subprocess
import importlib.util
from pathlib import Path
import re
from datetime import timedelta

# ==== è‡ªåŠ¨å®‰è£…ä¾èµ– ====
def pip_install(package):
    try:
        __import__(package)
    except ImportError:
        print(f'[INFO] å®‰è£…ä¾èµ–: {package}')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])

for pkg in ['srt', 'chardet', 'tqdm']:
    pip_install(pkg)

import srt
import chardet
from tqdm import tqdm

# ==== å·¥å…·å‡½æ•° ====
def detect_encoding(p):
    raw = Path(p).read_bytes()
    enc = chardet.detect(raw).get('encoding') or 'utf-8'
    try:
        raw.decode(enc)
    except Exception:
        enc = 'utf-8'
    return enc

def td2ss(t: timedelta):
    return t.total_seconds()

def ss2tc(seconds: float):
    ms = int(round(seconds * 1000))
    h = ms // 3600000
    m = (ms % 3600000) // 60000
    s = (ms % 60000) // 1000
    ms = ms % 1000
    return f'{h:02d}:{m:02d}:{s:02d}.{ms:03d}'

def safe_name(text, keep=30):
    text = re.sub(r'[\\/:*?\'&lt;&gt;|]', '_', text.strip())
    text = re.sub(r'\s+', ' ', text)
    return text[:keep] if text else 'clip'

# ==== ä¸»é€»è¾‘ ====
def main():
    base = Path(__file__).parent  # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼ˆç½®é¡¶æ–‡ä»¶å¤¹ï¼‰
    # æ‰¾åª’ä½“æ–‡ä»¶
    media_files = list(base.glob('*.mp4')) + list(base.glob('*.mkv')) + list(base.glob('*.mp3')) + list(base.glob('*.wav'))
    if not media_files:
        print('[ERROR] æ²¡æ‰¾åˆ°åª’ä½“æ–‡ä»¶ï¼ˆæ”¯æŒ mp4/mkv/mp3/wavï¼‰')
        return
    media = media_files[0]  # é»˜è®¤å–ç¬¬ä¸€ä¸ª
    print(f'[INFO] ä½¿ç”¨åª’ä½“æ–‡ä»¶: {media}')

    # æ‰¾ srt æ–‡ä»¶ï¼ˆåŒåï¼‰
    srt_file = media.with_suffix('.srt')
    if not srt_file.exists():
        print(f'[ERROR] æ²¡æ‰¾åˆ°å¯¹åº”å­—å¹•æ–‡ä»¶: {srt_file}')
        return
    print(f'[INFO] ä½¿ç”¨å­—å¹•æ–‡ä»¶: {srt_file}')

    # è¾“å‡ºç›®å½•
    outdir = base / f'{media.stem}_clips'
    outdir.mkdir(exist_ok=True)

    # è¯»å–å­—å¹•
    enc = detect_encoding(srt_file)
    text = srt_file.read_text(encoding=enc, errors='ignore')
    subs = list(srt.parse(text))

    total = 0
    for i, sub in enumerate(tqdm(subs, desc='Cutting', unit='seg'), start=1):
        start_s = td2ss(sub.start)
        end_s = td2ss(sub.end)

        ss = ss2tc(start_s)
        to = ss2tc(end_s)

        snippet = sub.content.replace('\n', ' ').strip()
        name_text = safe_name(snippet, keep=20)

        ext = '.mp4' if media.suffix.lower() in ['.mp4', '.mkv'] else '.m4a'
        out_path = outdir / f'{i:03d}_{name_text}{ext}'

        cmd = [
            'ffmpeg', '-y', '-hide_banner', '-loglevel', 'error',
            '-ss', ss, '-to', to, '-i', str(media),
            '-c:v', 'libx264', '-preset', 'veryfast', '-crf', '23',
            '-c:a', 'aac', '-b:a', '128k',
            str(out_path)
        ]
        try:
            subprocess.run(cmd, check=True)
            total += 1
        except subprocess.CalledProcessError:
            print(f'[WARN] ç¬¬ {i} æ®µå¯¼å‡ºå¤±è´¥')

    print(f'[å®Œæˆ] å…±å¯¼å‡º {total} æ®µ -&gt; {outdir}')

if __name__ == '__main__':
    main()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/srt%20-qie-shi-pin-yin-pin.html</guid><pubDate>Sun, 21 Sep 2025 10:46:32 +0000</pubDate></item><item><title>Gitea ç®¡ç†è„šæœ¬</title><link>https://feeday.cn/post/Gitea%20-guan-li-jiao-ben.html</link><description># éƒ¨ç½² Gitea
```
#!/bin/bash
# Gitea ç®¡ç†è„šæœ¬ï¼šå®‰è£…å‰å…ˆå¸è½½æ—§çš„
set -e

GITEA_VERSION='1.22.3'                          # è¦å®‰è£…çš„ç‰ˆæœ¬
GITEA_BIN='/usr/local/bin/gitea'
GITEA_USER='git'
GITEA_HOME='/var/lib/gitea'
GITEA_CONF='/etc/gitea'
SERVICE_FILE='/etc/systemd/system/gitea.service'

uninstall_gitea() {
    echo 'âš ï¸ å¸è½½æ—§ç‰ˆ Gitea ...'
    systemctl stop gitea &gt;/dev/null 2&gt;&amp;1 || true
    systemctl disable gitea &gt;/dev/null 2&gt;&amp;1 || true
    rm -f $SERVICE_FILE
    rm -f $GITEA_BIN
    systemctl daemon-reload
    echo 'âœ… å¸è½½å®Œæˆï¼ˆæ•°æ®ç›®å½• $GITEA_HOME å’Œé…ç½® $GITEA_CONF ä¿ç•™ï¼‰'
}

install_gitea() {
    echo 'ğŸ“¥ å¼€å§‹å®‰è£… Gitea v${GITEA_VERSION} ...'
    # å¸è½½æ—§ç‰ˆæœ¬
    uninstall_gitea

    # åˆ›å»ºç”¨æˆ·å’Œç›®å½•
    id -u $GITEA_USER &amp;&gt;/dev/null || useradd -r -m -d $GITEA_HOME -s /bin/bash $GITEA_USER
    mkdir -p $GITEA_HOME/{custom,data,log} $GITEA_CONF
    chown -R $GITEA_USER:$GITEA_USER $GITEA_HOME $GITEA_CONF

    # ä¸‹è½½äºŒè¿›åˆ¶
    wget -O $GITEA_BIN 'https://dl.gitea.com/gitea/${GITEA_VERSION}/gitea-${GITEA_VERSION}-linux-amd64'
    chmod +x $GITEA_BIN

    # å†™ systemd æœåŠ¡
    cat &gt; $SERVICE_FILE &lt;&lt;EOF
[Unit]
Description=Gitea
After=syslog.target
After=network.target
Requires=network.target

[Service]
RestartSec=2s
Type=simple
User=$GITEA_USER
Group=$GITEA_USER
WorkingDirectory=$GITEA_HOME
ExecStart=$GITEA_BIN web --config $GITEA_CONF/app.ini
Restart=always
Environment=USER=$GITEA_USER HOME=$GITEA_HOME GITEA_WORK_DIR=$GITEA_HOME

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable gitea
    systemctl start gitea
    echo 'âœ… å®‰è£…å®Œæˆï¼è®¿é—® http://ä½ çš„IP:3000 åˆå§‹åŒ–'
}

restart_gitea() {
    echo 'ğŸ”„ æ­£åœ¨é‡å¯ Gitea ...'
    systemctl restart gitea
    echo 'âœ… å·²é‡å¯'
}

stop_gitea() {
    echo 'â¹ï¸ æ­£åœ¨åœæ­¢ Gitea ...'
    systemctl stop gitea
    echo 'âœ… å·²åœæ­¢'
}

menu() {
    echo '===== Gitea ç®¡ç† ====='
    echo '1) å®‰è£…æœ€æ–° Giteaï¼ˆä¼šè‡ªåŠ¨å¸è½½æ—§ç‰ˆï¼‰'
    echo '2) å¸è½½ Gitea'
    echo '3) é‡å¯ Gitea'
    echo '4) åœæ­¢ Gitea'
    echo '======================'
    read -p 'è¯·é€‰æ‹©æ“ä½œ: ' choice

    case $choice in
        1) install_gitea ;;
        2) uninstall_gitea ;;
        3) restart_gitea ;;
        4) stop_gitea ;;
        *) echo 'æ— æ•ˆé€‰æ‹©' ;;
    esac
}

menu
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Gitea%20-guan-li-jiao-ben.html</guid><pubDate>Sat, 13 Sep 2025 05:29:30 +0000</pubDate></item><item><title>CentOS 7.6  SSH é˜²æš´åŠ›ç ´è§£</title><link>https://feeday.cn/post/CentOS%207.6%20%20SSH%20-fang-bao-li-po-jie.html</link><description>#  æ™®é€šè¿æ¥

```
ssh -p 22 root@192.168.1.1
```

#  å¯†é’¥è¿æ¥

- https://github.com/settings/ssh/new

```
ssh-keygen -t rsa -b 4096 -C '123@qq.com'
type C:\.ssh\id_rsa.pub

ssh -i &lt;ç§é’¥æ–‡ä»¶è·¯å¾„&gt; &lt;ç”¨æˆ·å&gt;@&lt;æœåŠ¡å™¨IP&gt;

ssh -T git@github.com
git@github.com:tcq20256/feeday.git
```

# å°ç¦æ”»å‡»çš„IP

```
#!/usr/bin/env bash
# setup_ssh_antibrute.sh
# CentOS 7.6ï¼šFail2Ban SSH é˜²æš´åŠ›ç ´è§£ï¼ˆå®‰è£…/é…ç½® + è‡ªæ„ˆä¿®å¤ ä¸€ä½“åŒ–ï¼‰
# - ä»…åŠ¨ fail2banï¼Œä¸æ”¹ sshd ç«¯å£/è®¤è¯æ–¹å¼ï¼Œä¸å½±å“å…¶ä»–æœåŠ¡
# - firewalld åœ¨è·‘ï¼šfirewallcmd-ipsetï¼ˆè¿è¡Œæ—¶è§„åˆ™ï¼Œéæ°¸ä¹…ï¼‰ï¼›å¦åˆ™ç”¨ iptables-multiport
# - BAN/UNBAN å®¡è®¡æ—¥å¿—å¯è‡ªå®šä¹‰è·¯å¾„ï¼ˆé»˜è®¤ /home/lighthouse/bash/ssh-ban.logï¼Œæˆ– BAN_LOG='__SCRIPT_DIR__'ï¼‰
# - æ£€æµ‹åˆ° socket è¿æ¥å¤±è´¥ä¼šè‡ªåŠ¨æ‰§è¡Œä¿®å¤æµç¨‹ï¼ˆæ¸…ç†æ®‹ç•™ã€é‡å»º /run/fail2banã€æ¢å¤ SELinux ä¸Šä¸‹æ–‡ã€è¡¥é½ iptablesï¼‰

set -euo pipefail

### ===== å¯è°ƒå‚æ•°ï¼ˆä¹Ÿå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰=====
BANTIME='${BANTIME:-3600}'     # è¢«å°æ—¶é•¿ï¼ˆç§’ï¼‰
FINDTIME='${FINDTIME:-600}'    # è§‚å¯Ÿçª—å£ï¼ˆç§’ï¼‰
MAXRETRY='${MAXRETRY:-5}'      # å¤±è´¥æ¬¡æ•°é˜ˆå€¼
MY_IP='${MY_IP:-}'             # å¯é€‰ï¼šä½ çš„å‡ºå£ç™½åå•ï¼Œå¦‚ 1.2.3.4
DEFAULT_BAN_LOG='/home/lighthouse/bash/ssh-ban.log'

# æ—¥å¿—ä½ç½®ï¼šæ”¯æŒ BAN_LOG='__SCRIPT_DIR__'
SCRIPT_DIR='$(cd -- '$(dirname -- '${BASH_SOURCE[0]}')' &amp;&amp; pwd)'
if [[ '${BAN_LOG:-}' == '__SCRIPT_DIR__' ]]; then
  BAN_LOG='${SCRIPT_DIR}/ssh-ban.log'
else
  BAN_LOG='${BAN_LOG:-$DEFAULT_BAN_LOG}'
fi

### ===== å°å·¥å…· =====
msg(){ echo -e '\033[1;32m[INFO]\033[0m $*'; }
warn(){ echo -e '\033[1;33m[WARN]\033[0m $*'; }
err(){ echo -e '\033[1;31m[ERR ]\033[0m $*'; }

require_root(){ [[ ${EUID:-$(id -u)} -eq 0 ]] || { err 'è¯·ç”¨ root è¿è¡Œï¼šsudo bash $0'; exit 1; }; }
file_put(){ # $1:path  $2:content
  local p='$1'; shift
  umask 022; cat &gt;'$p' &lt;&lt;&lt;'$*'
  chmod 0644 '$p'
}

### ===== ä¿®å¤æµç¨‹ï¼šæ¸…ç†æ®‹ç•™ / ç›®å½• / SELinux / ç»„ä»¶ =====
repair_fail2ban(){
  warn 'è§¦å‘è‡ªæ„ˆä¿®å¤ï¼šæ¸…ç†æ®‹ç•™å¹¶é‡å»ºè¿è¡Œç¯å¢ƒâ€¦â€¦'
  systemctl stop fail2ban || true
  pkill -9 -f fail2ban-server || true

  rm -rf /run/fail2ban /var/run/fail2ban
  install -d -m 755 -o root -g root /run/fail2ban
  ln -sfn /run/fail2ban /var/run/fail2ban

  # SELinuxï¼ˆè‹¥å¯ç”¨åˆ™æ¢å¤ä¸Šä¸‹æ–‡ï¼Œæ— å‰¯ä½œç”¨ï¼‰
  if command -v selinuxenabled &gt;/dev/null 2&gt;&amp;1 &amp;&amp; selinuxenabled; then
    restorecon -Rv /run/fail2ban || true
  fi

  # ç»„ä»¶å…œåº•ï¼šå½“å‰ banaction å¯èƒ½ç”¨åˆ° iptables
  yum install -y -q iptables iptables-services || true

  # ç¡®ä¿ fail2ban.conf ä½¿ç”¨æ ‡å‡† socket è·¯å¾„ï¼ˆä»…ä¿®æ­£ç¼ºå¤±/å¼‚å¸¸æƒ…å†µï¼‰
  local conf='/etc/fail2ban/fail2ban.conf'
  if [[ -f '$conf' ]]; then
    grep -qE '^\s*socket\s*=\s*/var/run/fail2ban/fail2ban\.sock' '$conf' || \
      sed -ri 's|^\s*socket\s*=.*|socket = /var/run/fail2ban/fail2ban.sock|g' '$conf'
    grep -qE '^\s*pidfile\s*=\s*/var/run/fail2ban/fail2ban\.pid' '$conf' || \
      sed -ri 's|^\s*pidfile\s*=.*|pidfile = /var/run/fail2ban/fail2ban.pid|g' '$conf'
  fi

  systemctl restart fail2ban
  sleep 1
}

### ===== ä¸»æµç¨‹ =====
require_root

# 1) å®‰è£…ä¾èµ–
if ! rpm -qa | grep -qiE '^epel-release'; then
  msg 'å®‰è£… epel-release ...'
  yum install -y epel-release
fi
if ! rpm -qa | grep -qiE '^fail2ban(-server)?'; then
  msg 'å®‰è£… fail2ban ...'
  yum install -y fail2ban
else
  msg 'fail2ban å·²å®‰è£…'
fi

# 2) æ£€æµ‹ firewalld
FIREWALLD_ACTIVE=0
if systemctl is-active firewalld &gt;/dev/null 2&gt;&amp;1; then
  FIREWALLD_ACTIVE=1
  msg 'firewalld è¿è¡Œä¸­ï¼šbanaction=firewallcmd-ipsetï¼ˆè¿è¡Œæ—¶è§„åˆ™ï¼Œéæ°¸ä¹…ï¼‰'
else
  warn 'firewalld æœªè¿è¡Œï¼šbanaction=iptables-multiport'
fi
BANACTION='iptables-multiport'
[[ $FIREWALLD_ACTIVE -eq 1 ]] &amp;&amp; BANACTION='firewallcmd-ipset'

# 3) è‡ªå®šä¹‰åŠ¨ä½œï¼šlog-banï¼ˆæ­£ç¡®ä½¿ç”¨ &lt;name&gt;/&lt;ip&gt;/&lt;port&gt;/&lt;failures&gt;ï¼›printf ç”¨ %%sï¼›date ç”¨ %%F %%Tï¼‰
file_put /etc/fail2ban/action.d/log-ban.local \
'[Definition]
actionban   = /bin/sh -c '\''printf '%%s\tBAN\tjail=&lt;name&gt;\tip=&lt;ip&gt;\tport=&lt;port&gt;\tfailures=&lt;failures&gt;\tsrc=%(src)s\n' '$(date '+%%F %%T')' &gt;&gt; %(logfile)s'\''
actionunban = /bin/sh -c '\''printf '%%s\tUNBAN\tjail=&lt;name&gt;\tip=&lt;ip&gt;\n' '$(date '+%%F %%T')' &gt;&gt; %(logfile)s'\'''
chmod 0644 /etc/fail2ban/action.d/log-ban.local

# 4) ç”Ÿæˆ jail.localï¼ˆä»…å¼€å¯ sshd ç›‘ç‹±ï¼‰
JAIL_LOCAL='/etc/fail2ban/jail.local'
if [[ -f '$JAIL_LOCAL' ]]; then
  cp -a '$JAIL_LOCAL' '${JAIL_LOCAL}.bak.$(date +%Y%m%d-%H%M%S)'
  msg 'å·²å¤‡ä»½åŸé…ç½®ï¼š${JAIL_LOCAL}.bak.*'
fi
IGNOREIP='127.0.0.1/8'
[[ -n '$MY_IP' ]] &amp;&amp; IGNOREIP='$IGNOREIP $MY_IP'
file_put '$JAIL_LOCAL' \
'[DEFAULT]
bantime   = ${BANTIME}
findtime  = ${FINDTIME}
maxretry  = ${MAXRETRY}
backend   = auto
ignoreip  = ${IGNOREIP}
banaction = ${BANACTION}

[sshd]
enabled  = true
port     = ssh
filter   = sshd
logpath  = /var/log/secure
action   = %(action_)s
           log-ban[logfile=${BAN_LOG}, src=/var/log/secure]
'
chmod 0644 '$JAIL_LOCAL'

# 5) æ—¥å¿—ä¸ logrotate
mkdir -p '$(dirname -- '$BAN_LOG')'
touch '$BAN_LOG'
chmod 0640 '$BAN_LOG'
chown root:root '$BAN_LOG'
file_put /etc/logrotate.d/ssh-ban \
'${BAN_LOG} {
    daily
    rotate 14
    missingok
    notifempty
    compress
    create 0640 root root
}
'

# 6) å…œåº•è¿è¡Œç›®å½•
install -d -m 755 -o root -g root /run/fail2ban
ln -sfn /run/fail2ban /var/run/fail2ban

# 7) è¯­æ³•æµ‹è¯• &amp; å¯åŠ¨
msg 'æ ¡éªŒ fail2ban é…ç½®è¯­æ³• ...'
if ! fail2ban-client -t; then
  err 'é…ç½®è¯­æ³•æ ¡éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹è¾“å‡ºã€‚</description><guid isPermaLink="true">https://feeday.cn/post/CentOS%207.6%20%20SSH%20-fang-bao-li-po-jie.html</guid><pubDate>Sat, 13 Sep 2025 04:09:13 +0000</pubDate></item><item><title>ä¸‹è½½é“¾æ¥</title><link>https://feeday.cn/post/xia-zai-lian-jie.html</link><description>## è·å–é“¾æ¥
```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é… Hugging Face blob åœ°å€
for (const link of links) {
  const href = link.href;
  // åŒ¹é… datasets ä»“åº“ blob é“¾æ¥
  const urlRegex = /^https:\/\/huggingface\.co\/datasets\/[^/]+\/[^/]+\/blob\/[^/]+\/.+$/;
  if (urlRegex.test(href)) {
    // æ›¿æ¢ blob â†’ resolve
    const realUrl = href.replace('/blob/', '/resolve/');
    console.log('ç›´é“¾: ' + realUrl);
  }
}
```

## æ‰§è¡Œä¸‹è½½

```
# -*- coding: utf-8 -*-
'''
auto_paste_two_options.py
ä¸¤ä¸ªé€‰é¡¹ï¼š
1) å¼€å§‹ï¼šè¿›å…¥åæ ‡è·å–ç•Œé¢ â†’ F5 ä¿å­˜åæ ‡åè‡ªåŠ¨å¼€å§‹å¾ªç¯
0) é€€å‡º

å¾ªç¯é€»è¾‘ï¼š
- ä» TXT æ¯è¡Œè¯»å–
- ç‚¹å‡»è¾“å…¥æ¡† â†’ ç²˜è´´ â†’ å›è½¦(æˆ–ç‚¹å‡»æŒ‰é’®)
- é—´éš” N ç§’ç»§ç»­
'''

import os, sys, json, time, subprocess

# ===== ä¾èµ–è‡ªåŠ¨å®‰è£… =====
def ensure_packages():
    for p in ['pyautogui', 'keyboard', 'pyperclip']:
        try:
            __import__('pyautogui' if p=='pyautogui' else p)
        except Exception:
            print(f'[å®‰è£…] ç¼ºå°‘ {p}ï¼Œæ­£åœ¨å®‰è£…...')
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', p])
ensure_packages()

import pyautogui, keyboard, pyperclip

pyautogui.FAILSAFE = True
pyautogui.PAUSE = 0.03

CONFIG_FILE = 'auto_paste_config.json'
STATE_FILE  = 'auto_paste_state.json'

# ===== è¿™é‡ŒæŒ‰éœ€æ”¹é»˜è®¤å€¼ =====
DEFAULT_CONFIG = {
    'txt_file': r'c:\Users\Puck\Desktop\sid.txt',   # â† æ”¹æˆä½ çš„ txt è·¯å¾„
    'coords': {'click_target': None, 'submit_btn': None},
    'interval_sec': 180,                  # é—´éš”ç§’ï¼ˆ3åˆ†é’Ÿï¼‰
    'clear_before_paste': True,           # ç²˜è´´å‰ Ctrl+A æ¸…ç©º
    'press_enter_after_paste': True       # True=å›è½¦æäº¤ï¼›False=ç‚¹å‡» submit_btn
}

# ========== å·¥å…·å‡½æ•° ==========
def load_json(path, default=None):
    if os.path.exists(path):
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return default

def save_json(path, data):
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_conf():
    conf = load_json(CONFIG_FILE, None)
    if conf is None:
        conf = DEFAULT_CONFIG.copy()
        save_json(CONFIG_FILE, conf)
    else:
        # è¡¥é½å­—æ®µ
        for k, v in DEFAULT_CONFIG.items():
            if k not in conf: conf[k] = v
        if 'coords' not in conf or not isinstance(conf['coords'], dict):
            conf['coords'] = {'click_target': None, 'submit_btn': None}
        conf['coords'].setdefault('click_target', None)
        conf['coords'].setdefault('submit_btn', None)
        save_json(CONFIG_FILE, conf)
    return conf

def click(xy):
    if not xy: return
    x, y = xy
    pyautogui.moveTo(x, y, duration=0.05)
    pyautogui.click()

def paste_text(text, clear_before=True):
    if clear_before:
        pyautogui.hotkey('ctrl', 'a'); time.sleep(0.05)
    pyperclip.copy(text); time.sleep(0.05)
    pyautogui.hotkey('ctrl', 'v')

def press_enter():
    pyautogui.press('enter')

def human_time(sec):
    m, s = divmod(int(sec), 60)
    h, m = divmod(m, 60)
    if h: return f'{h}å°æ—¶{m}åˆ†{s}ç§’'
    if m: return f'{m}åˆ†{s}ç§’'
    return f'{s}ç§’'

def countdown(total_sec):
    start = time.time()
    paused = False
    while True:
        if keyboard.is_pressed('esc'):
            print('\n[é€€å‡º] ESC è§¦å‘ï¼Œç»“æŸå¾ªç¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/xia-zai-lian-jie.html</guid><pubDate>Wed, 10 Sep 2025 15:58:07 +0000</pubDate></item><item><title>GPT5-é›¾é’Ÿå··-å½’é€”</title><link>https://feeday.cn/post/GPT5--wu-zhong-xiang---gui-tu.html</link><description>æ—è¿œåœ¨åŸå¸‚é‡Œä½åœ¨ä¸€é—´ä½çŸ®çš„éš”æ–­æˆ¿ï¼Œçª—å¤–æ˜¯ä¸€æ¡æ°¸è¿œæ½®ç€æ²¹çƒŸçš„èƒŒè¡—ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--wu-zhong-xiang---gui-tu.html</guid><pubDate>Sat, 06 Sep 2025 09:34:40 +0000</pubDate></item><item><title>GPT5-é›¾é’Ÿå··-æ— åæ—¥</title><link>https://feeday.cn/post/GPT5--wu-zhong-xiang---wu-ming-ri.html</link><description>æ—è¿œæ‹–ç€è¡Œæä»å°ç«™å‡ºæ¥ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--wu-zhong-xiang---wu-ming-ri.html</guid><pubDate>Thu, 04 Sep 2025 15:34:35 +0000</pubDate></item><item><title>GPT5-é¬¼æ•…äº‹-é›¾é’Ÿå··</title><link>https://feeday.cn/post/GPT5--gui-gu-shi---wu-zhong-xiang.html</link><description>## ä¸€

æ—è¿œå›åˆ°é›¾é’Ÿå··çš„æ—¶å€™ï¼Œå¤©åˆšä¸‹è¿‡ä¸€é˜µç»†é›¨ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/GPT5--gui-gu-shi---wu-zhong-xiang.html</guid><pubDate>Thu, 04 Sep 2025 14:50:12 +0000</pubDate></item><item><title>word åˆå¹¶æ–‡æ¡£</title><link>https://feeday.cn/post/word%20-he-bing-wen-dang.html</link><description>## æ–‡æ¡£è½¬æ¢docxååˆå¹¶
```
import os
import sys
import time
import shutil
import subprocess
from pathlib import Path

# ========== è‡ªåŠ¨å®‰è£…ä¾èµ– ==========
def install(package_name, import_name=None):
    try:
        __import__(import_name or package_name)
    except ImportError:
        print(f'âš™ï¸ æ­£åœ¨å®‰è£…ä¾èµ–: {package_name} ...')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package_name])

install('python-docx', 'docx')
install('docxcompose', 'docxcompose')
try:
    __import__('win32com.client')
except ImportError:
    try:
        install('pywin32', 'win32com')
    except Exception:
        pass

from docx import Document
from docxcompose.composer import Composer

# ========== é…ç½® ==========
input_dir = r'D:\doc'            # å¾…åˆå¹¶ç›®å½•ï¼ˆå« .doc / .docxï¼‰
output_file = r'D:\merged.docx'  # è¾“å‡ºï¼ˆå¿…é¡» .docxï¼‰

# ========== å®šä½ soffice.exe ==========
def find_soffice_exe():
    candidates = [
        r'C:\Program Files\LibreOffice\program\soffice.exe',
        r'C:\Program Files (x86)\LibreOffice\program\soffice.exe',
    ]
    # ä¹Ÿæ”¯æŒä¾¿æºç‰ˆ/è‡ªå®šä¹‰å®‰è£…ï¼šåœ¨å¸¸è§ç›˜ç¬¦æœä¸€å±‚
    for drive in ['C:', 'D:', 'E:']:
        p = Path(drive + r'\LibreOffice\program\soffice.exe')
        if p.exists():
            candidates.insert(0, str(p))
    for p in candidates:
        if os.path.exists(p):
            return p
    # PATH ä¸­æŸ¥æ‰¾
    w = shutil.which('soffice')
    return w

def has_word():
    try:
        import win32com.client  # noqa
        return True
    except Exception:
        return False

# ========== è½¬æ¢å‡½æ•° ==========
def convert_doc_to_docx_with_soffice(soffice_path, doc_path):
    outdir = os.path.dirname(doc_path)
    print(f'ğŸ”„ LibreOffice è½¬æ¢: {doc_path}')
    try:
        subprocess.run(
            [soffice_path, '--headless', '--convert-to', 'docx', '--outdir', outdir, doc_path],
            check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True
        )
        new_path = doc_path + 'x'  # xxx.doc -&gt; xxx.docx
        for _ in range(30):
            if os.path.exists(new_path):
                break
            time.sleep(0.1)
        if os.path.exists(new_path):
            print(f'âœ… è½¬æ¢æˆåŠŸ: {new_path}')
            return new_path
        print(f'âŒ è½¬æ¢å¤±è´¥: æœªæ‰¾åˆ° {new_path}')
    except subprocess.CalledProcessError as e:
        print('âŒ LibreOffice è½¬æ¢å‡ºé”™ï¼š')
        print(e.stdout or str(e))
    return None

def convert_doc_to_docx_with_word(doc_path):
    print(f'ğŸ”„ Word è½¬æ¢: {doc_path}')
    try:
        import win32com.client as win32
        word = win32.gencache.EnsureDispatch('Word.Application')
        word.Visible = False
        doc = None
        new_path = doc_path + 'x'
        try:
            doc = word.Documents.Open(doc_path)
            doc.SaveAs(new_path, FileFormat=16)  # 16 = wdFormatXMLDocument (.docx)
        finally:
            if doc is not None:
                doc.Close(False)
            word.Quit()
        if os.path.exists(new_path):
            print(f'âœ… è½¬æ¢æˆåŠŸ: {new_path}')
            return new_path
        else:
            print(f'âŒ è½¬æ¢å¤±è´¥: æœªæ‰¾åˆ° {new_path}')
    except Exception as e:
        print(f'âŒ Word è½¬æ¢å‡ºé”™: {e}')
    return None

def convert_doc_to_docx(doc_path):
    soffice = find_soffice_exe()
    if soffice and os.path.exists(soffice):
        p = convert_doc_to_docx_with_soffice(soffice, doc_path)
        if p:
            return p
    if has_word():
        p = convert_doc_to_docx_with_word(doc_path)
        if p:
            return p
    print(f'âš ï¸ æ— æ³•è½¬æ¢ï¼ˆç¼ºå°‘ LibreOffice æˆ– Wordï¼‰ï¼š{doc_path}')
    return None

# ========== åˆå¹¶ ==========
def merge_docs(input_dir, output_file):
    if not output_file.lower().endswith('.docx'):
        base, _ = os.path.splitext(output_file)
        output_file = base + '.docx'
        print(f'â„¹ï¸ è¾“å‡ºå¼ºåˆ¶ä¸º .docxï¼š{output_file}')

    names = [f for f in os.listdir(input_dir)
             if f.lower().endswith(('.doc', '.docx')) and not f.startswith('~$')]
    names.sort()
    if not names:
        print('âš ï¸ ç›®å½•ä¸­æ²¡æœ‰ .doc / .docx æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/word%20-he-bing-wen-dang.html</guid><pubDate>Wed, 03 Sep 2025 10:23:23 +0000</pubDate></item><item><title>youtube-è§†é¢‘é¢„è§ˆ</title><link>https://feeday.cn/post/youtube--shi-pin-yu-lan.html</link><description># ğŸ¬ yt-dlp-youtube-web

åŸºäº **Python Flask** çš„ æ²¹ç®¡è§†é¢‘é¢„è§ˆï¼Œä»…ä¾›æµ‹è¯•ï¼Œé€‚é… Cookie éªŒè¯ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/youtube--shi-pin-yu-lan.html</guid><pubDate>Sat, 30 Aug 2025 17:54:41 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤å›¾åƒ</title><link>https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</link><description>åˆ é™¤é‡å¤å›¾åƒ
## å®‰è£…ä¾èµ–
```
pip install opencv-python numpy keras tensorflow
```
## è„šæœ¬ç¨‹åº
```
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input

# åŠ è½½ResNet50æ¨¡å‹ç”¨äºæå–å›¾åƒç‰¹å¾
model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_image_features(image_path):
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    image = cv2.resize(image, (224, 224))  # è°ƒæ•´å›¾ç‰‡å¤§å°
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾
    features = features.flatten()  # å±•å¹³ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # ç‰¹å¾å‘é‡å½’ä¸€åŒ–
    
    return features

def delete_duplicate_images(directory):
    images = []
    features = []
    to_delete = []
    
    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        if os.path.isfile(file_path):
            try:
                image_features = extract_image_features(file_path)
                for i, feature in enumerate(features):
                    # è®¡ç®—å›¾åƒä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦
                    similarity = np.dot(image_features, feature) / (np.linalg.norm(image_features) * np.linalg.norm(feature))
                    if similarity &gt; 0.99:  # è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œåˆ¤æ–­å›¾ç‰‡æ˜¯å¦ç›¸ä¼¼
                        print(f'Found duplicate: {filename} and {images[i]}')
                        to_delete.append(file_path)
                        break
                else:
                    images.append(filename)
                    features.append(image_features)
            except Exception as e:
                print(f'Error processing {filename}: {e}')
    
    # åˆ é™¤é‡å¤çš„å›¾ç‰‡
    for file_path in to_delete:
        os.remove(file_path)
        print(f'Deleted duplicate image: {file_path}')

# è®¾ç½®å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
directory = r'D:\test'
delete_duplicate_images(directory)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</guid><pubDate>Wed, 20 Aug 2025 04:08:42 +0000</pubDate></item><item><title>æ­£åˆ™è¡¨è¾¾å¼</title><link>https://feeday.cn/post/zheng-ze-biao-da-shi.html</link><description>
# æ­£åˆ™è¡¨è¾¾å¼é€ŸæŸ¥ä¸ç¤ºä¾‹

---

## åŸºç¡€åŒ¹é…

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **éæ•°å­—** | `[^0-9]*` | `abc123` | `abc` |
| **éæ•°å­—ï¼ˆç®€å†™ï¼‰** | `\D+` | `A9B` | `A` |
| **n ä½æ•°å­—** | `\d{4}` | `2025-08` | `2025` |
| **è‡³å°‘ n ä½æ•°å­—** | `\d{3,}` | `abc12345xyz` | `12345` |
| **é•¿åº¦ 3â€“20 çš„ä»»æ„å­—ç¬¦** | `.{3,20}` | `hello` | `hello` |

---

## å¤šè¡Œæ¨¡å¼ï¼ˆ`(?m)`ï¼‰

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **æ¯è¡Œæœ€åä¸¤ä¸ªå­—ç¬¦** | `(?m).{2}$` | `abc\ndefg` | `bc`, `fg` |
| **æ¯è¡Œå¼€å¤´ä¸¤ä¸ªå­—ç¬¦** | `(?m)^.{2}` | `abc\ndefg` | `ab`, `de` |

---

## å­—ç¬¦ç±»

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **ä¸­æ–‡å­—ç¬¦** | `[\u4e00-\u9fa5]` | `ä½ å¥½123` | `ä½ `, `å¥½` |
| **ä¸­æ–‡å­—ç¬¦ï¼ˆæ¨èï¼‰** | `\p{Han}` | `æ±‰å­—abc` | `æ±‰`, `å­—` |
| **è‹±æ–‡å’Œæ•°å­—** | `[A-Za-z0-9]+` | `abc123!` | `abc123` |
| **æ•°å­—ã€å­—æ¯ã€ä¸‹åˆ’çº¿** | `[A-Za-z0-9_]+` | `abc_123!` | `abc_123` |
| **é•¿åº¦ 3â€“20 çš„æ•°å­—/å­—æ¯/ä¸‹åˆ’çº¿** | `[A-Za-z0-9_]{3,20}` | `abc_123` | `abc_123` |

---

## å¸¸ç”¨æå–è§„åˆ™

| åŠŸèƒ½ | æ­£åˆ™ | ç¤ºä¾‹æ–‡æœ¬ | åŒ¹é…ç»“æœ |
|------|------|----------|----------|
| **åŒ¹é… `(æ•°å­—)`** | `\(\d+\)` | `file(1).txt` | `(1)` |
| **é‚®ç®±** | `^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+$` | `test@example.com` | `test@example.com` |
| **ä¸­å›½å¤§é™†æ‰‹æœºå·** | `^1[3-9]\d{9}$` | `13812345678` | `13812345678` |

---

## URL åŒ¹é…ï¼ˆåŒå¼•å·åŒ…å›´ï¼‰

1. åŸå§‹ç‰ˆæœ¬ï¼ˆä¸å…è®¸åŸŸåä¸­æœ‰ `.`ï¼‰
```regex
https?:\/\/[^\s\/$.?#]+[^\s]*?(?=')
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zheng-ze-biao-da-shi.html</guid><pubDate>Thu, 14 Aug 2025 14:46:44 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤æ–‡ä»¶</title><link>https://feeday.cn/post/shan-chu-zhong-fu-wen-jian.html</link><description>## åˆ é™¤é‡å¤æ–‡ä»¶
```
import os
import re

# === é…ç½® ===
FOLDER = r'C:\Users\1'  # ç›®æ ‡ç›®å½•
RECURSIVE = False                    # True=é€’å½’å­æ–‡ä»¶å¤¹
DRY_RUN = False                       # True=é¢„æ¼”ï¼›ç¡®è®¤åæ”¹ä¸º False çœŸåˆ 

# è§„åˆ™ï¼šåªè¦â€œæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰â€é‡Œå‡ºç° (æ•°å­—) å°±è®¤å®šä¸ºå‰¯æœ¬
# ä¾‹ï¼ša(1).txt / a (2).txt / a(12) (3).jpg éƒ½ä¼šè¢«åˆ é™¤
PAREN_NUM_IN_STEM = re.compile(r'\(\s*\d+\s*\)')

def iter_files(folder):
    if RECURSIVE:
        for root, _, files in os.walk(folder):
            for f in files:
                yield root, f
    else:
        for f in os.listdir(folder):
            p = os.path.join(folder, f)
            if os.path.isfile(p):
                yield folder, f

deleted, skipped = 0, 0

for root, fname in iter_files(FOLDER):
    stem, ext = os.path.splitext(fname)
    if ext == '':  # æ— æ‰©å±•åä¹ŸæŒ‰è§„åˆ™å¤„ç†
        stem = fname
    if PAREN_NUM_IN_STEM.search(stem):
        path = os.path.join(root, fname)
        try:
            if DRY_RUN:
                print(f'[é¢„æ¼”] å°†åˆ é™¤ï¼š{path}')
            else:
                os.remove(path)
                print(f'å·²åˆ é™¤ï¼š{path}')
            deleted += 1
        except Exception as e:
            print(f'åˆ é™¤å¤±è´¥ï¼š{path}ï¼ŒåŸå› ï¼š{e}')
            skipped += 1

print(f'\nå®Œæˆã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-wen-jian.html</guid><pubDate>Thu, 14 Aug 2025 14:07:26 +0000</pubDate></item><item><title>æ–‡æœ¬åˆå¹¶</title><link>https://feeday.cn/post/wen-ben-he-bing.html</link><description>##  ç‰¹æ®Šæ ¼å¼æ–‡æœ¬åˆå¹¶
```
import os
import chardet  # pip install chardet

# æŒ‡å®šç›®å½•è·¯å¾„ï¼ˆä¿®æ”¹ä¸ºä½ çš„ç›®å½•ï¼‰
directory = r'D:\txthb'  # ç¤ºä¾‹ï¼šr'D:\data\texts'

# è¾“å‡ºæ–‡ä»¶è·¯å¾„
output_file = os.path.join(directory, 'merged.txt')
error_log = os.path.join(directory, 'errors.log')

# æ‰©å±•å¸¸è§ç¼–ç åˆ—è¡¨ï¼Œæ”¯æŒæ›´å¤šï¼ˆå¦‚ç¹ä½“Big5ã€UTF-16ï¼‰
common_encodings = ['utf-8', 'gbk', 'utf-8-sig', 'gb2312', 'big5', 'utf-16', 'latin1', 'cp1252']

def read_file_with_encoding(file_path):
    # å…ˆå°è¯•æ£€æµ‹ç¼–ç 
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        detected = chardet.detect(raw_data)
        encoding = detected['encoding'] if detected['encoding'] else None
    
    # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œé€ä¸ªå°è¯•å¸¸è§ç¼–ç 
    if not encoding:
        for enc in common_encodings:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    return f.read().strip()
            except UnicodeDecodeError:
                continue
        raise ValueError(f'æ— æ³•è¯»å–æ–‡ä»¶ {file_path}ï¼Œç¼–ç ä¸æ”¯æŒã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wen-ben-he-bing.html</guid><pubDate>Tue, 12 Aug 2025 10:27:27 +0000</pubDate></item><item><title>å¾®è½¯æœ¬åœ°æ–‡å­—è½¬è¯­éŸ³</title><link>https://feeday.cn/post/wei-ruan-ben-di-wen-zi-zhuan-yu-yin.html</link><description>## HTML ç‰ˆæœ¬
```
&lt;!DOCTYPE html&gt;
&lt;html lang='zh-CN'&gt;
&lt;head&gt;
    &lt;meta charset='UTF-8'&gt;
    &lt;meta name='viewport' content='width=device-width, initial-scale=1.0'&gt;
    &lt;title&gt;æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;æ–‡æœ¬è½¬è¯­éŸ³å¹¶æ’­æ”¾&lt;/h1&gt;

    &lt;label for='textInput'&gt;è¯·è¾“å…¥æ–‡æœ¬ï¼š&lt;/label&gt;&lt;br&gt;
    &lt;textarea id='textInput' rows='4' cols='50'&gt;&lt;/textarea&gt;&lt;br&gt;&lt;br&gt;

    &lt;label for='filterChinese'&gt;åªæ˜¾ç¤ºä¸­æ–‡è¯­éŸ³ï¼Ÿ&lt;/label&gt;
    &lt;input type='checkbox' id='filterChinese' checked&gt;&lt;br&gt;&lt;br&gt;

    &lt;label for='voiceSelect'&gt;é€‰æ‹©è¯­éŸ³ï¼ˆéŸ³è‰²ï¼‰ï¼š&lt;/label&gt;
    &lt;select id='voiceSelect'&gt;&lt;/select&gt;&lt;br&gt;&lt;br&gt;

    &lt;button id='startButton'&gt;å¼€å§‹æœ—è¯»&lt;/button&gt;
    &lt;button id='stopButton'&gt;åœæ­¢æœ—è¯»&lt;/button&gt;

    &lt;script&gt;
        // è·å–å¯ç”¨çš„è¯­éŸ³å¹¶å¡«å……é€‰æ‹©æ¡†
        function populateVoiceList() {
            const voices = speechSynthesis.getVoices();
            const voiceSelect = document.getElementById('voiceSelect');
            const filterChinese = document.getElementById('filterChinese').checked;
            voiceSelect.innerHTML = ''; // æ¸…ç©ºç°æœ‰é€‰é¡¹

            // æ”¯æŒæ‰€æœ‰è¯­éŸ³ï¼ˆæ›´å¤šéŸ³è‰²ï¼‰ï¼Œæˆ–å¯é€‰è¿‡æ»¤ä¸­æ–‡
            let filteredVoices = voices;
            if (filterChinese) {
                filteredVoices = voices.filter(voice =&gt; voice.lang.startsWith('zh-')); // æ”¯æŒ zh-CN, zh-TW ç­‰
            }

            console.log('å¯ç”¨è¯­éŸ³åˆ—è¡¨:', filteredVoices); // è°ƒè¯•ï¼šæ‰“å°åˆ°æ§åˆ¶å°

            if (filteredVoices.length === 0) {
                // å¦‚æœæ²¡æœ‰è¯­éŸ³ï¼Œæ˜¾ç¤ºæç¤º
                const option = document.createElement('option');
                option.textContent = 'æ— å¯ç”¨è¯­éŸ³ï¼ˆè¯·å®‰è£…TTSå¼•æ“ï¼‰';
                option.disabled = true;
                voiceSelect.appendChild(option);
                alert('æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç”¨è¯­éŸ³ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wei-ruan-ben-di-wen-zi-zhuan-yu-yin.html</guid><pubDate>Tue, 12 Aug 2025 04:37:10 +0000</pubDate></item><item><title>è§†é¢‘å»¶é•¿</title><link>https://feeday.cn/post/shi-pin-yan-chang.html</link><description># è§†é¢‘å»¶é•¿

ä¸æ»¡è¶³åç§’çš„æ°´å¹³æ­£å€’æ’­æ”¾å»¶è¿Ÿåç§’ä»¥ä¸Š

```
import os, math
from moviepy.editor import VideoFileClip, concatenate_videoclips, vfx

# === é…ç½® ===
INPUT_DIR  = r'D:\\1'   # å¾…å¤„ç†è§†é¢‘ç›®å½•
OUTPUT_DIR = r'D:\2'   # è¾“å‡ºç›®å½•
TARGET_SEC = 10                      # æœ€å°‘ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰
EXTS = ('.mp4', '.mov', '.avi', '.mkv', '.m4v')

os.makedirs(OUTPUT_DIR, exist_ok=True)

def build_pingpong_min_duration(clip, min_sec=10):
    '''
    æŠŠ clip åšæˆâ€œæ­£æ”¾+å€’æ”¾â€äº¤æ›¿çš„ ping-pong å¾ªç¯ï¼Œ
    ä¸€ç›´æ‹¼åˆ°æ—¶é•¿ &gt;= min_secï¼Œä¸æˆªæ–­ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-yan-chang.html</guid><pubDate>Mon, 11 Aug 2025 04:31:45 +0000</pubDate></item><item><title>deepseek-chat-é¬¼æ•…äº‹-é›¾é’Ÿå··</title><link>https://feeday.cn/post/deepseek-chat--gui-gu-shi---wu-zhong-xiang.html</link><description>## é›¾é’Ÿå··

### æ–‡æ¡ˆ  

'å½“é’Ÿå£°æ•²å“ç¬¬åäºŒä¸‹ï¼Œä½ ä¼šå¬è§è‡ªå·±çš„å¿ƒè·³æ¶ˆå¤±ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/deepseek-chat--gui-gu-shi---wu-zhong-xiang.html</guid><pubDate>Sun, 10 Aug 2025 04:26:13 +0000</pubDate></item><item><title>æŒ‡å®šæ–‡ä»¶å¤¹é‡å‘½å</title><link>https://feeday.cn/post/zhi-ding-wen-jian-jia-zhong-ming-ming.html</link><description>æŒ‡å®šæ–‡ä»¶å¤¹åŒ…å«å­æ–‡ä»¶å¤¹é‡å‘½å
```
import os
import shutil
import uuid

def rename_image_files(directory, prefix='Real_'):
    '''
    éå†ç›®å½•åŠå­ç›®å½•ï¼Œæ‰¹é‡é‡å‘½åå›¾åƒ/è§†é¢‘æ–‡ä»¶ä¸º å‰ç¼€+ç¼–å·ï¼Œé¿å…é‡å¤ã€è¦†ç›–ã€é—æ¼ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zhi-ding-wen-jian-jia-zhong-ming-ming.html</guid><pubDate>Fri, 08 Aug 2025 04:24:09 +0000</pubDate></item><item><title>Kontext-æç¤ºè¯</title><link>https://feeday.cn/post/Kontext--ti-shi-ci.html</link><description>

- [https://huggingface.co/spaces/kontext-community](https://huggingface.co/spaces/kontext-community/FLUX.1-Kontext-multi-image)

## è€ç…§ç‰‡ä¿®å¤
```
restore and colorize this photo. Repair the damaged white background. Maintain the consistency between the characters and the background
```

- https://zhuanlan.zhihu.com/p/1922042108895797435

éœ€æ±‚ç±»å‹ | è‹±æ–‡æ¨¡æ¿ | ä¸­æ–‡è§£æ
-- | -- | --
å¯¹è±¡ä¿®æ”¹ | 'Change [object] to [new state], keep [content to preserve] unchanged' | æ›´æ”¹ [å…·ä½“å¯¹è±¡] ä¸º [æ–°çš„çŠ¶æ€]ï¼ŒåŒæ—¶ä¿æŒ [éœ€è¦ä¿ç•™çš„å†…å®¹] ä¸å˜ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/Kontext--ti-shi-ci.html</guid><pubDate>Wed, 30 Jul 2025 10:02:57 +0000</pubDate></item><item><title>å¤šä¸ªè¡¨åˆå¹¶</title><link>https://feeday.cn/post/duo-ge-biao-he-bing.html</link><description>### å¤šå¼ æ ¼å¼ä¸€æ ·çš„è¡¨åˆå¹¶æˆä¸€ä¸ªè¡¨
```
import pandas as pd
import os

# è®¾ç½®æ–‡ä»¶å¤¹è·¯å¾„
folder_path = r'D:\hb  # æ›¿æ¢ä¸ºä½ çš„CSVæ–‡ä»¶å¤¹è·¯å¾„

# è·å–æ‰€æœ‰ CSV æ–‡ä»¶è·¯å¾„
csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

# åˆå¹¶æ‰€æœ‰ CSV æ–‡ä»¶
df_list = [pd.read_csv(os.path.join(folder_path, f)) for f in csv_files]
combined_df = pd.concat(df_list, ignore_index=True)

# ä¿å­˜ä¸ºä¸€ä¸ªæ–°æ–‡ä»¶
combined_df.to_csv(r'D:\hb.csv', index=False)

```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/duo-ge-biao-he-bing.html</guid><pubDate>Mon, 28 Jul 2025 05:05:08 +0000</pubDate></item><item><title>æ–‡æœ¬è¡Œè½¬è¡¨åˆ—</title><link>https://feeday.cn/post/wen-ben-xing-zhuan-biao-lie.html</link><description>
### è¿è¡Œè„šæœ¬
```
import sys
import subprocess
import os
import re

# è‡ªåŠ¨å®‰è£…åŒ…çš„å‡½æ•°
def install_package(package):
    try:
        __import__(package)
    except ImportError:
        print(f'ç¼ºå°‘åŒ… {package}ï¼Œæ­£åœ¨å®‰è£…...')
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
        print(f'{package} å®‰è£…å®Œæˆã€‚</description><guid isPermaLink="true">https://feeday.cn/post/wen-ben-xing-zhuan-biao-lie.html</guid><pubDate>Thu, 24 Jul 2025 14:56:23 +0000</pubDate></item><item><title>è¯­è¨€æ¨¡å‹-API-æ‰¹é‡ç”Ÿæˆæ–‡æœ¬</title><link>https://feeday.cn/post/yu-yan-mo-xing--API--pi-liang-sheng-cheng-wen-ben.html</link><description>æ–‡æœ¬æ¨¡å‹æ‰¹é‡ç”Ÿæˆæ–‡æœ¬æµ‹è¯•

## ChatGPT 

ç¬¬ä¸‰æ–¹ä»£ç†æ¥å£

-  [https://openkey.cloud](https://openkey.cloud/register?aff=22CVF)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key='sk-x',
    base_url='https://openkey.cloud/v1'
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

category_map = {
    'æ¡ˆä»¶æ¡ˆä¾‹': 'Case Study',
    'åšå®¢æ–‡ç« ': 'Blog Article',
    'ä¸ªäººæ—¥è®°': 'Personal Diary',
    'è§‚ç‚¹': 'Opinion',
    'å¹¿å‘Šæ–‡æ¡ˆ': 'Advertising Copy',
    'æŠ€æœ¯æ–‡æ¡£': 'Technical Document',
    'è¯„è®º': 'Review',
    'æ•£æ–‡': 'Essay',
    'ç¤¾äº¤åª’ä½“å¸–å­': 'Social Media Post',
    'è¯—æ­Œ': 'Poetry',
    'å°è¯´ç‰‡æ®µ': 'Fiction Excerpt',
    'æ–°é—»æŠ¥é“': 'News Report',
    'å­¦æœ¯è®ºæ–‡æ‘˜è¦': 'Academic Abstract',
    'AI': 'Artificial Intelligence',
    'åŠ¨ç‰©': 'Animals',
    'æƒ…æ„Ÿ': 'Emotion',
    'å…¬ç›Š': 'Public Welfare',
    'è´­ç‰©': 'Shopping',
    'å¤ä»£æ–‡æ˜': 'Ancient Civilization',
    'äº¤é€š': 'Transportation',
    'æ•™è‚²': 'Education',
    'è¿‘ä»£æˆ˜äº‰': 'Modern War',
    'ç»æµ': 'Economics',
    'ç§‘å¹»': 'Science Fiction',
    'ç§‘æŠ€': 'Technology',
    'ç§‘æ™®': 'Popular Science',
    'å†å²': 'History',
    'æ—…è¡Œ': 'Travel',
    'ç¾é£Ÿ': 'Cuisine',
    'æ¯å©´': 'Mother and Baby',
    'å¥‡å¹»': 'Fantasy',
    'æ°”å€™å˜åŒ–': 'Climate Change',
    'ä¸‰å†œ': 'Agriculture and Rural Affairs',
    'ç¤¾ä¼šé—®é¢˜': 'Social Issues',
    'æ‘„å½±': 'Photography',
    'ç”Ÿæ´»': 'Lifestyle',
    'æ—¶å°š': 'Fashion',
    'æ—¶æ”¿': 'Current Politics',
    'ä½“è‚²': 'Sports',
    'æ–‡åŒ–': 'Culture',
    'æ­¦å™¨': 'Weapons',
    'æ ¡å›­': 'Campus',
    'åŒ»ç–—': 'Medical',
    'è‰ºæœ¯': 'Art',
    'éŸ³ä¹': 'Music',
    'å½±è§†': 'Film and TV',
    'æ¸¸æˆ': 'Gaming',
    'å¨±ä¹': 'Entertainment',
    'è‚²å„¿': 'Parenting',
    'èŒåœº': 'Workplace',
    'æ¤ç‰©': 'Plants',
    'å•†ä¸š': 'Business',
    'æ­£å¼': 'Formal',
    'å™äº‹': 'Narrative',
    'æƒ…æ„ŸåŒ–': 'Emotional',
    'ç§‘æ™®': 'Popular Science'
}

def char_count(text: str) -&gt; int:
    return len(text)

def generate_text(primary, secondary, style, max_retries=3):
    primary_en = category_map.get(primary, primary)
    secondary_en = category_map.get(secondary, secondary)
    style_en = category_map.get(style, style)

    prompt = (
        f'Please write a coherent, well-structured English text with at least 250 characters and preferably no more than 350 characters about the following:\n'
        f'Primary category: {primary_en}\n'
        f'Secondary category: {secondary_en}\n'
        f'Writing style: {style_en}\n'
        f'Important: The entire text must be in English without any Chinese characters or words.'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=900
            )
            text = response.choices[0].message.content.strip()
            char_num = char_count(text)
            if char_num &gt;= 250:
                return text
            else:
                print(f'Retry {attempt} for {primary}-{secondary}-{style}, char count {char_num} &lt; 250')
                time.sleep(1)
        except Exception as e:
            print(f'Error for {primary}-{secondary}-{style}: {e}')
            time.sleep(2)
    print(f'Max retries reached for {primary}-{secondary}-{style}, returning last result')
    return text

def write_to_csv_with_timestamp(base_name, rows, batch_size, output_dir='D:/data/output'):
    os.makedirs(output_dir, exist_ok=True)
    now_str = datetime.now().strftime('%Y%m%d%H%M')
    filename = f'{base_name}_{now_str}_{batch_size}.csv'
    full_path = os.path.join(output_dir, filename)
    with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch of {len(rows)} records to {full_path}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    buffer = []
    base_name = 'generated_texts'
    output_dir = r'C:\test'  # ä½ éœ€è¦çš„è¾“å‡ºç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                char_num = char_count(content)
                print(f'Content ({char_num} chars):\n')
                print(content)
                print('\n' + '='*80 + '\n')

                buffer.append([task_counter, primary, secondary, style, content, char_num])

                if len(buffer) &gt;= batch_size:
                    write_to_csv_with_timestamp(base_name, buffer, batch_size, output_dir=output_dir)
                    buffer.clear()

                time.sleep(1)  # é™æµé˜²å°ç¦

    if buffer:
        write_to_csv_with_timestamp(base_name, buffer, len(buffer), output_dir=output_dir)

    print('All done!')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[354/2028] Generating: ä¸ªäººæ—¥è®° - ç§‘å¹» - å™äº‹
Generated chars: 400
Full content:
October 12, 2147

Today, I stumbled upon an ancient device in the ruins of an old libraryâ€”an old smartphone. Its screen flickered to life, revealing images of a world long gone. I felt a surge of nostalgia for a time when humans thrived on connection, not just data. As I scrolled through its apps, I wondered what stories lay hidden in its memory, waiting to bridge the gap between past and present.
```

## DeepSeek
- [https://platform.deepseek.com/api_keys](https://platform.deepseek.com/api_keys)
### è¿è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ›¿æ¢æˆ DeepSeek çš„ base_url å’Œ api_key
client = OpenAI(
    api_key='sk-x',  # è¿™é‡Œæ¢æˆä½ åœ¨ DeepSeek ç”³è¯·çš„ API Key
    base_url='https://api.deepseek.com'    # DeepSeek API åœ°å€ï¼Œå¸¦/v1ä¹Ÿå¯ä»¥
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

def generate_text(primary: str, secondary: str, style: str, max_retries=3) -&gt; str:
    prompt = (
        f'Please write an English text about the following topic.\n'
        f'The text must be coherent and well-structured,\n'
        f'with at least 200 characters. Avoid making the text too long.\n\n'
        f'Primary category: {primary}\n'
        f'Secondary category: {secondary}\n'
        f'Writing style: {style}'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='deepseek-chat',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=500  # å…è®¸ç¨é•¿æ–‡æœ¬ï¼Œæ¨¡å‹è‡ªåŠ¨æ§åˆ¶é•¿åº¦
            )
            text = response.choices[0].message.content.strip()
            length = len(text)
            if length &gt;= 200:
                return text.replace('\n', ' ')
            else:
                print(f'Retry {attempt} for {primary} - {secondary} - {style}: char count {length} &lt; 200')
                time.sleep(1)
        except Exception as e:
            print(f'Error on {primary} - {secondary} - {style}: {e}')
            time.sleep(2)

    print(f'Max retries reached for {primary} - {secondary} - {style}. Returning last result.')
    if text:
        return text.replace('\n', ' ')
    return ''

def save_batch_to_csv(rows, batch_num, base_name='deepseek_output', output_dir='output'):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    filename = f'{base_name}_{timestamp}_batch{batch_num}.csv'
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch {batch_num} with {len(rows)} records to {filepath}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    batch_data = []
    batch_number = 1
    base_name = 'deepseek_output'
    output_dir = r'c:\test'  # ä¿®æ”¹æˆä½ æƒ³ä¿å­˜çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f'Content ({length} characters):\n')
                print(content)
                print('\n' + '='*100 + '\n')

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) &gt;= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name, output_dir)
                    batch_data.clear()
                    batch_number += 1

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name, output_dir)

    print('All tasks completed.')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[15/2028] Generating: æ¡ˆä»¶æ¡ˆä¾‹ - å…¬ç›Š - æƒ…æ„ŸåŒ–

Content (827 characters):

**A Beacon of Hope: The Power of Compassion in Legal Cases**    In the midst of cold courtrooms and rigid laws, some cases shine as reminders of humanityâ€™s warmth. Take the story of an elderly woman evicted unfairlyâ€”her plight moved strangers to crowdfund her legal fees. Or the pro bono lawyers who fought for a childâ€™s right to education against all odds. These stories arenâ€™t just about justice; theyâ€™re about hearts uniting to lift others up.    Every such case whispers a truth: the law is stronger when wrapped in kindness. Behind every docket number is a life, and behind every verdict, a chance to heal. Letâ€™s celebrate these unsung heroesâ€”the donors, volunteers, and advocatesâ€”who turn legal battles into triumphs of empathy. Because justice, when paired with love, doesnâ€™t just winâ€”it transforms.    (Characters: 598)
```
## Kimi 

-  [https://platform.moonshot.cn/console/api-keys](https://platform.moonshot.cn/console/api-keys)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# === æ¨¡å‹é€‰æ‹© ===
USE_MODEL = 'moonshot'

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆMoonshot ä¸­æ–‡ï¼‰===
client = OpenAI(
    api_key='sk-xxx',  # â† æ›¿æ¢ä¸ºä½ çš„ API Key
    base_url='https://api.moonshot.cn/v1'
)



model_name = 'kimi-k2-0711-preview'
system_prompt = (
    'ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/yu-yan-mo-xing--API--pi-liang-sheng-cheng-wen-ben.html</guid><pubDate>Thu, 24 Jul 2025 14:11:48 +0000</pubDate></item><item><title>ç­›å‡ºæ–‡ä»¶æŒ‡å®šæ¯”ä¾‹çš„æ–‡ä»¶</title><link>https://feeday.cn/post/shai-chu-wen-jian-zhi-ding-bi-li-de-wen-jian.html</link><description>ç­›å‡ºæ–‡ä»¶æŒ‡å®šæ¯”ä¾‹çš„æ–‡ä»¶
```
import os
import shutil
import random

# è®¾ç½®æºç›®å½•å’Œç›®æ ‡ç›®å½•
source_dir = r'G:\trian'
target_dir = r'G:\test'
move_percent = 10  # ç™¾åˆ†æ¯”

# éå†ä¸€çº§å­æ–‡ä»¶å¤¹
for subfolder in os.listdir(source_dir):
    subfolder_path = os.path.join(source_dir, subfolder)
    if not os.path.isdir(subfolder_path):
        continue  # è·³è¿‡éæ–‡ä»¶å¤¹é¡¹

    # æ”¶é›†è¯¥å­æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼ˆé€’å½’ï¼‰
    all_files = []
    for root, _, files in os.walk(subfolder_path):
        for file in files:
            full_path = os.path.join(root, file)
            all_files.append(full_path)

    # éšæœºé€‰å–ç™¾åˆ†æ¯”æ–‡ä»¶
    total = len(all_files)
    if total == 0:
        continue

    move_count = max(1, int(total * move_percent / 100))
    selected_files = random.sample(all_files, move_count)

    # æ‰§è¡Œç§»åŠ¨
    for file_path in selected_files:
        rel_path = os.path.relpath(file_path, source_dir)
        dest_path = os.path.join(target_dir, rel_path)
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
        shutil.move(file_path, dest_path)
        print(f'Moved: {file_path} â†’ {dest_path}')

print(f'\nâœ… æ¯ä¸ªå­æ–‡ä»¶å¤¹å·²éšæœºç§»åŠ¨çº¦ {move_percent}% æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shai-chu-wen-jian-zhi-ding-bi-li-de-wen-jian.html</guid><pubDate>Wed, 23 Jul 2025 04:51:37 +0000</pubDate></item><item><title>è§†é¢‘æå–å›¾åƒ</title><link>https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</link><description>è§†é¢‘æå–å›¾åƒ
```
import cv2
import os

def extract_frames(video_path, output_folder):
    # è·å–è§†é¢‘æ–‡ä»¶åå¹¶ç”¨ä½œè¾“å‡ºæ–‡ä»¶å¤¹çš„åç§°ï¼ˆå»æ‰æ‰©å±•åï¼‰
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    video_output_folder = os.path.join(output_folder, video_name)
    
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(video_output_folder, exist_ok=True)

    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f'æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼š{video_path}')
        return

    # è·å–è§†é¢‘çš„å¸§ç‡ï¼ˆFPSï¼‰
    fps = cap.get(cv2.CAP_PROP_FPS)
    print(f'è§†é¢‘å¸§ç‡ï¼š{fps} FPS')

    # è·å–è§†é¢‘çš„æ€»å¸§æ•°
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f'è§†é¢‘æ€»å¸§æ•°ï¼š{total_frames}')

    # éå†è§†é¢‘ä¸­çš„æ¯ä¸€å¸§
    for frame_num in range(total_frames):
        ret, frame = cap.read()
        if not ret:
            print(f'æ— æ³•è¯»å–ç¬¬ {frame_num} å¸§')
            break

        # æ¯ç§’æå–ä¸€å¸§
        if frame_num % int(fps) == 0:
            # è·å–å½“å‰å¸§çš„æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            timestamp = frame_num // int(fps)
            # æ„é€ è¾“å‡ºå›¾åƒçš„æ–‡ä»¶è·¯å¾„
            output_path = os.path.join(video_output_folder, f'frame_{timestamp:04d}.jpg')
            # ä¿å­˜å½“å‰å¸§ä¸ºå›¾åƒæ–‡ä»¶
            if frame is not None:
                cv2.imwrite(output_path, frame)
                print(f'å·²ä¿å­˜ï¼š{output_path}')
            else:
                print(f'ç¬¬ {timestamp} ç§’å›¾åƒä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</guid><pubDate>Wed, 23 Jul 2025 04:50:00 +0000</pubDate></item><item><title>ç­›æŸ¥é‡å¤æˆ–ç±»ä¼¼å›¾åƒ</title><link>https://feeday.cn/post/shai-cha-zhong-fu-huo-lei-si-tu-xiang.html</link><description>ç­›æŸ¥é‡å¤æˆ–ç±»ä¼¼å›¾åƒ
```
import subprocess
import sys
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input
from sklearn.metrics.pairwise import cosine_similarity  # ç”¨äºä½™å¼¦ç›¸ä¼¼åº¦

# pip å®‰è£… scikit-learn
def install_package(package):
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])
        print(f'{package} å®‰è£…æˆåŠŸï¼')
    except subprocess.CalledProcessError as e:
        print(f'å®‰è£…å¤±è´¥: {e}')

# ç¡®ä¿å®‰è£… scikit-learn
install_package('scikit-learn')

# æå–å›¾ç‰‡ç‰¹å¾
def extract_image_features(image_path):
    if not os.path.exists(image_path):  # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        print(f'æ–‡ä»¶ä¸å­˜åœ¨: {image_path}')
        return None
    
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    if image is None:  # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦åŠ è½½æˆåŠŸ
        print(f'æ— æ³•è¯»å–å›¾ç‰‡: {image_path}')
        return None  # å¦‚æœè¯»å–å¤±è´¥ï¼Œè¿”å›None
    image = cv2.resize(image, (256, 256))  # ç¼©æ”¾å›¾ç‰‡åˆ°ç»Ÿä¸€å°ºå¯¸
    image = image[16:240, 16:240]  # è£å‰ªä¸­é—´åŒºåŸŸ(224x224)
    
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥è¦æ±‚
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
    
    print(f'ç‰¹å¾å‘é‡: {features.flatten()}')  # æ‰“å°ç‰¹å¾å‘é‡ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰å·®å¼‚
    return features.flatten()  # å¹³é“ºç‰¹å¾å‘é‡

# ç§»åŠ¨é‡å¤å›¾ç‰‡åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
def move_duplicate_images(directory, output_directory, use_cosine_similarity=True):
    current_dir = directory  # ä½¿ç”¨ä¼ å…¥çš„ç›®å½•è·¯å¾„
    files = [f for f in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, f))]  # è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
    
    image_features = {}
    moved_count = 0  # è®°å½•ç§»åŠ¨çš„å›¾ç‰‡æ•°é‡
    duplicate_pairs = []  # ç”¨äºä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶åå¯¹

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(output_directory):  # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºå®ƒ
        os.makedirs(output_directory)

    for file_name in files:
        if file_name.endswith('.jpg') or file_name.endswith('.png'):  # ç­›é€‰å‡ºå›¾ç‰‡æ–‡ä»¶
            file_path = os.path.join(current_dir, file_name)
            image_feature = extract_image_features(file_path)

            if image_feature is None:  # å¦‚æœè¯»å–å¤±è´¥ï¼Œè·³è¿‡æ­¤æ–‡ä»¶
                continue

            is_duplicate = False
            for existing_path, existing_feature in image_features.items():
                if use_cosine_similarity:
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—ç›¸ä¼¼åº¦
                    similarity = cosine_similarity([existing_feature], [image_feature])[0][0]
                    print(f'è®¡ç®—ç›¸ä¼¼åº¦: {similarity}')  # æ‰“å°è®¡ç®—å‡ºçš„ç›¸ä¼¼åº¦

                    if similarity &gt; 0.8:  # è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå€¼è¶Šæ¥è¿‘1è¯´æ˜è¶Šç›¸ä¼¼
                        is_duplicate = True
                        print(f'ç§»åŠ¨é‡å¤å›¾ç‰‡: {file_path}')
                        # ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                        new_path = os.path.join(output_directory, file_name)
                        os.rename(file_path, new_path)  # ç§»åŠ¨æ–‡ä»¶
                        moved_count += 1
                        # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                        duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                        break
                else:
                    # ä½¿ç”¨æ¬§æ°è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
                    distance = np.linalg.norm(existing_feature - image_feature)  # è®¡ç®—æ¬§æ°è·ç¦»
                    print(f'è®¡ç®—è·ç¦»: {distance}')  # æ‰“å°è®¡ç®—å‡ºçš„æ¬§æ°è·ç¦»
                    if distance &lt; 0.6:  # åˆ é™¤ç±»ä¼¼å›¾åƒ 0.6  åˆ é™¤é‡å¤å›¾åƒ 0.1
                        is_duplicate = True
                        print(f'ç§»åŠ¨é‡å¤å›¾ç‰‡: {file_path}')
                        # ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                        new_path = os.path.join(output_directory, file_name)
                        os.rename(file_path, new_path)  # ç§»åŠ¨æ–‡ä»¶
                        moved_count += 1
                        # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                        duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                        break

            if not is_duplicate:
                image_features[file_path] = image_feature

    # å°†é‡å¤å›¾ç‰‡æ–‡ä»¶åå¯¹ä¿å­˜åˆ°txtæ–‡ä»¶
    output_file = os.path.join(output_directory, 'duplicate_images.txt')  # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
    if duplicate_pairs:
        with open(output_file, 'w') as f:
            for file1, file2 in duplicate_pairs:
                f.write(f'{file1} ä¸ {file2} é‡å¤æˆ–ç±»ä¼¼\n')

    print('å·²ç§»åŠ¨ {} å¼ é‡å¤å›¾ç‰‡'.format(moved_count))

# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = ResNet50(weights='imagenet', include_top=False, pooling='avg')

# æŒ‡å®šç›®å½•è·¯å¾„ï¼Œè®¾ç½®æ˜¯å¦ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
input_directory = r'D:\test\img'  # å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹
output_directory = r'D:\test\img2'  # è‡ªå®šä¹‰ä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶å¤¹

move_duplicate_images(input_directory, output_directory, use_cosine_similarity=False)  # è®¾ç½®ä¸ºTrueä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åˆ¤æ–­ä¸¤ä¸ªå›¾ç‰‡çš„ç‰¹å¾æ–¹å‘æ˜¯å¦ç›¸ä¼¼ï¼Œè®¾ç½®ä¸ºFalseç§»é™¤é‡å¤å›¾åƒ
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shai-cha-zhong-fu-huo-lei-si-tu-xiang.html</guid><pubDate>Wed, 23 Jul 2025 04:47:45 +0000</pubDate></item><item><title>å›¾åƒç›´æ–¹å›¾åœ¨çº¿è°ƒèŠ‚</title><link>https://feeday.cn/post/tu-xiang-zhi-fang-tu-zai-xian-diao-jie.html</link><description>```
&lt;!DOCTYPE html&gt;
&lt;html lang='zh-CN'&gt;
&lt;head&gt;
&lt;meta charset='UTF-8'&gt;
&lt;title&gt;åœ¨çº¿å›¾åƒç›´æ–¹å›¾ä¸è°ƒæ•´&lt;/title&gt;
&lt;style&gt;
body { font-family: sans-serif; padding: 20px; max-width: 1000px; margin: auto; }
#controls { display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px; margin-bottom: 20px; }
.control-group { display: flex; align-items: center; }
.control-group label { width: 80px; }
.control-group input[type=range] { flex: 1; margin: 0 10px; }
.control-group input[type=number] { width: 60px; }
canvas { border: 1px solid #ccc; display: block; margin-bottom: 20px; }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h2&gt;åœ¨çº¿å›¾åƒç›´æ–¹å›¾ä¸è°ƒæ•´&lt;/h2&gt;
&lt;input type='file' id='fileInput' accept='image/*'&gt;
&lt;div id='controls'&gt;
&lt;div class='control-group'&gt;
&lt;label for='exposureRange'&gt;æ›å…‰&lt;/label&gt;
&lt;input type='range' id='exposureRange' min='-2' max='2' step='0.1' value='0'&gt;
&lt;input type='number' id='exposureNumber' min='-2' max='2' step='0.1' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='contrastRange'&gt;å¯¹æ¯”åº¦&lt;/label&gt;
&lt;input type='range' id='contrastRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='contrastNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='highlightsRange'&gt;é«˜å…‰&lt;/label&gt;
&lt;input type='range' id='highlightsRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='highlightsNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='shadowsRange'&gt;é˜´å½±&lt;/label&gt;
&lt;input type='range' id='shadowsRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='shadowsNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='whitesRange'&gt;ç™½è‰²&lt;/label&gt;
&lt;input type='range' id='whitesRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='whitesNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;div class='control-group'&gt;
&lt;label for='blacksRange'&gt;é»‘è‰²&lt;/label&gt;
&lt;input type='range' id='blacksRange' min='-1' max='1' step='0.05' value='0'&gt;
&lt;input type='number' id='blacksNumber' min='-1' max='1' step='0.05' value='0'&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;canvas id='previewCanvas' width='800' height='600'&gt;&lt;/canvas&gt;
&lt;canvas id='histCanvas' width='800' height='200'&gt;&lt;/canvas&gt;

&lt;!-- å¼•å…¥ Chart.js --&gt;
&lt;script src='https://cdn.jsdelivr.net/npm/chart.js'&gt;&lt;/script&gt;
&lt;script&gt;
let originalImageData = null;
const previewCanvas = document.getElementById('previewCanvas');
const previewCtx = previewCanvas.getContext('2d');
const histCanvas = document.getElementById('histCanvas');
const histCtx = histCanvas.getContext('2d');
let histChart = null;

// è¯»å–æ§ä»¶å…ƒç´ 
const controls = ['exposure','contrast','highlights','shadows','whites','blacks'];
const state = {};
controls.forEach(name =&gt; {
state[name] = 0;
const rangeEl = document.getElementById(name + 'Range');
const numEl = document.getElementById(name + 'Number');
// åŒæ­¥æ»‘å—å’Œæ•°å­—
rangeEl.addEventListener('input', () =&gt; { numEl.value = rangeEl.value; updateState(); });
numEl.addEventListener('input', () =&gt; { rangeEl.value = numEl.value; updateState(); });
});

document.getElementById('fileInput').addEventListener('change', (e) =&gt; {
const file = e.target.files[0];
if (!file) return;
const img = new Image();
img.onload = () =&gt; {
// è°ƒæ•´ç”»å¸ƒå¤§å°
previewCanvas.width = img.width;
previewCanvas.height = img.height;
previewCtx.drawImage(img, 0, 0);
originalImageData = previewCtx.getImageData(0, 0, img.width, img.height);
applyAdjustments();
};
img.src = URL.createObjectURL(file);
});

function updateState() {
controls.forEach(name =&gt; {
state[name] = parseFloat(document.getElementById(name + 'Number').value);
});
applyAdjustments();
}

function applyAdjustments() {
if (!originalImageData) return;
const imgData = new ImageData(
new Uint8ClampedArray(originalImageData.data),
originalImageData.width,
originalImageData.height
);
const data = imgData.data;
const {exposure, contrast, highlights, shadows, whites, blacks} = state;
for (let i = 0; i &lt; data.length; i += 4) {
let r = data[i] / 255;
let g = data[i+1] / 255;
let b = data[i+2] / 255;
// äº®åº¦
const lum = 0.2126*r + 0.7152*g + 0.0722*b;
// æ›å…‰ï¼š2^EV
const evFactor = Math.pow(2, exposure);
r *= evFactor; g *= evFactor; b *= evFactor;
// å¯¹æ¯”åº¦
const cFactor = contrast + 1;
r = (r - 0.5) * cFactor + 0.5;
g = (g - 0.5) * cFactor + 0.5;
b = (b - 0.5) * cFactor + 0.5;
// é«˜å…‰/é˜´å½±
if (lum &gt; 0.5) {
const factor = (lum - 0.5) * 2;
r += highlights * factor;
g += highlights * factor;
b += highlights * factor;
} else {
const factor = (0.5 - lum) * 2;
r += shadows * factor;
g += shadows * factor;
b += shadows * factor;
}
// ç™½è‰²/é»‘è‰²å‰ªåˆ‡
if (lum &gt; 0.8) {
const factor = (lum - 0.8) * 5;
r += whites * factor; g += whites * factor; b += whites * factor;
}
if (lum &lt; 0.2) {
const factor = (0.2 - lum) * 5;
r -= blacks * factor; g -= blacks * factor; b -= blacks * factor;
}
// é™å¹…
data[i]   = Math.min(255, Math.max(0, r * 255));
data[i+1] = Math.min(255, Math.max(0, g * 255));
data[i+2] = Math.min(255, Math.max(0, b * 255));
}
// æ›´æ–°é¢„è§ˆ
previewCtx.putImageData(imgData, 0, 0);
updateHistogram(imgData);
}

function updateHistogram(imageData) {
const bins = 256;
const counts = new Array(bins).fill(0);
const data = imageData.data;
for (let i = 0; i &lt; data.length; i += 4) {
// ç°åº¦å€¼
const lum = Math.round(0.299*data[i] + 0.587*data[i+1] + 0.114*data[i+2]);
counts[lum]++;
}
const labels = counts.map((_,i) =&gt; i);
if (!histChart) {
histChart = new Chart(histCtx, {
type: 'bar',
data: {
labels,
datasets: [{ label: 'åƒç´ æ•°', data: counts, backgroundColor: 'rgba(0,0,0,0.5)' }]
},
options: {
responsive: true,
scales: { x: { display: false }, y: { beginAtZero: true } },
plugins: { legend: { display: false } }
}
});
} else {
histChart.data.datasets[0].data = counts;
histChart.update();
}
}
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
````ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tu-xiang-zhi-fang-tu-zai-xian-diao-jie.html</guid><pubDate>Sun, 20 Jul 2025 04:49:40 +0000</pubDate></item><item><title>å›¾åƒåˆ†ç±»è„šæœ¬</title><link>https://feeday.cn/post/tu-xiang-fen-lei-jiao-ben.html</link><description>## ResNet50
```
import subprocess
import sys

# è‡ªåŠ¨å®‰è£…ä¾èµ–
def install_packages():
    packages = ['torch', 'torchvision', 'pillow', 'pandas', 'openpyxl', 'requests']
    for pkg in packages:
        try:
            __import__(pkg)
        except ImportError:
            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])

install_packages()

# === å¯¼å…¥ä¾èµ– ===
import os
import shutil
import torch
from torchvision import models, transforms
from PIL import Image
import pandas as pd
from collections import defaultdict
import requests

# === å›¾åƒé¢„å¤„ç†ï¼ˆImageNetï¼‰===
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# === åŠ è½½ ResNet50 æ¨¡å‹ ===
model = models.resnet50(pretrained=True)
model.eval()

# === åŠ è½½ç±»åˆ«æ ‡ç­¾ ===
# https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt

LABELS_PATH = r'g:\Dataset\Image\COCO_Annotations\imagenet_classes.txt'
with open(LABELS_PATH, 'r', encoding='utf-8') as f:
    labels = f.read().strip().split('\n')


# === å•å¼ å›¾åƒåˆ†ç±» ===
def classify_image(image_path):
    image = Image.open(image_path).convert('RGB')
    input_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.nn.functional.softmax(output[0], dim=0)
        top1_prob, top1_class = torch.topk(probs, 1)
    return labels[top1_class.item()], top1_prob.item()

# === åˆ†ç±»ä¸»æµç¨‹ ===
def organize_images_by_class(src_dir, dst_dir):
    records = []
    class_counts = defaultdict(int)

    for fname in os.listdir(src_dir):
        if not fname.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.png')):
            continue

        img_path = os.path.join(src_dir, fname)
        predicted_class, prob = classify_image(img_path)
        class_folder = os.path.join(dst_dir, predicted_class)
        os.makedirs(class_folder, exist_ok=True)

        shutil.copy(img_path, os.path.join(class_folder, fname))
        records.append({
            'æ–‡ä»¶å': fname,
            'é¢„æµ‹ç±»åˆ«': predicted_class,
            'ç½®ä¿¡åº¦': round(prob, 4)
        })
        class_counts[predicted_class] += 1

    # ä¿å­˜ç»“æœåˆ° Excel
    df = pd.DataFrame(records)
    count_df = pd.DataFrame([
        {'é¢„æµ‹ç±»åˆ«': k, 'å›¾ç‰‡æ•°é‡': v}
        for k, v in sorted(class_counts.items(), key=lambda x: -x[1])
    ])
    output_excel = os.path.join(dst_dir, 'result.xlsx')
    with pd.ExcelWriter(output_excel) as writer:
        df.to_excel(writer, index=False, sheet_name='åˆ†ç±»ç»“æœ')
        count_df.to_excel(writer, index=False, sheet_name='ç±»åˆ«æ±‡æ€»')

    print(f'\nâœ… åˆ†ç±»å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ {output_excel}')
    print(f'ğŸ“ åˆ†ç±»åçš„æ–‡ä»¶ä½äº: {dst_dir}')

# === å‘½ä»¤è¡Œå…¥å£ ===
if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(description='å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»å¹¶å¤åˆ¶åˆ°å¯¹åº”ç±»åˆ«ç›®å½•')
    parser.add_argument('--src', default=r'G:\Dataset\Image\images', help='åŸå§‹å›¾åƒè·¯å¾„')
    parser.add_argument('--dst', default=r'G:\Dataset\Image\tag', help='åˆ†ç±»ç»“æœä¿å­˜è·¯å¾„')
    args = parser.parse_args()

    organize_images_by_class(args.src, args.dst)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tu-xiang-fen-lei-jiao-ben.html</guid><pubDate>Sun, 20 Jul 2025 04:49:00 +0000</pubDate></item><item><title>typecho å¯†ç å¿˜è®°å¯†ç  sqlite æ•°æ®åº“</title><link>https://feeday.cn/post/typecho%20-mi-ma-wang-ji-mi-ma-%20sqlite%20-shu-ju-ku.html</link><description>åšå®¢å¿˜è®°äº†å¯†ç å¯ä»¥ç”¨ä»¥ä¸‹æ–¹æ³•æ‰¾å›å¯†ç ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/typecho%20-mi-ma-wang-ji-mi-ma-%20sqlite%20-shu-ju-ku.html</guid><pubDate>Sun, 20 Jul 2025 04:48:22 +0000</pubDate></item><item><title>åœ¨çº¿æ–‡ä»¶åŠ å¯†è§£å¯†</title><link>https://feeday.cn/post/zai-xian-wen-jian-jia-mi-jie-mi.html</link><description>huggingface  spaces gradio

## requirements.txt
```
gradio
cryptography
```

## app.py

```
import gradio as gr
from cryptography.fernet import Fernet
import os

# AES åŠ å¯†å‡½æ•°ï¼ˆFernet å®ç°ï¼‰
def encrypt_file_gr(file):
    file_path = file.name
    key = Fernet.generate_key()
    cipher = Fernet(key)
    with open(file_path, 'rb') as f:
        data = f.read()
    encrypted_data = cipher.encrypt(data)
    enc_path = file_path + '.enc'
    with open(enc_path, 'wb') as f:
        f.write(encrypted_data)
    return key.decode(), enc_path

# AES è§£å¯†å‡½æ•°ï¼Œæ¢å¤åŸå§‹æ–‡ä»¶åå’Œæ ¼å¼
def decrypt_file_gr(file, key):
    file_path = file.name
    cipher = Fernet(key.encode())
    try:
        with open(file_path, 'rb') as f:
            encrypted_data = f.read()
        decrypted_data = cipher.decrypt(encrypted_data)
        # å»æ‰ .enc åç¼€ï¼Œæ¢å¤åŸå§‹æ–‡ä»¶å
        if file_path.lower().endswith('.enc'):
            dec_path = file_path[:-4]
        else:
            dec_path = file_path + '.dec'
        with open(dec_path, 'wb') as f:
            f.write(decrypted_data)
        return dec_path
    except Exception:
        return None

# Gradio ç•Œé¢è®¾è®¡
with gr.Blocks() as demo:
    gr.Markdown('# æ–‡ä»¶åŠ å¯†è§£å¯†å·¥å…·')

    with gr.Tab('åŠ å¯†'):
        encrypt_in = gr.File(label='ä¸Šä¼ æ–‡ä»¶')
        encrypt_btn = gr.Button('åŠ å¯†æ–‡ä»¶ ğŸ”’')
        # æ–‡æœ¬æ¡†æ˜¾ç¤ºå¯†é’¥å¹¶æä¾›å¤åˆ¶æŒ‰é’®
        encrypt_key = gr.Textbox(label='ç”Ÿæˆçš„å¯†é’¥', interactive=False, show_copy_button=True)
        encrypt_out = gr.File(label='ä¸‹è½½åŠ å¯†æ–‡ä»¶ (.enc)')
        encrypt_btn.click(
            fn=encrypt_file_gr,
            inputs=encrypt_in,
            outputs=[encrypt_key, encrypt_out]
        )

    with gr.Tab('è§£å¯†'):
        decrypt_in = gr.File(label='ä¸Šä¼ åŠ å¯†æ–‡ä»¶ (.enc)')
        decrypt_key_in = gr.Textbox(label='è¾“å…¥å¯†é’¥')
        decrypt_btn = gr.Button('è§£å¯†æ–‡ä»¶ ğŸ”“')
        decrypt_out = gr.File(label='ä¸‹è½½è§£å¯†æ–‡ä»¶ï¼ˆåŸå§‹æ ¼å¼ï¼‰')
        decrypt_btn.click(
            fn=decrypt_file_gr,
            inputs=[decrypt_in, decrypt_key_in],
            outputs=decrypt_out
        )

if __name__ == '__main__':
    demo.launch()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/zai-xian-wen-jian-jia-mi-jie-mi.html</guid><pubDate>Sun, 20 Jul 2025 04:47:52 +0000</pubDate></item><item><title>è§†é¢‘æå–å›¾åƒ</title><link>https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</link><description>```
import os
import cv2
from pathlib import Path

# æŒ‡å®šè§†é¢‘æ‰€åœ¨ç›®å½•
video_dir = r'c:\video'  # ä¿®æ”¹ä¸ºä½ çš„è§†é¢‘ç›®å½•
output_dir = r'c:\img'  # ä¿å­˜å›¾ç‰‡çš„ç›®å½•

# æ¯ç§’æå–å¸§æ•°
frames_per_second = 1  # æ¯ç§’æå–1å¸§

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
Path(output_dir).mkdir(parents=True, exist_ok=True)

# éå†æŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
for filename in os.listdir(video_dir):
    if filename.endswith(('.mp4', '.avi', '.mov', '.mkv')):  # æ ¹æ®è§†é¢‘æ ¼å¼è°ƒæ•´
        video_path = os.path.join(video_dir, filename)

        # ä½¿ç”¨ OpenCV æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(video_path)

        # è·å–è§†é¢‘çš„å¸§ç‡
        fps = cap.get(cv2.CAP_PROP_FPS)
        print(f'è§†é¢‘ {filename} çš„å¸§ç‡: {fps} å¸§/ç§’')

        frame_count = 0
        saved_frame_count = 0

        while True:
            ret, frame = cap.read()

            # å¦‚æœè¯»å–æˆåŠŸ
            if ret:
                frame_count += 1

                # æ¯éš”ä¸€å®šå¸§æ•°ï¼ˆæ ¹æ®fpsè®¡ç®—æ¯ç§’æå–1å¸§ï¼‰
                if frame_count % int(fps / frames_per_second) == 0:
                    # ä½¿ç”¨ pathlib å¤„ç†è·¯å¾„å’Œæ–‡ä»¶å
                    image_filename = Path(filename).stem + f'_{saved_frame_count + 1}.jpg'
                    image_path = Path(output_dir) / image_filename

                    # ä¿å­˜å›¾ç‰‡
                    cv2.imwrite(str(image_path), frame)
                    saved_frame_count += 1
                    print(f'ä¿å­˜å›¾ç‰‡ï¼š{image_path}')
            else:
                break  # å¦‚æœæ²¡æœ‰æ›´å¤šå¸§å¯è¯»å–ï¼Œè·³å‡ºå¾ªç¯

        # é‡Šæ”¾è§†é¢‘å¯¹è±¡
        cap.release()

print('æ‰€æœ‰è§†é¢‘çš„å¸§æå–å®Œæ¯•ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shi-pin-ti-qu-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:47:14 +0000</pubDate></item><item><title>å¯¼å‡ºdocxæ–‡æ¡£é‡Œçš„å›¾åƒ</title><link>https://feeday.cn/post/dao-chu-docx-wen-dang-li-de-tu-xiang.html</link><description>## æ‰§è¡Œç»“æœ
```
f:/doc/
â”‚
â”œâ”€â”€ document1.docx
â”œâ”€â”€ document2.docx
â””â”€â”€ document3.docx
```

```
f:/doc/png/
â”‚
â”œâ”€â”€ document1/
â”‚   â”œâ”€â”€ document1.txt      # Contains the extracted text (e.g., 'å›¾ç‰‡ç®€ä»‹ï¼šdescription text')
â”‚   â”œâ”€â”€ document1_000001.png  # Image extracted from the document, renamed based on the corresponding text
â”‚   â”œâ”€â”€ document1_000002.png  # Another image
â”‚   â””â”€â”€ document1_000003.png  # Another image
â”‚
â”œâ”€â”€ document2/
â”‚   â”œâ”€â”€ document2.txt
â”‚   â”œâ”€â”€ document2_000001.png
â”‚   â”œâ”€â”€ document2_000002.png
â”‚   â””â”€â”€ document2_000003.png
â”‚
â””â”€â”€ document3/
    â”œâ”€â”€ document3.txt
    â”œâ”€â”€ document3_000001.png
    â”œâ”€â”€ document3_000002.png
    â””â”€â”€ document3_000003.png
```


##  å®Œæ•´ä»£ç 
```
from docx import Document
import os
import re
import shutil
 
# pip install python-docx
# pip install lxml  # é€šå¸¸ä¸å¿…éœ€ï¼Œé™¤éåœ¨å®‰è£… python-docx åå‡ºç°é—®é¢˜
 
 
def get_picture(document, paragraph):
    '''
    ä»æ®µè½ä¸­è·å–å›¾ç‰‡
    '''
    img = paragraph._element.xpath('.//pic:pic')
    if not img:
        return None
    img = img[0]
    embed = img.xpath('.//a:blip/@r:embed')[0]
    related_part = document.part.related_parts[embed]
    image = related_part.image
    return image
 
def extract_content(docx_path, output_dir):
    try:
        doc = Document(docx_path)
        base_filename = os.path.splitext(os.path.basename(docx_path))[0]
        doc_output_dir = os.path.join(output_dir, base_filename)
        os.makedirs(doc_output_dir, exist_ok=True)
        shutil.copy(docx_path, doc_output_dir)
 
        extracted_text = []
        extracted_images = []
 
        for para in doc.paragraphs:
            match = re.search(r'å›¾ç‰‡ç®€ä»‹ï¼š(.*)', para.text)
            if match:
                violation_text = match.group(1).strip() if match.group(1).strip() else 'XXX'
                extracted_text.append(violation_text)
 
            image = get_picture(doc, para)
            if image:
                blob = image.blob
                image_index = len(extracted_images) + 1
                formatted_index = f'{image_index:06d}'
                img_path = os.path.join(doc_output_dir, f'{base_filename}_{formatted_index}.png')
                extracted_images.append(img_path)
                with open(img_path, 'wb') as f:
                    f.write(blob)
 
        if extracted_text:
            text_filename = f'{base_filename}.txt'
            text_path = os.path.join(doc_output_dir, text_filename)
            with open(text_path, 'w', encoding='utf-8') as text_file:
                text_file.write('\n'.join(extracted_text))
            rename_images_based_on_text(doc_output_dir, text_path, extracted_images)
 
    except Exception as e:
        print(f'Error processing {docx_path}: {e}')
 
def rename_images_based_on_text(output_dir, text_file_path, extracted_images):
    with open(text_file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
 
    if len(extracted_images) != len(lines):
        print(f'Error: The number of images ({len(extracted_images)}) and text lines ({len(lines)}) do not match in {output_dir}.')
        return
 
    for image_path, line in zip(extracted_images, lines):
        new_image_name = f'{os.path.splitext(image_path)[0]}_{line.strip()}{os.path.splitext(image_path)[1]}'
        os.rename(image_path, new_image_name)
        print(f'Renamed '{image_path}' to '{new_image_name}'')
 
def process_documents(folder_path, output_folder):
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    for filename in os.listdir(folder_path):
        if filename.endswith('.docx') or filename.endswith('.doc'):
            docx_path = os.path.join(folder_path, filename)
            extract_content(docx_path, output_folder)
 
# ç¤ºä¾‹ç”¨æ³•
folder_path = 'f:/doc'
output_folder = 'f:/doc/png'
process_documents(folder_path, output_folder)
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/dao-chu-docx-wen-dang-li-de-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:46:40 +0000</pubDate></item><item><title>åˆ›å»ºæŒ‡å®šå¤§å°æ–‡ä»¶</title><link>https://feeday.cn/post/chuang-jian-zhi-ding-da-xiao-wen-jian.html</link><description>è¿è¡Œ cmd æ‰§è¡Œåˆ›å»ºæ–‡æœ¬æ–‡ä»¶

```
fsutil file createnew f:\1GB.txt 1073741824
```

æ¢ç®—å•ä½

```
byte (B):1073741824
kilobyte (kB):1048576
megabyte (MB):1024
gigabyte (GB):	1
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/chuang-jian-zhi-ding-da-xiao-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:46:02 +0000</pubDate></item><item><title>è·å–ç½‘é¡µé“¾æ¥</title><link>https://feeday.cn/post/huo-qu-wang-ye-lian-jie.html</link><description>æ§åˆ¶å°æµè§ˆå™¨è·å–ç½‘å€

## bilibili
```
const links = document.getElementsByTagName('a');
// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é…çš„ç½‘å€
for (const link of links) {
  const href = link.href;
  // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç±»ä¼¼çš„ç½‘å€
  const urlRegex = /https:\/\/www\.bilibili\.com\/video\/[A-Za-z0-9]+\/?/;
  if (urlRegex.test(href)) {
    console.log('åŒ¹é…åˆ°çš„ç½‘å€: ' + href);
  }
}
```

## youtube

```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é…çš„ç½‘å€
for (const link of links) {
  const href = link.href;
  // ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… YouTube è§†é¢‘é“¾æ¥
  const urlRegex = /https:\/\/www\.youtube\.com\/watch\?v=[A-Za-z0-9_-]+/;
  if (urlRegex.test(href)) {
    console.log('åŒ¹é…åˆ°çš„ç½‘å€: ' + href);
  }
}
```
## dataset
```
const links = document.getElementsByTagName('a');

// éå†æ‰€æœ‰é“¾æ¥å¹¶æŸ¥æ‰¾åŒ¹é… Hugging Face blob åœ°å€
for (const link of links) {
  const href = link.href;
  // åŒ¹é… datasets ä»“åº“ blob é“¾æ¥
  const urlRegex = /^https:\/\/huggingface\.co\/datasets\/[^/]+\/[^/]+\/blob\/[^/]+\/.+$/;
  if (urlRegex.test(href)) {
    // æ›¿æ¢ blob â†’ resolve
    const realUrl = href.replace('/blob/', '/resolve/');
    console.log('ç›´é“¾: ' + realUrl);
  }
}
```
ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/huo-qu-wang-ye-lian-jie.html</guid><pubDate>Sun, 20 Jul 2025 04:45:35 +0000</pubDate></item><item><title>æŸ¥æ‰¾æ›¿æ¢</title><link>https://feeday.cn/post/cha-zhao-ti-huan.html</link><description>æœç´¢åŒ¹é…å½“å‰ç›®å½•ä¸‹æ‰€æœ‰[æ–‡ä»¶å]æˆ–æ–‡ä»¶é‡Œçš„å†…å®¹æ‰“å°æ˜¾ç¤ºè¡Œå·
```
grep -rn 'Money' *
```

æœç´¢å¤šä¸ªæ–‡ä»¶å¹¶æŸ¥æ‰¾åŒ¹é…æ–‡æœ¬åœ¨å“ªäº›æ–‡ä»¶ä¸­ï¼š
```
grep -l 'Money' file1 file2 file3...
```

æŸ¥æ‰¾ formatting.php æ–‡ä»¶å†… lengthâ€™, 55 æ›¿æ¢ lengthâ€™, 56 :
```
sed -i s/'length', 55'/'length', 56'/g `grep 'length', 55' -rl --include='formatting.php' ./`
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/cha-zhao-ti-huan.html</guid><pubDate>Sun, 20 Jul 2025 04:45:05 +0000</pubDate></item><item><title>ç§»åˆ°æ–‡ä»¶</title><link>https://feeday.cn/post/yi-dao-wen-jian.html</link><description>### æŒ‰ç…§æŒ‡å®šæ–‡ä»¶åç§»åˆ°æ–‡ä»¶

### ç®€ä»‹
å‡è®¾ç›®å½•ä¸æ–‡ä»¶å¦‚ä¸‹ï¼š
```
H:\
â”œâ”€ data
â”‚   â”œâ”€ report1.txt
â”‚   â”œâ”€ image_fail.png
â”‚   â””â”€ sub
â”‚       â””â”€ test_error.log
â”œâ”€ list.txt
â””â”€ copy    ï¼ˆåˆå§‹ä¸ºç©ºï¼‰
```

list.txt å†…å®¹ï¼ˆæ¯è¡Œä¸€ä¸ªå…³é”®å­—ï¼‰
```
report
fail
missing
error
```

è¿è¡Œæ§åˆ¶å°è¾“å‡ºï¼š
```
âœ” å·²ç§»åŠ¨: 'report1.txt' å¯¹åº”å…³é”®å­— 'report' åˆ° 'H:\copy\report1.txt'
âœ” å·²ç§»åŠ¨: 'image_fail.png' å¯¹åº”å…³é”®å­— 'fail' åˆ° 'H:\copy\image_fail.png'
âš  æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶ for key: 'missing'
âœ” å·²ç§»åŠ¨: 'test_error.log' å¯¹åº”å…³é”®å­— 'error' åˆ° 'H:\copy\test_error.log'
 
å…± 4 ä¸ªå…³é”®å­—ï¼ŒæˆåŠŸç§»åŠ¨ 3 ä¸ªï¼Œå¯¹åº”æ–‡ä»¶ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/yi-dao-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:44:19 +0000</pubDate></item><item><title>åˆ é™¤é‡å¤å›¾åƒ</title><link>https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</link><description>```
import os
import cv2
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input
 
# pip install opencv-python numpy keras tensorflow
 
def extract_image_features(image_path):
    image = cv2.imread(image_path)  # è¯»å–å›¾ç‰‡
    image = cv2.resize(image, (256, 256))  # ç¼©æ”¾å›¾ç‰‡åˆ°ç»Ÿä¸€å°ºå¯¸
    image = image[16:240, 16:240]  # è£å‰ªä¸­é—´åŒºåŸŸ(224x224)
    
    image = np.expand_dims(image, axis=0)  # æ‰©å±•ç»´åº¦ä»¥åŒ¹é…æ¨¡å‹è¾“å…¥è¦æ±‚
    image = preprocess_input(image)  # é¢„å¤„ç†å›¾ç‰‡
    
    features = model.predict(image)  # æå–ç‰¹å¾å‘é‡
    features /= np.linalg.norm(features)  # å½’ä¸€åŒ–ç‰¹å¾å‘é‡
    
    return features.flatten()  # å¹³é“ºç‰¹å¾å‘é‡
 
def delete_duplicate_images():
    current_dir = os.getcwd()  # è·å–å½“å‰ç›®å½•è·¯å¾„
    files = [f for f in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, f))]  # è·å–å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
 
    image_features = {}
    deleted_count = 0  # è®°å½•åˆ é™¤çš„å›¾ç‰‡æ•°é‡
    duplicate_pairs = []  # ç”¨äºä¿å­˜é‡å¤å›¾ç‰‡çš„æ–‡ä»¶åå¯¹
 
    for file_name in files:
        if file_name.endswith('.jpg') or file_name.endswith('.png'):  # ç­›é€‰å‡ºå›¾ç‰‡æ–‡ä»¶
            file_path = os.path.join(current_dir, file_name)
            image_feature = extract_image_features(file_path)
 
            is_duplicate = False
            for existing_path, existing_feature in image_features.items():
                distance = np.linalg.norm(existing_feature - image_feature)  # è®¡ç®—æ¬§æ°è·ç¦»
                if distance &lt; 0.3:  # è®¾å®šé˜ˆå€¼æ¥åˆ¤æ–­ç›¸ä¼¼åº¦ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                    is_duplicate = True
                    print(f'åˆ é™¤é‡å¤å›¾ç‰‡: {file_path}')
                    os.remove(file_path)
                    deleted_count += 1
                    # è®°å½•é‡å¤çš„æ–‡ä»¶åå¯¹ (å½“å‰æ–‡ä»¶åå’Œå·²æœ‰æ–‡ä»¶å)
                    duplicate_pairs.append((file_name, os.path.basename(existing_path)))
                    break
 
            if not is_duplicate:
                image_features[file_path] = image_feature
 
    # å°†é‡å¤å›¾ç‰‡æ–‡ä»¶åå¯¹ä¿å­˜åˆ°txtæ–‡ä»¶
    if duplicate_pairs:
        with open('duplicate_images.txt', 'w') as f:
            for file1, file2 in duplicate_pairs:
                f.write(f'{file1} ä¸ {file2} é‡å¤\n')
    
    print('å·²åˆ é™¤ {} å¼ é‡å¤å›¾ç‰‡'.format(deleted_count))
 
# åŠ è½½é¢„è®­ç»ƒçš„ResNet50æ¨¡å‹
model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
 
delete_duplicate_images()
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/shan-chu-zhong-fu-tu-xiang.html</guid><pubDate>Sun, 20 Jul 2025 04:43:13 +0000</pubDate></item><item><title>md5å¤„ç†æ–‡ä»¶</title><link>https://feeday.cn/post/md5-chu-li-wen-jian.html</link><description>## åˆ é™¤MD5å€¼ç›¸åŒçš„æ–‡ä»¶

é€šè¿‡MD5å€¼æŠŠé‡å¤çš„æ–‡ä»¶ç§»åˆ°delæ–‡ä»¶å¤¹ï¼Œè¡¨æ ¼è®°å½•ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/md5-chu-li-wen-jian.html</guid><pubDate>Sun, 20 Jul 2025 04:42:26 +0000</pubDate></item><item><title>åŒæ­¥ä»£ç </title><link>https://feeday.cn/post/tong-bu-dai-ma.html</link><description>## å¸¸ç”¨çš„ Git å‘½ä»¤

æ›´æ–°ç«¯å£åˆ·æ–°DNS

```
git config --global http.proxy 127.0.0.1:7890
git config --global https.proxy 127.0.0.1:7890
ipconfig/flushdns
```
### ä»£ç ä»“åº“æ‹‰å–æ¨é€

- https://github.com/settings/ssh/new
- https://huggingface.co/settings/keys/add?type=ssh

æ‹‰å–ä»“åº“æœ¬åœ°åˆ°æœ¬åœ°æ¨é€åˆ°è¿œç¨‹ä»“åº“

```
git clone https://github.com/lllyasviel/Fooocus.git
git config --global user.email 'you@example.com'
git config --global user.name 'Your Name'
git remote set-url origin git@github.com:lllyasviel/Fooocus.git
ssh-keygen -t rsa -b 4096 -C 'your_email@example.com'
ssh -T git@github.com
git add . 
git commit -m 'Test' 
```

æœ¬åœ°æ¨é€åˆ°è¿œç¨‹ä»“åº“
```
git push origin main
```
è¿œç¨‹ä»“åº“åŒæ­¥åˆ°æœ¬åœ° 
```
git pull origin main  
```

### 1. **å…‹éš†è¿œç¨‹ä»“åº“**

å…‹éš†ä¸€ä¸ªè¿œç¨‹ä»“åº“åˆ°æœ¬åœ°ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

```bash
git clone https://github.com/lllyasviel/Fooocus.git
```

### 2. **æ£€æŸ¥å½“å‰ Git é…ç½®**

æŸ¥çœ‹ Git çš„å…¨å±€é…ç½®ï¼Œå¦‚ç”¨æˆ·åå’Œé‚®ç®±ï¼š

```bash
git config --list
```

### 3. **æ£€æŸ¥å½“å‰çŠ¶æ€**

æŸ¥çœ‹å½“å‰å·¥ä½œç›®å½•å’Œæš‚å­˜åŒºçš„çŠ¶æ€ï¼ˆå“ªäº›æ–‡ä»¶å·²ä¿®æ”¹ã€æœªè·Ÿè¸ªç­‰ï¼‰ï¼š

```bash
git status
```

### 4. **æ·»åŠ æ–‡ä»¶åˆ°æš‚å­˜åŒº**

å°†æ–‡ä»¶æ·»åŠ åˆ°æš‚å­˜åŒºï¼Œå‡†å¤‡æäº¤ï¼š

```bash
git add &lt;file_name&gt;  # æ·»åŠ æŒ‡å®šæ–‡ä»¶
git add .  # æ·»åŠ æ‰€æœ‰ä¿®æ”¹çš„æ–‡ä»¶
```

### 5. **æäº¤æ›´æ”¹**

æäº¤æ›´æ”¹å¹¶æ·»åŠ æäº¤ä¿¡æ¯ï¼š

```bash
git commit -m 'æè¿°æœ¬æ¬¡æäº¤çš„å†…å®¹'
```

### 6. **æ¨é€è¿œç¨‹ä»“åº“**

å°†æœ¬åœ°æ›´æ”¹æ¨é€åˆ°è¿œç¨‹ä»“åº“ï¼š

```bash
git push origin branch-name
```

### 7. **è¿œç¨‹ä»“åº“æ›´æ–°**

æ‹‰å–è¿œç¨‹ä»“åº“çš„æ›´æ–°ï¼Œå¹¶åˆå¹¶åˆ°å½“å‰åˆ†æ”¯ï¼š

```bash
git pull origin branch-name
```

### 8. **æŸ¥çœ‹è¿œç¨‹ä»“åº“ä¿¡æ¯**

æŸ¥çœ‹å½“å‰é¡¹ç›®çš„è¿œç¨‹ä»“åº“åœ°å€ï¼š

```bash
git remote -v
```

### 9. **æŸ¥çœ‹æäº¤å†å²**

æŸ¥çœ‹æäº¤å†å²è®°å½•ï¼š

```bash
git log
```

### 10. **åˆ›å»ºæ–°åˆ†æ”¯**

åˆ›å»ºä¸€ä¸ªæ–°åˆ†æ”¯ï¼Œå¹¶åˆ‡æ¢åˆ°è¯¥åˆ†æ”¯ï¼š

```bash
git checkout -b new-branch-name
```

### 11. **åˆ‡æ¢åˆ†æ”¯**

åˆ‡æ¢åˆ°å·²æœ‰çš„åˆ†æ”¯ï¼š

```bash
git checkout branch-name
```

### 12. **åˆå¹¶åˆ†æ”¯**

å°†å½“å‰åˆ†æ”¯åˆå¹¶åˆ°ç›®æ ‡åˆ†æ”¯ï¼š

```bash
git merge branch-name
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/tong-bu-dai-ma.html</guid><pubDate>Sun, 20 Jul 2025 04:41:37 +0000</pubDate></item><item><title>æŸ¥æ‰¾ä»£ç </title><link>https://feeday.cn/post/cha-zhao-dai-ma.html</link><description>## Windows æŸ¥æ‰¾
```
Get-ChildItem -Recurse -File | Select-String -Pattern '56'
```
## Bash æŸ¥æ‰¾
æœç´¢åŒ¹é…å½“å‰ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶åæˆ–æ–‡ä»¶é‡Œçš„å†…å®¹æ‰“å°æ˜¾ç¤ºè¡Œå·
```
grep -rn 'Money' *
```
æœç´¢å¤šä¸ªæ–‡ä»¶å¹¶æŸ¥æ‰¾åŒ¹é…æ–‡æœ¬åœ¨å“ªäº›æ–‡ä»¶ä¸­ï¼š
```
grep -l 'Money' file1 file2 file3...
```
æŸ¥æ‰¾ formatting.php æ–‡ä»¶å†… lengthâ€™, 55 æ›¿æ¢ lengthâ€™, 56 :

```
sed -i s/'length', 55'/'length', 56'/g `grep 'length', 55' -rl --include='formatting.php' ./`
```ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/cha-zhao-dai-ma.html</guid><pubDate>Sun, 20 Jul 2025 04:40:46 +0000</pubDate></item><item><title>NextChat</title><link>https://feeday.cn/post/NextChat.html</link><description>

âœ¨ Light and Fast AI Assistant,with Claude, DeepSeek, GPT4 &amp; Gemini Pro support. 


[NextChatAI](https://nextchat.club?utm_source=readme) / [Web App Demo](https://app.nextchat.dev) / [Desktop App](https://github.com/Yidadaa/ChatGPT-Next-Web/releases) / [Discord](https://discord.gg/YCkeafCafC) / [Enterprise Edition](#enterprise-edition) / [Twitter](https://twitter.com/NextChatDev)


[saas-url]: https://nextchat.club?utm_source=readme
[saas-image]: https://img.shields.io/badge/NextChat-Saas-green?logo=microsoftedge
[web-url]: https://app.nextchat.dev/
[download-url]: https://github.com/Yidadaa/ChatGPT-Next-Web/releases
[Web-image]: https://img.shields.io/badge/Web-PWA-orange?logo=microsoftedge
[Windows-image]: https://img.shields.io/badge/-Windows-blue?logo=windows
[MacOS-image]: https://img.shields.io/badge/-MacOS-black?logo=apple
[Linux-image]: https://img.shields.io/badge/-Linux-333?logo=ubuntu

[&lt;img src='https://zeabur.com/button.svg' alt='Deploy on Zeabur' height='30'&gt;](https://zeabur.com/templates/ZBUEFA) [&lt;img src='https://vercel.com/button' alt='Deploy on Vercel' height='30'&gt;](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2FChatGPTNextWeb%2FChatGPT-Next-Web&amp;env=OPENAI_API_KEY&amp;env=CODE&amp;project-name=nextchat&amp;repository-name=NextChat)  [&lt;img src='https://gitpod.io/button/open-in-gitpod.svg' alt='Open in Gitpod' height='30'&gt;](https://gitpod.io/#https://github.com/ChatGPTNextWeb/NextChat) 

[&lt;img src='https://github.com/user-attachments/assets/903482d4-3e87-4134-9af1-f2588fa90659' height='50' width='' &gt;](https://monica.im/?utm=nxcrp)



## Dokploy

Dokploy æ˜¯ä¸€ä¸ªå…è´¹çš„ã€å¯è‡ªæ‰˜ç®¡çš„å¹³å°å³æœåŠ¡ ï¼ˆPaaSï¼‰ï¼Œå¯ç®€åŒ–åº”ç”¨ç¨‹åºå’Œæ•°æ®åº“çš„éƒ¨ç½²å’Œç®¡ç†ã€‚</description><guid isPermaLink="true">https://feeday.cn/post/NextChat.html</guid><pubDate>Sat, 19 Jul 2025 20:47:38 +0000</pubDate></item><item><title>åˆ›å»ºåšå®¢</title><link>https://feeday.cn/post/chuang-jian-bo-ke.html</link><description>## å®‰è£…æ­¥éª¤

1. ã€åˆ›å»ºä»“åº“ã€‘ç‚¹å‡»[é€šè¿‡æ¨¡æ¿åˆ›å»ºä»“åº“](https://github.com/new?template_name=Gmeek-template&amp;template_owner=Meekdai)ï¼Œå»ºè®®ä»“åº“åç§°ä¸º`XXX.github.io`ï¼Œå…¶ä¸­`XXX`ä¸ºä½ çš„githubç”¨æˆ·åã€‚</description><guid isPermaLink="true">https://feeday.cn/post/chuang-jian-bo-ke.html</guid><pubDate>Sat, 19 Jul 2025 17:50:50 +0000</pubDate></item></channel></rss>
<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='/gmeek/GmeekVercount.js'></script>
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="æ–‡æœ¬æ¨¡å‹æ‰¹é‡ç”Ÿæˆæ–‡æœ¬æµ‹è¯•

## ChatGPT 

ç¬¬ä¸‰æ–¹ä»£ç†æ¥å£

-  [https://openkey.cloud](https://openkey.cloud/register?aff=22CVF)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key='sk-x',
    base_url='https://openkey.cloud/v1'
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

category_map = {
    'æ¡ˆä»¶æ¡ˆä¾‹': 'Case Study',
    'åšå®¢æ–‡ç« ': 'Blog Article',
    'ä¸ªäººæ—¥è®°': 'Personal Diary',
    'è§‚ç‚¹': 'Opinion',
    'å¹¿å‘Šæ–‡æ¡ˆ': 'Advertising Copy',
    'æŠ€æœ¯æ–‡æ¡£': 'Technical Document',
    'è¯„è®º': 'Review',
    'æ•£æ–‡': 'Essay',
    'ç¤¾äº¤åª’ä½“å¸–å­': 'Social Media Post',
    'è¯—æ­Œ': 'Poetry',
    'å°è¯´ç‰‡æ®µ': 'Fiction Excerpt',
    'æ–°é—»æŠ¥é“': 'News Report',
    'å­¦æœ¯è®ºæ–‡æ‘˜è¦': 'Academic Abstract',
    'AI': 'Artificial Intelligence',
    'åŠ¨ç‰©': 'Animals',
    'æƒ…æ„Ÿ': 'Emotion',
    'å…¬ç›Š': 'Public Welfare',
    'è´­ç‰©': 'Shopping',
    'å¤ä»£æ–‡æ˜': 'Ancient Civilization',
    'äº¤é€š': 'Transportation',
    'æ•™è‚²': 'Education',
    'è¿‘ä»£æˆ˜äº‰': 'Modern War',
    'ç»æµ': 'Economics',
    'ç§‘å¹»': 'Science Fiction',
    'ç§‘æŠ€': 'Technology',
    'ç§‘æ™®': 'Popular Science',
    'å†å²': 'History',
    'æ—…è¡Œ': 'Travel',
    'ç¾é£Ÿ': 'Cuisine',
    'æ¯å©´': 'Mother and Baby',
    'å¥‡å¹»': 'Fantasy',
    'æ°”å€™å˜åŒ–': 'Climate Change',
    'ä¸‰å†œ': 'Agriculture and Rural Affairs',
    'ç¤¾ä¼šé—®é¢˜': 'Social Issues',
    'æ‘„å½±': 'Photography',
    'ç”Ÿæ´»': 'Lifestyle',
    'æ—¶å°š': 'Fashion',
    'æ—¶æ”¿': 'Current Politics',
    'ä½“è‚²': 'Sports',
    'æ–‡åŒ–': 'Culture',
    'æ­¦å™¨': 'Weapons',
    'æ ¡å›­': 'Campus',
    'åŒ»ç–—': 'Medical',
    'è‰ºæœ¯': 'Art',
    'éŸ³ä¹': 'Music',
    'å½±è§†': 'Film and TV',
    'æ¸¸æˆ': 'Gaming',
    'å¨±ä¹': 'Entertainment',
    'è‚²å„¿': 'Parenting',
    'èŒåœº': 'Workplace',
    'æ¤ç‰©': 'Plants',
    'å•†ä¸š': 'Business',
    'æ­£å¼': 'Formal',
    'å™äº‹': 'Narrative',
    'æƒ…æ„ŸåŒ–': 'Emotional',
    'ç§‘æ™®': 'Popular Science'
}

def char_count(text: str) -> int:
    return len(text)

def generate_text(primary, secondary, style, max_retries=3):
    primary_en = category_map.get(primary, primary)
    secondary_en = category_map.get(secondary, secondary)
    style_en = category_map.get(style, style)

    prompt = (
        f'Please write a coherent, well-structured English text with at least 250 characters and preferably no more than 350 characters about the following:\n'
        f'Primary category: {primary_en}\n'
        f'Secondary category: {secondary_en}\n'
        f'Writing style: {style_en}\n'
        f'Important: The entire text must be in English without any Chinese characters or words.'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=900
            )
            text = response.choices[0].message.content.strip()
            char_num = char_count(text)
            if char_num >= 250:
                return text
            else:
                print(f'Retry {attempt} for {primary}-{secondary}-{style}, char count {char_num} < 250')
                time.sleep(1)
        except Exception as e:
            print(f'Error for {primary}-{secondary}-{style}: {e}')
            time.sleep(2)
    print(f'Max retries reached for {primary}-{secondary}-{style}, returning last result')
    return text

def write_to_csv_with_timestamp(base_name, rows, batch_size, output_dir='D:/data/output'):
    os.makedirs(output_dir, exist_ok=True)
    now_str = datetime.now().strftime('%Y%m%d%H%M')
    filename = f'{base_name}_{now_str}_{batch_size}.csv'
    full_path = os.path.join(output_dir, filename)
    with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch of {len(rows)} records to {full_path}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    buffer = []
    base_name = 'generated_texts'
    output_dir = r'C:\test'  # ä½ éœ€è¦çš„è¾“å‡ºç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                char_num = char_count(content)
                print(f'Content ({char_num} chars):\n')
                print(content)
                print('\n' + '='*80 + '\n')

                buffer.append([task_counter, primary, secondary, style, content, char_num])

                if len(buffer) >= batch_size:
                    write_to_csv_with_timestamp(base_name, buffer, batch_size, output_dir=output_dir)
                    buffer.clear()

                time.sleep(1)  # é™æµé˜²å°ç¦

    if buffer:
        write_to_csv_with_timestamp(base_name, buffer, len(buffer), output_dir=output_dir)

    print('All done!')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[354/2028] Generating: ä¸ªäººæ—¥è®° - ç§‘å¹» - å™äº‹
Generated chars: 400
Full content:
October 12, 2147

Today, I stumbled upon an ancient device in the ruins of an old libraryâ€”an old smartphone. Its screen flickered to life, revealing images of a world long gone. I felt a surge of nostalgia for a time when humans thrived on connection, not just data. As I scrolled through its apps, I wondered what stories lay hidden in its memory, waiting to bridge the gap between past and present.
```

## DeepSeek
- [https://platform.deepseek.com/api_keys](https://platform.deepseek.com/api_keys)
### è¿è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ›¿æ¢æˆ DeepSeek çš„ base_url å’Œ api_key
client = OpenAI(
    api_key='sk-x',  # è¿™é‡Œæ¢æˆä½ åœ¨ DeepSeek ç”³è¯·çš„ API Key
    base_url='https://api.deepseek.com'    # DeepSeek API åœ°å€ï¼Œå¸¦/v1ä¹Ÿå¯ä»¥
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

def generate_text(primary: str, secondary: str, style: str, max_retries=3) -> str:
    prompt = (
        f'Please write an English text about the following topic.\n'
        f'The text must be coherent and well-structured,\n'
        f'with at least 200 characters. Avoid making the text too long.\n\n'
        f'Primary category: {primary}\n'
        f'Secondary category: {secondary}\n'
        f'Writing style: {style}'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='deepseek-chat',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=500  # å…è®¸ç¨é•¿æ–‡æœ¬ï¼Œæ¨¡å‹è‡ªåŠ¨æ§åˆ¶é•¿åº¦
            )
            text = response.choices[0].message.content.strip()
            length = len(text)
            if length >= 200:
                return text.replace('\n', ' ')
            else:
                print(f'Retry {attempt} for {primary} - {secondary} - {style}: char count {length} < 200')
                time.sleep(1)
        except Exception as e:
            print(f'Error on {primary} - {secondary} - {style}: {e}')
            time.sleep(2)

    print(f'Max retries reached for {primary} - {secondary} - {style}. Returning last result.')
    if text:
        return text.replace('\n', ' ')
    return ''

def save_batch_to_csv(rows, batch_num, base_name='deepseek_output', output_dir='output'):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    filename = f'{base_name}_{timestamp}_batch{batch_num}.csv'
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch {batch_num} with {len(rows)} records to {filepath}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    batch_data = []
    batch_number = 1
    base_name = 'deepseek_output'
    output_dir = r'c:\test'  # ä¿®æ”¹æˆä½ æƒ³ä¿å­˜çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f'Content ({length} characters):\n')
                print(content)
                print('\n' + '='*100 + '\n')

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) >= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name, output_dir)
                    batch_data.clear()
                    batch_number += 1

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name, output_dir)

    print('All tasks completed.')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[15/2028] Generating: æ¡ˆä»¶æ¡ˆä¾‹ - å…¬ç›Š - æƒ…æ„ŸåŒ–

Content (827 characters):

**A Beacon of Hope: The Power of Compassion in Legal Cases**    In the midst of cold courtrooms and rigid laws, some cases shine as reminders of humanityâ€™s warmth. Take the story of an elderly woman evicted unfairlyâ€”her plight moved strangers to crowdfund her legal fees. Or the pro bono lawyers who fought for a childâ€™s right to education against all odds. These stories arenâ€™t just about justice; theyâ€™re about hearts uniting to lift others up.    Every such case whispers a truth: the law is stronger when wrapped in kindness. Behind every docket number is a life, and behind every verdict, a chance to heal. Letâ€™s celebrate these unsung heroesâ€”the donors, volunteers, and advocatesâ€”who turn legal battles into triumphs of empathy. Because justice, when paired with love, doesnâ€™t just winâ€”it transforms.    (Characters: 598)
```
## Kimi 

-  [https://platform.moonshot.cn/console/api-keys](https://platform.moonshot.cn/console/api-keys)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# === æ¨¡å‹é€‰æ‹© ===
USE_MODEL = 'moonshot'

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆMoonshot ä¸­æ–‡ï¼‰===
client = OpenAI(
    api_key='sk-xxx',  # â† æ›¿æ¢ä¸ºä½ çš„ API Key
    base_url='https://api.moonshot.cn/v1'
)



model_name = 'kimi-k2-0711-preview'
system_prompt = (
    'ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚">
<meta property="og:title" content="è¯­è¨€æ¨¡å‹-API-æ‰¹é‡ç”Ÿæˆæ–‡æœ¬">
<meta property="og:description" content="æ–‡æœ¬æ¨¡å‹æ‰¹é‡ç”Ÿæˆæ–‡æœ¬æµ‹è¯•

## ChatGPT 

ç¬¬ä¸‰æ–¹ä»£ç†æ¥å£

-  [https://openkey.cloud](https://openkey.cloud/register?aff=22CVF)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key='sk-x',
    base_url='https://openkey.cloud/v1'
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

category_map = {
    'æ¡ˆä»¶æ¡ˆä¾‹': 'Case Study',
    'åšå®¢æ–‡ç« ': 'Blog Article',
    'ä¸ªäººæ—¥è®°': 'Personal Diary',
    'è§‚ç‚¹': 'Opinion',
    'å¹¿å‘Šæ–‡æ¡ˆ': 'Advertising Copy',
    'æŠ€æœ¯æ–‡æ¡£': 'Technical Document',
    'è¯„è®º': 'Review',
    'æ•£æ–‡': 'Essay',
    'ç¤¾äº¤åª’ä½“å¸–å­': 'Social Media Post',
    'è¯—æ­Œ': 'Poetry',
    'å°è¯´ç‰‡æ®µ': 'Fiction Excerpt',
    'æ–°é—»æŠ¥é“': 'News Report',
    'å­¦æœ¯è®ºæ–‡æ‘˜è¦': 'Academic Abstract',
    'AI': 'Artificial Intelligence',
    'åŠ¨ç‰©': 'Animals',
    'æƒ…æ„Ÿ': 'Emotion',
    'å…¬ç›Š': 'Public Welfare',
    'è´­ç‰©': 'Shopping',
    'å¤ä»£æ–‡æ˜': 'Ancient Civilization',
    'äº¤é€š': 'Transportation',
    'æ•™è‚²': 'Education',
    'è¿‘ä»£æˆ˜äº‰': 'Modern War',
    'ç»æµ': 'Economics',
    'ç§‘å¹»': 'Science Fiction',
    'ç§‘æŠ€': 'Technology',
    'ç§‘æ™®': 'Popular Science',
    'å†å²': 'History',
    'æ—…è¡Œ': 'Travel',
    'ç¾é£Ÿ': 'Cuisine',
    'æ¯å©´': 'Mother and Baby',
    'å¥‡å¹»': 'Fantasy',
    'æ°”å€™å˜åŒ–': 'Climate Change',
    'ä¸‰å†œ': 'Agriculture and Rural Affairs',
    'ç¤¾ä¼šé—®é¢˜': 'Social Issues',
    'æ‘„å½±': 'Photography',
    'ç”Ÿæ´»': 'Lifestyle',
    'æ—¶å°š': 'Fashion',
    'æ—¶æ”¿': 'Current Politics',
    'ä½“è‚²': 'Sports',
    'æ–‡åŒ–': 'Culture',
    'æ­¦å™¨': 'Weapons',
    'æ ¡å›­': 'Campus',
    'åŒ»ç–—': 'Medical',
    'è‰ºæœ¯': 'Art',
    'éŸ³ä¹': 'Music',
    'å½±è§†': 'Film and TV',
    'æ¸¸æˆ': 'Gaming',
    'å¨±ä¹': 'Entertainment',
    'è‚²å„¿': 'Parenting',
    'èŒåœº': 'Workplace',
    'æ¤ç‰©': 'Plants',
    'å•†ä¸š': 'Business',
    'æ­£å¼': 'Formal',
    'å™äº‹': 'Narrative',
    'æƒ…æ„ŸåŒ–': 'Emotional',
    'ç§‘æ™®': 'Popular Science'
}

def char_count(text: str) -> int:
    return len(text)

def generate_text(primary, secondary, style, max_retries=3):
    primary_en = category_map.get(primary, primary)
    secondary_en = category_map.get(secondary, secondary)
    style_en = category_map.get(style, style)

    prompt = (
        f'Please write a coherent, well-structured English text with at least 250 characters and preferably no more than 350 characters about the following:\n'
        f'Primary category: {primary_en}\n'
        f'Secondary category: {secondary_en}\n'
        f'Writing style: {style_en}\n'
        f'Important: The entire text must be in English without any Chinese characters or words.'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=900
            )
            text = response.choices[0].message.content.strip()
            char_num = char_count(text)
            if char_num >= 250:
                return text
            else:
                print(f'Retry {attempt} for {primary}-{secondary}-{style}, char count {char_num} < 250')
                time.sleep(1)
        except Exception as e:
            print(f'Error for {primary}-{secondary}-{style}: {e}')
            time.sleep(2)
    print(f'Max retries reached for {primary}-{secondary}-{style}, returning last result')
    return text

def write_to_csv_with_timestamp(base_name, rows, batch_size, output_dir='D:/data/output'):
    os.makedirs(output_dir, exist_ok=True)
    now_str = datetime.now().strftime('%Y%m%d%H%M')
    filename = f'{base_name}_{now_str}_{batch_size}.csv'
    full_path = os.path.join(output_dir, filename)
    with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch of {len(rows)} records to {full_path}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    buffer = []
    base_name = 'generated_texts'
    output_dir = r'C:\test'  # ä½ éœ€è¦çš„è¾“å‡ºç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                char_num = char_count(content)
                print(f'Content ({char_num} chars):\n')
                print(content)
                print('\n' + '='*80 + '\n')

                buffer.append([task_counter, primary, secondary, style, content, char_num])

                if len(buffer) >= batch_size:
                    write_to_csv_with_timestamp(base_name, buffer, batch_size, output_dir=output_dir)
                    buffer.clear()

                time.sleep(1)  # é™æµé˜²å°ç¦

    if buffer:
        write_to_csv_with_timestamp(base_name, buffer, len(buffer), output_dir=output_dir)

    print('All done!')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[354/2028] Generating: ä¸ªäººæ—¥è®° - ç§‘å¹» - å™äº‹
Generated chars: 400
Full content:
October 12, 2147

Today, I stumbled upon an ancient device in the ruins of an old libraryâ€”an old smartphone. Its screen flickered to life, revealing images of a world long gone. I felt a surge of nostalgia for a time when humans thrived on connection, not just data. As I scrolled through its apps, I wondered what stories lay hidden in its memory, waiting to bridge the gap between past and present.
```

## DeepSeek
- [https://platform.deepseek.com/api_keys](https://platform.deepseek.com/api_keys)
### è¿è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ›¿æ¢æˆ DeepSeek çš„ base_url å’Œ api_key
client = OpenAI(
    api_key='sk-x',  # è¿™é‡Œæ¢æˆä½ åœ¨ DeepSeek ç”³è¯·çš„ API Key
    base_url='https://api.deepseek.com'    # DeepSeek API åœ°å€ï¼Œå¸¦/v1ä¹Ÿå¯ä»¥
)

primary_classes = [
    'æ¡ˆä»¶æ¡ˆä¾‹', 'åšå®¢æ–‡ç« ', 'ä¸ªäººæ—¥è®°', 'è§‚ç‚¹', 'å¹¿å‘Šæ–‡æ¡ˆ', 'æŠ€æœ¯æ–‡æ¡£',
    'è¯„è®º', 'æ•£æ–‡', 'ç¤¾äº¤åª’ä½“å¸–å­', 'è¯—æ­Œ', 'å°è¯´ç‰‡æ®µ', 'æ–°é—»æŠ¥é“', 'å­¦æœ¯è®ºæ–‡æ‘˜è¦'
]

secondary_classes = [
    'AI', 'åŠ¨ç‰©', 'æƒ…æ„Ÿ', 'å…¬ç›Š', 'è´­ç‰©', 'å¤ä»£æ–‡æ˜', 'äº¤é€š', 'æ•™è‚²', 'è¿‘ä»£æˆ˜äº‰', 'ç»æµ',
    'ç§‘å¹»', 'ç§‘æŠ€', 'ç§‘æ™®', 'å†å²', 'æ—…è¡Œ', 'ç¾é£Ÿ', 'æ¯å©´', 'å¥‡å¹»', 'æ°”å€™å˜åŒ–', 'ä¸‰å†œ',
    'ç¤¾ä¼šé—®é¢˜', 'æ‘„å½±', 'ç”Ÿæ´»', 'æ—¶å°š', 'æ—¶æ”¿', 'ä½“è‚²', 'æ–‡åŒ–', 'æ­¦å™¨', 'æ ¡å›­', 'åŒ»ç–—',
    'è‰ºæœ¯', 'éŸ³ä¹', 'å½±è§†', 'æ¸¸æˆ', 'å¨±ä¹', 'è‚²å„¿', 'èŒåœº', 'æ¤ç‰©', 'å•†ä¸š'
]

styles = ['æ­£å¼', 'å™äº‹', 'æƒ…æ„ŸåŒ–', 'ç§‘æ™®']

def generate_text(primary: str, secondary: str, style: str, max_retries=3) -> str:
    prompt = (
        f'Please write an English text about the following topic.\n'
        f'The text must be coherent and well-structured,\n'
        f'with at least 200 characters. Avoid making the text too long.\n\n'
        f'Primary category: {primary}\n'
        f'Secondary category: {secondary}\n'
        f'Writing style: {style}'
    )
    text = ''
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model='deepseek-chat',
                messages=[{'role': 'user', 'content': prompt}],
                temperature=0.7,
                max_tokens=500  # å…è®¸ç¨é•¿æ–‡æœ¬ï¼Œæ¨¡å‹è‡ªåŠ¨æ§åˆ¶é•¿åº¦
            )
            text = response.choices[0].message.content.strip()
            length = len(text)
            if length >= 200:
                return text.replace('\n', ' ')
            else:
                print(f'Retry {attempt} for {primary} - {secondary} - {style}: char count {length} < 200')
                time.sleep(1)
        except Exception as e:
            print(f'Error on {primary} - {secondary} - {style}: {e}')
            time.sleep(2)

    print(f'Max retries reached for {primary} - {secondary} - {style}. Returning last result.')
    if text:
        return text.replace('\n', ' ')
    return ''

def save_batch_to_csv(rows, batch_num, base_name='deepseek_output', output_dir='output'):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
    filename = f'{base_name}_{timestamp}_batch{batch_num}.csv'
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['ç¼–å·', 'ä¸€çº§ç±»', 'äºŒçº§ç±»', 'é£æ ¼', 'å†…å®¹', 'å­—ç¬¦æ•°'])
        writer.writerows(rows)
    print(f'Saved batch {batch_num} with {len(rows)} records to {filepath}')

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    batch_data = []
    batch_number = 1
    base_name = 'deepseek_output'
    output_dir = r'c:\test'  # ä¿®æ”¹æˆä½ æƒ³ä¿å­˜çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f'\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n')
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f'Content ({length} characters):\n')
                print(content)
                print('\n' + '='*100 + '\n')

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) >= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name, output_dir)
                    batch_data.clear()
                    batch_number += 1

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name, output_dir)

    print('All tasks completed.')

if __name__ == '__main__':
    main()
```
### è¾“å‡ºç»“æœ
```
[15/2028] Generating: æ¡ˆä»¶æ¡ˆä¾‹ - å…¬ç›Š - æƒ…æ„ŸåŒ–

Content (827 characters):

**A Beacon of Hope: The Power of Compassion in Legal Cases**    In the midst of cold courtrooms and rigid laws, some cases shine as reminders of humanityâ€™s warmth. Take the story of an elderly woman evicted unfairlyâ€”her plight moved strangers to crowdfund her legal fees. Or the pro bono lawyers who fought for a childâ€™s right to education against all odds. These stories arenâ€™t just about justice; theyâ€™re about hearts uniting to lift others up.    Every such case whispers a truth: the law is stronger when wrapped in kindness. Behind every docket number is a life, and behind every verdict, a chance to heal. Letâ€™s celebrate these unsung heroesâ€”the donors, volunteers, and advocatesâ€”who turn legal battles into triumphs of empathy. Because justice, when paired with love, doesnâ€™t just winâ€”it transforms.    (Characters: 598)
```
## Kimi 

-  [https://platform.moonshot.cn/console/api-keys](https://platform.moonshot.cn/console/api-keys)

### æ‰§è¡Œè„šæœ¬
```
from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# === æ¨¡å‹é€‰æ‹© ===
USE_MODEL = 'moonshot'

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆMoonshot ä¸­æ–‡ï¼‰===
client = OpenAI(
    api_key='sk-xxx',  # â† æ›¿æ¢ä¸ºä½ çš„ API Key
    base_url='https://api.moonshot.cn/v1'
)



model_name = 'kimi-k2-0711-preview'
system_prompt = (
    'ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚">
<meta property="og:type" content="article">
<meta property="og:url" content="https://feeday.cn//post/yu-yan-mo-xing--API--pi-liang-sheng-cheng-wen-ben.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>è¯­è¨€æ¨¡å‹-API-æ‰¹é‡ç”Ÿæˆæ–‡æœ¬</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}
.copy-feedback {
    display: none;
    position: absolute;
    top: 10px;
    right: 50px;
    color: var(--color-fg-on-emphasis);
    background-color: var(--color-fg-muted);
    border-radius: 3px;
    padding: 5px 8px;
    font-size: 12px;
}
</style>




<body>
    <div id="header">
<h1 class="postTitle">è¯­è¨€æ¨¡å‹-API-æ‰¹é‡ç”Ÿæˆæ–‡æœ¬</h1>
<div class="title-right">
    <a href="https://feeday.cn/" id="buttonHome" class="btn btn-invisible circle" title="é¦–é¡µ">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/tcq233/feeday/issues/20" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="åˆ‡æ¢ä¸»é¢˜">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><p>æ–‡æœ¬æ¨¡å‹æ‰¹é‡ç”Ÿæˆæ–‡æœ¬æµ‹è¯•</p>
<h2>ChatGPT</h2>
<p>ç¬¬ä¸‰æ–¹ä»£ç†æ¥å£</p>
<ul>
<li><a href="https://openkey.cloud/register?aff=22CVF" rel="nofollow">https://openkey.cloud</a></li>
</ul>
<h3>æ‰§è¡Œè„šæœ¬</h3>
<pre class="notranslate"><code class="notranslate">from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = OpenAI(
    api_key="sk-x",
    base_url="https://openkey.cloud/v1"
)

primary_classes = [
    "æ¡ˆä»¶æ¡ˆä¾‹", "åšå®¢æ–‡ç« ", "ä¸ªäººæ—¥è®°", "è§‚ç‚¹", "å¹¿å‘Šæ–‡æ¡ˆ", "æŠ€æœ¯æ–‡æ¡£",
    "è¯„è®º", "æ•£æ–‡", "ç¤¾äº¤åª’ä½“å¸–å­", "è¯—æ­Œ", "å°è¯´ç‰‡æ®µ", "æ–°é—»æŠ¥é“", "å­¦æœ¯è®ºæ–‡æ‘˜è¦"
]

secondary_classes = [
    "AI", "åŠ¨ç‰©", "æƒ…æ„Ÿ", "å…¬ç›Š", "è´­ç‰©", "å¤ä»£æ–‡æ˜", "äº¤é€š", "æ•™è‚²", "è¿‘ä»£æˆ˜äº‰", "ç»æµ",
    "ç§‘å¹»", "ç§‘æŠ€", "ç§‘æ™®", "å†å²", "æ—…è¡Œ", "ç¾é£Ÿ", "æ¯å©´", "å¥‡å¹»", "æ°”å€™å˜åŒ–", "ä¸‰å†œ",
    "ç¤¾ä¼šé—®é¢˜", "æ‘„å½±", "ç”Ÿæ´»", "æ—¶å°š", "æ—¶æ”¿", "ä½“è‚²", "æ–‡åŒ–", "æ­¦å™¨", "æ ¡å›­", "åŒ»ç–—",
    "è‰ºæœ¯", "éŸ³ä¹", "å½±è§†", "æ¸¸æˆ", "å¨±ä¹", "è‚²å„¿", "èŒåœº", "æ¤ç‰©", "å•†ä¸š"
]

styles = ["æ­£å¼", "å™äº‹", "æƒ…æ„ŸåŒ–", "ç§‘æ™®"]

category_map = {
    "æ¡ˆä»¶æ¡ˆä¾‹": "Case Study",
    "åšå®¢æ–‡ç« ": "Blog Article",
    "ä¸ªäººæ—¥è®°": "Personal Diary",
    "è§‚ç‚¹": "Opinion",
    "å¹¿å‘Šæ–‡æ¡ˆ": "Advertising Copy",
    "æŠ€æœ¯æ–‡æ¡£": "Technical Document",
    "è¯„è®º": "Review",
    "æ•£æ–‡": "Essay",
    "ç¤¾äº¤åª’ä½“å¸–å­": "Social Media Post",
    "è¯—æ­Œ": "Poetry",
    "å°è¯´ç‰‡æ®µ": "Fiction Excerpt",
    "æ–°é—»æŠ¥é“": "News Report",
    "å­¦æœ¯è®ºæ–‡æ‘˜è¦": "Academic Abstract",
    "AI": "Artificial Intelligence",
    "åŠ¨ç‰©": "Animals",
    "æƒ…æ„Ÿ": "Emotion",
    "å…¬ç›Š": "Public Welfare",
    "è´­ç‰©": "Shopping",
    "å¤ä»£æ–‡æ˜": "Ancient Civilization",
    "äº¤é€š": "Transportation",
    "æ•™è‚²": "Education",
    "è¿‘ä»£æˆ˜äº‰": "Modern War",
    "ç»æµ": "Economics",
    "ç§‘å¹»": "Science Fiction",
    "ç§‘æŠ€": "Technology",
    "ç§‘æ™®": "Popular Science",
    "å†å²": "History",
    "æ—…è¡Œ": "Travel",
    "ç¾é£Ÿ": "Cuisine",
    "æ¯å©´": "Mother and Baby",
    "å¥‡å¹»": "Fantasy",
    "æ°”å€™å˜åŒ–": "Climate Change",
    "ä¸‰å†œ": "Agriculture and Rural Affairs",
    "ç¤¾ä¼šé—®é¢˜": "Social Issues",
    "æ‘„å½±": "Photography",
    "ç”Ÿæ´»": "Lifestyle",
    "æ—¶å°š": "Fashion",
    "æ—¶æ”¿": "Current Politics",
    "ä½“è‚²": "Sports",
    "æ–‡åŒ–": "Culture",
    "æ­¦å™¨": "Weapons",
    "æ ¡å›­": "Campus",
    "åŒ»ç–—": "Medical",
    "è‰ºæœ¯": "Art",
    "éŸ³ä¹": "Music",
    "å½±è§†": "Film and TV",
    "æ¸¸æˆ": "Gaming",
    "å¨±ä¹": "Entertainment",
    "è‚²å„¿": "Parenting",
    "èŒåœº": "Workplace",
    "æ¤ç‰©": "Plants",
    "å•†ä¸š": "Business",
    "æ­£å¼": "Formal",
    "å™äº‹": "Narrative",
    "æƒ…æ„ŸåŒ–": "Emotional",
    "ç§‘æ™®": "Popular Science"
}

def char_count(text: str) -&gt; int:
    return len(text)

def generate_text(primary, secondary, style, max_retries=3):
    primary_en = category_map.get(primary, primary)
    secondary_en = category_map.get(secondary, secondary)
    style_en = category_map.get(style, style)

    prompt = (
        f"Please write a coherent, well-structured English text with at least 250 characters and preferably no more than 350 characters about the following:\n"
        f"Primary category: {primary_en}\n"
        f"Secondary category: {secondary_en}\n"
        f"Writing style: {style_en}\n"
        f"Important: The entire text must be in English without any Chinese characters or words."
    )
    text = ""
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=900
            )
            text = response.choices[0].message.content.strip()
            char_num = char_count(text)
            if char_num &gt;= 250:
                return text
            else:
                print(f"Retry {attempt} for {primary}-{secondary}-{style}, char count {char_num} &lt; 250")
                time.sleep(1)
        except Exception as e:
            print(f"Error for {primary}-{secondary}-{style}: {e}")
            time.sleep(2)
    print(f"Max retries reached for {primary}-{secondary}-{style}, returning last result")
    return text

def write_to_csv_with_timestamp(base_name, rows, batch_size, output_dir="D:/data/output"):
    os.makedirs(output_dir, exist_ok=True)
    now_str = datetime.now().strftime("%Y%m%d%H%M")
    filename = f"{base_name}_{now_str}_{batch_size}.csv"
    full_path = os.path.join(output_dir, filename)
    with open(full_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        writer.writerow(["ç¼–å·", "ä¸€çº§ç±»", "äºŒçº§ç±»", "é£æ ¼", "å†…å®¹", "å­—ç¬¦æ•°"])
        writer.writerows(rows)
    print(f"Saved batch of {len(rows)} records to {full_path}")

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    buffer = []
    base_name = "generated_texts"
    output_dir = r"C:\test"  # ä½ éœ€è¦çš„è¾“å‡ºç›®å½•ï¼Œè¯·ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f"\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n")
                content = generate_text(primary, secondary, style)
                char_num = char_count(content)
                print(f"Content ({char_num} chars):\n")
                print(content)
                print("\n" + "="*80 + "\n")

                buffer.append([task_counter, primary, secondary, style, content, char_num])

                if len(buffer) &gt;= batch_size:
                    write_to_csv_with_timestamp(base_name, buffer, batch_size, output_dir=output_dir)
                    buffer.clear()

                time.sleep(1)  # é™æµé˜²å°ç¦

    if buffer:
        write_to_csv_with_timestamp(base_name, buffer, len(buffer), output_dir=output_dir)

    print("All done!")

if __name__ == "__main__":
    main()
</code></pre>
<h3>è¾“å‡ºç»“æœ</h3>
<pre class="notranslate"><code class="notranslate">[354/2028] Generating: ä¸ªäººæ—¥è®° - ç§‘å¹» - å™äº‹
Generated chars: 400
Full content:
October 12, 2147

Today, I stumbled upon an ancient device in the ruins of an old libraryâ€”an old smartphone. Its screen flickered to life, revealing images of a world long gone. I felt a surge of nostalgia for a time when humans thrived on connection, not just data. As I scrolled through its apps, I wondered what stories lay hidden in its memory, waiting to bridge the gap between past and present.
</code></pre>
<h2>DeepSeek</h2>
<ul>
<li><a href="https://platform.deepseek.com/api_keys" rel="nofollow">https://platform.deepseek.com/api_keys</a></li>
</ul>
<h3>è¿è¡Œè„šæœ¬</h3>
<pre class="notranslate"><code class="notranslate">from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ›¿æ¢æˆ DeepSeek çš„ base_url å’Œ api_key
client = OpenAI(
    api_key="sk-x",  # è¿™é‡Œæ¢æˆä½ åœ¨ DeepSeek ç”³è¯·çš„ API Key
    base_url="https://api.deepseek.com"    # DeepSeek API åœ°å€ï¼Œå¸¦/v1ä¹Ÿå¯ä»¥
)

primary_classes = [
    "æ¡ˆä»¶æ¡ˆä¾‹", "åšå®¢æ–‡ç« ", "ä¸ªäººæ—¥è®°", "è§‚ç‚¹", "å¹¿å‘Šæ–‡æ¡ˆ", "æŠ€æœ¯æ–‡æ¡£",
    "è¯„è®º", "æ•£æ–‡", "ç¤¾äº¤åª’ä½“å¸–å­", "è¯—æ­Œ", "å°è¯´ç‰‡æ®µ", "æ–°é—»æŠ¥é“", "å­¦æœ¯è®ºæ–‡æ‘˜è¦"
]

secondary_classes = [
    "AI", "åŠ¨ç‰©", "æƒ…æ„Ÿ", "å…¬ç›Š", "è´­ç‰©", "å¤ä»£æ–‡æ˜", "äº¤é€š", "æ•™è‚²", "è¿‘ä»£æˆ˜äº‰", "ç»æµ",
    "ç§‘å¹»", "ç§‘æŠ€", "ç§‘æ™®", "å†å²", "æ—…è¡Œ", "ç¾é£Ÿ", "æ¯å©´", "å¥‡å¹»", "æ°”å€™å˜åŒ–", "ä¸‰å†œ",
    "ç¤¾ä¼šé—®é¢˜", "æ‘„å½±", "ç”Ÿæ´»", "æ—¶å°š", "æ—¶æ”¿", "ä½“è‚²", "æ–‡åŒ–", "æ­¦å™¨", "æ ¡å›­", "åŒ»ç–—",
    "è‰ºæœ¯", "éŸ³ä¹", "å½±è§†", "æ¸¸æˆ", "å¨±ä¹", "è‚²å„¿", "èŒåœº", "æ¤ç‰©", "å•†ä¸š"
]

styles = ["æ­£å¼", "å™äº‹", "æƒ…æ„ŸåŒ–", "ç§‘æ™®"]

def generate_text(primary: str, secondary: str, style: str, max_retries=3) -&gt; str:
    prompt = (
        f"Please write an English text about the following topic.\n"
        f"The text must be coherent and well-structured,\n"
        f"with at least 200 characters. Avoid making the text too long.\n\n"
        f"Primary category: {primary}\n"
        f"Secondary category: {secondary}\n"
        f"Writing style: {style}"
    )
    text = ""
    for attempt in range(1, max_retries + 1):
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=500  # å…è®¸ç¨é•¿æ–‡æœ¬ï¼Œæ¨¡å‹è‡ªåŠ¨æ§åˆ¶é•¿åº¦
            )
            text = response.choices[0].message.content.strip()
            length = len(text)
            if length &gt;= 200:
                return text.replace('\n', ' ')
            else:
                print(f"Retry {attempt} for {primary} - {secondary} - {style}: char count {length} &lt; 200")
                time.sleep(1)
        except Exception as e:
            print(f"Error on {primary} - {secondary} - {style}: {e}")
            time.sleep(2)

    print(f"Max retries reached for {primary} - {secondary} - {style}. Returning last result.")
    if text:
        return text.replace('\n', ' ')
    return ""

def save_batch_to_csv(rows, batch_num, base_name="deepseek_output", output_dir="output"):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"{base_name}_{timestamp}_batch{batch_num}.csv"
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["ç¼–å·", "ä¸€çº§ç±»", "äºŒçº§ç±»", "é£æ ¼", "å†…å®¹", "å­—ç¬¦æ•°"])
        writer.writerows(rows)
    print(f"Saved batch {batch_num} with {len(rows)} records to {filepath}")

def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)
    task_counter = 0
    batch_size = 5  # ç”Ÿæˆ5æ¡ä¿å­˜æˆè¡¨
    batch_data = []
    batch_number = 1
    base_name = "deepseek_output"
    output_dir = r"c:\test"  # ä¿®æ”¹æˆä½ æƒ³ä¿å­˜çš„è·¯å¾„

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f"\n[{task_counter}/{total_tasks}] Generating: {primary} - {secondary} - {style}\n")
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f"Content ({length} characters):\n")
                print(content)
                print("\n" + "="*100 + "\n")

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) &gt;= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name, output_dir)
                    batch_data.clear()
                    batch_number += 1

                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«è¢«é™æµ

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name, output_dir)

    print("All tasks completed.")

if __name__ == "__main__":
    main()
</code></pre>
<h3>è¾“å‡ºç»“æœ</h3>
<pre class="notranslate"><code class="notranslate">[15/2028] Generating: æ¡ˆä»¶æ¡ˆä¾‹ - å…¬ç›Š - æƒ…æ„ŸåŒ–

Content (827 characters):

**A Beacon of Hope: The Power of Compassion in Legal Cases**    In the midst of cold courtrooms and rigid laws, some cases shine as reminders of humanityâ€™s warmth. Take the story of an elderly woman evicted unfairlyâ€”her plight moved strangers to crowdfund her legal fees. Or the pro bono lawyers who fought for a childâ€™s right to education against all odds. These stories arenâ€™t just about justice; theyâ€™re about hearts uniting to lift others up.    Every such case whispers a truth: the law is stronger when wrapped in kindness. Behind every docket number is a life, and behind every verdict, a chance to heal. Letâ€™s celebrate these unsung heroesâ€”the donors, volunteers, and advocatesâ€”who turn legal battles into triumphs of empathy. Because justice, when paired with love, doesnâ€™t just winâ€”it transforms.    (Characters: 598)
</code></pre>
<h2>Kimi</h2>
<ul>
<li><a href="https://platform.moonshot.cn/console/api-keys" rel="nofollow">https://platform.moonshot.cn/console/api-keys</a></li>
</ul>
<h3>æ‰§è¡Œè„šæœ¬</h3>
<pre class="notranslate"><code class="notranslate">from openai import OpenAI
import time
import csv
import os
from datetime import datetime

# === æ¨¡å‹é€‰æ‹© ===
USE_MODEL = "moonshot"

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆMoonshot ä¸­æ–‡ï¼‰===
client = OpenAI(
    api_key="sk-xxx",  # â† æ›¿æ¢ä¸ºä½ çš„ API Key
    base_url="https://api.moonshot.cn/v1"
)



model_name = "kimi-k2-0711-preview"
system_prompt = (
    "ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ æ“…é•¿ä¸­æ–‡å†…å®¹åˆ›ä½œï¼Œèƒ½å¤Ÿæ ¹æ®ç»™å®šçš„åˆ†ç±»å’Œé£æ ¼ï¼Œ"
    "ç”ŸæˆçœŸå®ã€è¿è´¯ä¸”ç»“æ„è‰¯å¥½çš„ä¸­æ–‡æ–‡æœ¬ï¼Œå†…å®¹ä¸å°‘äº200å­—ã€‚"
)

# === åˆ†ç±»å®šä¹‰ ===
primary_classes = [
    "æ¡ˆä»¶æ¡ˆä¾‹", "åšå®¢æ–‡ç« ", "ä¸ªäººæ—¥è®°", "è§‚ç‚¹", "å¹¿å‘Šæ–‡æ¡ˆ", "æŠ€æœ¯æ–‡æ¡£",
    "è¯„è®º", "æ•£æ–‡", "ç¤¾äº¤åª’ä½“å¸–å­", "è¯—æ­Œ", "å°è¯´ç‰‡æ®µ", "æ–°é—»æŠ¥é“", "å­¦æœ¯è®ºæ–‡æ‘˜è¦"
]

secondary_classes = [
    "AI", "åŠ¨ç‰©", "æƒ…æ„Ÿ", "å…¬ç›Š", "è´­ç‰©", "å¤ä»£æ–‡æ˜", "äº¤é€š", "æ•™è‚²", "è¿‘ä»£æˆ˜äº‰", "ç»æµ",
    "ç§‘å¹»", "ç§‘æŠ€", "ç§‘æ™®", "å†å²", "æ—…è¡Œ", "ç¾é£Ÿ", "æ¯å©´", "å¥‡å¹»", "æ°”å€™å˜åŒ–", "ä¸‰å†œ",
    "ç¤¾ä¼šé—®é¢˜", "æ‘„å½±", "ç”Ÿæ´»", "æ—¶å°š", "æ—¶æ”¿", "ä½“è‚²", "æ–‡åŒ–", "æ­¦å™¨", "æ ¡å›­", "åŒ»ç–—",
    "è‰ºæœ¯", "éŸ³ä¹", "å½±è§†", "æ¸¸æˆ", "å¨±ä¹", "è‚²å„¿", "èŒåœº", "æ¤ç‰©", "å•†ä¸š"
]

styles = ["æ­£å¼", "å™äº‹", "æƒ…æ„ŸåŒ–", "ç§‘æ™®"]

# === å†…å®¹ç”Ÿæˆå‡½æ•° ===
def generate_text(primary: str, secondary: str, style: str, max_retries=3) -&gt; str:
    prompt = (
        f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ï¼Œæ’°å†™ä¸€æ®µç»“æ„æ¸…æ™°ã€é€šé¡ºè¿è´¯çš„ä¸­æ–‡å†…å®¹ã€‚\n"
        f"å†…å®¹é•¿åº¦åº”ä¸å°‘äº200å­—ï¼Œä¸è¦è¿‡é•¿ã€‚\n\n"
        f"ä¸€çº§åˆ†ç±»ï¼š{primary}\n"
        f"äºŒçº§åˆ†ç±»ï¼š{secondary}\n"
        f"å†™ä½œé£æ ¼ï¼š{style}"
    )
    text = ""
    for attempt in range(1, max_retries + 1):
        try:
            messages = [{"role": "system", "content": system_prompt},
                        {"role": "user", "content": prompt}]

            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                temperature=0.7,
                max_tokens=500,
                timeout=60  # â° é˜²æ­¢é•¿æ—¶é—´å¡ä½
            )
            text = response.choices[0].message.content.strip()
            if len(text) &gt;= 200:
                return text.replace('\n', ' ')
            else:
                print(f"âš ï¸ Retry {attempt}: å†…å®¹å¤ªçŸ­ï¼ˆ{len(text)} å­—ç¬¦ï¼‰")
                time.sleep(1)
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼š{primary}-{secondary}-{style} ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥ï¼š{e}")
            time.sleep(2)

    # æœ€ç»ˆå¤±è´¥å¤„ç†
    fail_msg = "ç”Ÿæˆå¤±è´¥ï¼šå†…å®¹ä¸ºç©º"
    with open("error_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[å¤±è´¥] {primary}-{secondary}-{style}\n")
    return fail_msg

# === ä¿å­˜ CSV ===
def save_batch_to_csv(rows, batch_num, base_name="output", output_dir="output"):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"{base_name}_{timestamp}_batch{batch_num}.csv"
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["ç¼–å·", "ä¸€çº§ç±»", "äºŒçº§ç±»", "é£æ ¼", "å†…å®¹", "å­—ç¬¦æ•°"])
        writer.writerows(rows)
    print(f"âœ… ä¿å­˜ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(rows)} æ¡ â†’ {filepath}")

# === ä¸»å‡½æ•° ===
def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)  # = 2028
    task_counter = 0
    batch_data = []
    batch_size = 52
    batch_number = 1
    output_dir = r"C:\test"  # â† æ›¿æ¢ä¸ºä½ çš„è¾“å‡ºç›®å½•

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f"\n[{task_counter}/{total_tasks}] â³ æ­£åœ¨ç”Ÿæˆï¼š{primary} - {secondary} - {style}")
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f"â†’ å†…å®¹é•¿åº¦: {length} å­—ç¬¦")
                print("å†…å®¹ï¼š")
                print(content)
                print("=" * 100)

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) &gt;= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name="moonshot", output_dir=output_dir)
                    batch_data.clear()
                    batch_number += 1
                time.sleep(1)

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name="moonshot", output_dir=output_dir)

    print("\nğŸ‰ æ‰€æœ‰ 2028 æ¡ä¸­æ–‡å†…å®¹ç”Ÿæˆå®Œæ¯•ï¼")

if __name__ == "__main__":
    main()
</code></pre>
<h3>è¾“å‡ºç»“æœ</h3>
<pre class="notranslate"><code class="notranslate">[37/2028] â³ æ­£åœ¨ç”Ÿæˆï¼šæ¡ˆä»¶æ¡ˆä¾‹ - ç»æµ - æ­£å¼
â†’ å†…å®¹é•¿åº¦: 534 å­—ç¬¦
å†…å®¹ï¼š
æ¡ˆä¾‹åç§°ï¼šé‡‘è¾‰é›†å›¢è´¢åŠ¡é€ å‡æ¡ˆ  æ¡ˆä»¶èƒŒæ™¯ï¼š2022å¹´3æœˆï¼Œç»è¯ç›‘ä¼šç¨½æŸ¥æ€»é˜Ÿç«‹æ¡ˆï¼Œä¸Šå¸‚å…¬å¸é‡‘è¾‰é›†å›¢ï¼ˆä»£ç ï¼š603877ï¼‰è¢«æŒ‡æ§åœ¨2019è‡³2021å¹´é—´ï¼Œé€šè¿‡è™šå¢æµ·å¤–å·¥ç¨‹æ”¶å…¥ã€æå‰ç¡®è®¤æœªå®Œå·¥é¡¹ç›®åˆ©æ¶¦åŠåˆ©ç”¨å…³è”æ–¹å¾ªç¯äº¤æ˜“ç­‰æ–¹å¼ï¼Œç´¯è®¡è™šå¢è¥ä¸šæ”¶å…¥äººæ°‘å¸24.6äº¿å…ƒï¼Œè™šå¢å‡€ åˆ©æ¶¦7.8äº¿å…ƒï¼Œå¯¼è‡´å¹´åº¦æŠ¥å‘Šå­˜åœ¨é‡å¤§è™šå‡è®°è½½ã€‚  è°ƒæŸ¥ä¸å®¡ç†ï¼šè¯ç›‘ä¼šè”åˆè´¢æ”¿éƒ¨ã€å…¬å®‰éƒ¨æˆç«‹ä¸“æ¡ˆç»„ï¼Œè°ƒå–é‡‘è¾‰é›†å›¢åŠå…¶ä¸Šä¸‹æ¸¸ä¼ä¸š çš„ç”µå­è´¦å¥—ã€é“¶è¡Œæµæ°´åŠæµ·è¿æå•ã€‚ç»æ¯”å¯¹ï¼Œå‘ç°å…¶æµ·å¤–é¡¹ç›®å®Œå·¥ç‡è¢«ç³»ç»Ÿç¯¡æ”¹ï¼Œä¸”å¤šå®¶æ³¨å†Œäºè‹±å±ç»´äº¬ç¾¤å²›çš„å£³å…¬å¸ä¸å®é™…æ§åˆ¶äººå­˜åœ¨éšè”½è‚¡æƒå…³ç³»ã€‚2023å¹´1æœˆï¼Œæ¡ˆä»¶ç§»é€ä¸Šæµ·å¸‚äººæ°‘æ£€å¯Ÿé™¢ç¬¬ä¸‰åˆ†é™¢å®¡æŸ¥èµ·è¯‰ã€‚åŒå¹´12æœˆï¼Œä¸Šæµ·å¸‚ç¬¬ä¸‰ä¸­çº§äººæ°‘æ³•é™¢ä»¥è¿è§„æŠ«éœ²é‡è¦ä¿¡æ¯ç½ª ã€æ“çºµè¯åˆ¸å¸‚åœºç½ªä¸¤ç½ªå¹¶ç½šï¼Œåˆ¤å¤„é‡‘è¾‰é›†å›¢ç½šé‡‘äººæ°‘å¸3äº¿å…ƒï¼›å¯¹æ—¶ä»»è‘£äº‹é•¿èµµæŸåˆ¤å¤„æœ‰æœŸå¾’åˆ‘ä¸ƒå¹´ï¼Œå¹¶å¤„ç½šé‡‘2000ä¸‡å…ƒï¼›å¯¹è´¢åŠ¡æ€»ç›‘ç­‰ äº”åç›´æ¥è´£ä»»äººå‘˜åˆ†åˆ«åˆ¤å¤„ä¸‰è‡³äº”å¹´ä¸ç­‰æœ‰æœŸå¾’åˆ‘ã€‚  å…¸å‹æ„ä¹‰ï¼šæœ¬æ¡ˆç³»æ³¨å†Œåˆ¶ä¸‹é¦–ä¾‹ä»¥â€œå…¨é“¾æ¡è¯æ®ç©¿é€â€è®¤å®šè´¢åŠ¡é€ å‡çš„æ ‡æ†æ¡ˆä»¶ã€‚åˆ¤å†³ä¹¦é¦–æ¬¡ç¡®è®¤ï¼Œä¸Šå¸‚å…¬å¸é€šè¿‡â€œæµ·å¤–é¡¹ç›®â€è·¨å¢ƒèˆå¼ŠåŒæ ·é€‚ç”¨ã€Šåˆ‘æ³•ã€‹ç¬¬ä¸€ç™¾å…­åä¸€æ¡ï¼Œä¸ºåç»­åŒç±»æ¡ˆä»¶å®¡ç†æä¾›äº†æ˜ç¡®è£åˆ¤æ ‡å‡†ï¼Œå¹¶æ¨åŠ¨è¯ç›‘ä¼šä¿®è®¢ã€Šä¸Šå¸‚å…¬å¸ç°åœºæ£€æŸ¥åŠæ³•ã€‹ï¼Œå¼ºåŒ–äº†å¯¹å¼‚å¸¸å¢ƒå¤–æ”¶å…¥çš„ç›‘ç®¡ã€‚
====================================================================================================
</code></pre>
<h2>è…¾è®¯æ··å…ƒ</h2>
<ul>
<li><a href="https://console.cloud.tencent.com/cam/capi" rel="nofollow">https://console.cloud.tencent.com/cam/capi</a></li>
</ul>
<h3>æ‰§è¡Œè„šæœ¬</h3>
<pre class="notranslate"><code class="notranslate"># -*- coding: utf-8 -*-
import time
import csv
import os
import json
from datetime import datetime
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.hunyuan.v20230901 import hunyuan_client, models

# pip install tencentcloud-sdk-python

# === æ¨¡å‹ &amp; æç¤ºè¯ ===
system_prompt = (
    "ä½ æ˜¯ç”±è…¾è®¯äº‘æ··å…ƒå¤§æ¨¡å‹æä¾›çš„ä¸­æ–‡æ–‡æœ¬ç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿æ’°å†™ç»“æ„æ¸…æ™°ã€çœŸå®ã€è¿è´¯çš„å†…å®¹ï¼Œé£æ ¼å¤šæ ·ï¼Œç¬¦åˆæŒ‡å®šè¯­ä½“è¦æ±‚ã€‚"
)

# === åˆ†ç±»å®šä¹‰ ===
primary_classes = [
    "æ¡ˆä»¶æ¡ˆä¾‹", "åšå®¢æ–‡ç« ", "ä¸ªäººæ—¥è®°", "è§‚ç‚¹", "å¹¿å‘Šæ–‡æ¡ˆ", "æŠ€æœ¯æ–‡æ¡£",
    "è¯„è®º", "æ•£æ–‡", "ç¤¾äº¤åª’ä½“å¸–å­", "è¯—æ­Œ", "å°è¯´ç‰‡æ®µ", "æ–°é—»æŠ¥é“", "å­¦æœ¯è®ºæ–‡æ‘˜è¦"
]

secondary_classes = [
    "AI", "åŠ¨ç‰©", "æƒ…æ„Ÿ", "å…¬ç›Š", "è´­ç‰©", "å¤ä»£æ–‡æ˜", "äº¤é€š", "æ•™è‚²", "è¿‘ä»£æˆ˜äº‰", "ç»æµ",
    "ç§‘å¹»", "ç§‘æŠ€", "ç§‘æ™®", "å†å²", "æ—…è¡Œ", "ç¾é£Ÿ", "æ¯å©´", "å¥‡å¹»", "æ°”å€™å˜åŒ–", "ä¸‰å†œ",
    "ç¤¾ä¼šé—®é¢˜", "æ‘„å½±", "ç”Ÿæ´»", "æ—¶å°š", "æ—¶æ”¿", "ä½“è‚²", "æ–‡åŒ–", "æ­¦å™¨", "æ ¡å›­", "åŒ»ç–—",
    "è‰ºæœ¯", "éŸ³ä¹", "å½±è§†", "æ¸¸æˆ", "å¨±ä¹", "è‚²å„¿", "èŒåœº", "æ¤ç‰©", "å•†ä¸š"
]

styles = ["æ­£å¼", "å™äº‹", "æƒ…æ„ŸåŒ–", "ç§‘æ™®"]

# === åˆå§‹åŒ–è…¾è®¯æ··å…ƒå®¢æˆ·ç«¯ ===
cred = credential.Credential("xxx", "xxx")  # â† æ›¿æ¢ä¸ºä½ çš„å¯†é’¥
httpProfile = HttpProfile()
httpProfile.endpoint = "hunyuan.tencentcloudapi.com"
clientProfile = ClientProfile()
clientProfile.httpProfile = httpProfile
client = hunyuan_client.HunyuanClient(cred, "", clientProfile)

# === å†…å®¹ç”Ÿæˆå‡½æ•° ===
def generate_text(primary: str, secondary: str, style: str, max_retries=3) -&gt; str:
    prompt = (
        f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚æ’°å†™ä¸€æ®µä¸­æ–‡å†…å®¹ï¼Œç»“æ„æ¸…æ™°ã€è¯­ä¹‰è¿è´¯ã€‚\n"
        f"å†…å®¹é•¿åº¦ä¸å°‘äº200å­—ï¼Œé¿å…å†—é•¿ã€‚\n\n"
        f"ä¸€çº§åˆ†ç±»ï¼š{primary}\n"
        f"äºŒçº§åˆ†ç±»ï¼š{secondary}\n"
        f"å†™ä½œé£æ ¼ï¼š{style}"
    )

    for attempt in range(1, max_retries + 1):
        try:
            req = models.ChatCompletionsRequest()
            params = {
                "Model": "hunyuan-turbo",
                "Messages": [
                    {"Role": "system", "Content": system_prompt},
                    {"Role": "user", "Content": prompt}
                ],
                "Temperature": 0.7,
                "TopP": 0.8,
                "MaxTokens": 500
            }
            req.from_json_string(json.dumps(params))
            resp = client.ChatCompletions(req)
            text = resp.Choices[0].Message.Content.strip()
            if len(text) &gt;= 200:
                return text.replace('\n', ' ')
            else:
                print(f"âš ï¸ Retry {attempt}: å†…å®¹å¤ªçŸ­ï¼ˆ{len(text)} å­—ç¬¦ï¼‰")
                time.sleep(1)
        except Exception as e:
            print(f"âŒ é”™è¯¯ï¼š{primary}-{secondary}-{style} ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥ï¼š{e}")
            time.sleep(2)

    with open("error_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[å¤±è´¥] {primary}-{secondary}-{style}\n")
    return "ç”Ÿæˆå¤±è´¥ï¼šå†…å®¹ä¸ºç©º"

# === ä¿å­˜ CSV ===
def save_batch_to_csv(rows, batch_num, base_name="output", output_dir="output"):
    os.makedirs(output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    filename = f"{base_name}_{timestamp}_batch{batch_num}.csv"
    filepath = os.path.join(output_dir, filename)
    with open(filepath, mode='w', encoding='utf-8-sig', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["ç¼–å·", "ä¸€çº§ç±»", "äºŒçº§ç±»", "é£æ ¼", "å†…å®¹", "å­—ç¬¦æ•°"])
        writer.writerows(rows)
    print(f"âœ… ä¿å­˜ç¬¬ {batch_num} æ‰¹ï¼Œå…± {len(rows)} æ¡ â†’ {filepath}")

# === ä¸»å‡½æ•° ===
def main():
    total_tasks = len(primary_classes) * len(secondary_classes) * len(styles)  # = 2028
    task_counter = 0
    batch_data = []
    batch_size = 52
    batch_number = 1
    output_dir = r"C:\test"  # â† æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ä¿å­˜ç›®å½•

    for primary in primary_classes:
        for secondary in secondary_classes:
            for style in styles:
                task_counter += 1
                print(f"\n[{task_counter}/{total_tasks}] â³ æ­£åœ¨ç”Ÿæˆï¼š{primary} - {secondary} - {style}")
                content = generate_text(primary, secondary, style)
                length = len(content)
                print(f"â†’ å†…å®¹é•¿åº¦: {length} å­—ç¬¦")
                print("å†…å®¹ï¼š")
                print(content)
                print("=" * 100)

                batch_data.append([task_counter, primary, secondary, style, content, length])

                if len(batch_data) &gt;= batch_size:
                    save_batch_to_csv(batch_data, batch_number, base_name="hunyuan", output_dir=output_dir)
                    batch_data.clear()
                    batch_number += 1
                time.sleep(1)

    if batch_data:
        save_batch_to_csv(batch_data, batch_number, base_name="hunyuan", output_dir=output_dir)

    print("\nğŸ‰ æ‰€æœ‰ 2028 æ¡ä¸­æ–‡å†…å®¹ç”Ÿæˆå®Œæ¯•ï¼")

if __name__ == "__main__":
    main()

</code></pre>
<h3>è¾“å‡ºç»“æœ</h3>
<pre class="notranslate"><code class="notranslate">[111/2028] â³ æ­£åœ¨ç”Ÿæˆï¼šæ¡ˆä»¶æ¡ˆä¾‹ - æ­¦å™¨ - æƒ…æ„ŸåŒ–
âš ï¸ Retry 1: å†…å®¹å¤ªçŸ­ï¼ˆ177 å­—ç¬¦ï¼‰
â†’ å†…å®¹é•¿åº¦: 413 å­—ç¬¦
å†…å®¹ï¼š
ã€Šè‡´å‘½çš„æ­¦å™¨ã€‹  åœ¨é‚£ä¸ªçœ‹ä¼¼å¹³é™çš„å°é•‡ä¸Šï¼Œå‘ç”Ÿäº†ä¸€ä»¶ä»¤äººç—›å¿ƒç–¾é¦–çš„æ¡ˆä»¶ã€‚å—å®³è€…æ˜¯ä¸€ä½æ— è¾œçš„è·¯äººï¼Œè€Œè¿™ä¸€åˆ‡çš„ç½ªæ¶æºå¤´ï¼Œç«Ÿç„¶æ˜¯ä¸€æŠŠè¢«æ¶æ„ä½¿ç”¨çš„æ­¦å™¨ã€‚  é‚£æ˜¯ä¸€ä¸ªé˜´éœ¾å¯†å¸ƒçš„åˆåï¼Œè¡—é“ä¸Šè¡Œäººå¯¥å¯¥ã€‚çŠ¯ç½ªå«Œç–‘äººä¸çŸ¥ä»ä½•å¤„æå‡ºäº†ä¸€æŠŠå¯’å…‰é—ªé—ªçš„åŒ•é¦–ï¼Œåœ¨æ¯«æ— å¾å…†çš„æƒ…å†µä¸‹ï¼Œå†²å‘äº†ä¸€ä½æ­£åŒ†åŒ†èµ¶è·¯çš„å¥³å£«ã€‚å¥³å£«æƒŠæçš„çœ¼ç¥ä¸­å……æ»¡äº†ç»æœ›ï¼Œå¥¹è¯•å›¾èº²é¿ï¼Œå¯é‚£æŠŠåŒ•é¦–å°±åƒæ¶é­”çš„ç ç‰™ï¼Œæ— æƒ…åœ°åˆºå‘å¥¹ã€‚å‘¨å›´çš„äººéƒ½è¢«è¿™çªå¦‚å…¶æ¥çš„ä¸€å¹•å“å‘†äº†ï¼ŒçŸ­æš‚çš„æƒŠæ„•ä¹‹åï¼Œæ‰æœ‰äººååº”è¿‡æ¥æŠ¥è­¦ã€‚  å½“è­¦å¯Ÿè¿…é€Ÿèµ¶åˆ°ç°åœºæ—¶ï¼Œå—å®³è€…å·²ç»å€’åœ¨è¡€æ³Šä¹‹ä¸­ï¼Œç”Ÿå‘½å‚å±ã€‚é‚£æŠŠå†°å†·çš„åŒ•é¦–ï¼Œæ­¤æ—¶æˆä¸ºäº†ç½ªæ¶çš„è±¡å¾ã€‚å®ƒæœ¬æ˜¯ä¸€ç§é˜²èº«çš„å·¥å…·ï¼Œå´åœ¨åäººçš„æ‰‹ä¸­å˜æˆäº†ä¼¤å®³ä»–äººç”Ÿå‘½ã€ç ´åå®¶åº­å¹¸ç¦çš„å‡¶å™¨ã€‚è¿™èµ·æ¡ˆä»¶è®©æˆ‘ä»¬æ·±åˆ»åœ°æ„è¯†åˆ°ï¼Œæ­¦å™¨çš„å±é™©æ€§ä¸€æ—¦å¤±æ§ï¼Œå°†ä¼šå¸¦æ¥å¤šä¹ˆå·¨å¤§çš„ç¾éš¾ã€‚å®ƒä¸ä»…ä¼¤å®³äº†ä¸€ä¸ªäººçš„èº«ä½“ï¼Œæ›´æ˜¯ç»™æ— æ•°äº²äººçš„å¿ƒä¸­ç•™ä¸‹äº†æ°¸è¿œæ— æ³•ç£¨ç­çš„ä¼¤ç—›ã€‚æˆ‘ä»¬æ¸´æœ›ç¤¾ä¼šçš„å®‰å…¨ä¸å’Œè°ï¼Œå¸Œæœ›è¿™æ ·çš„æ‚²å‰§ä¸å†å› ä¸ºè¢«æ¶æ„ä½¿ç”¨çš„æ­¦å™¨è€Œå‘ç”Ÿã€‚
</code></pre></div>
<div style="font-size:small;margin-top:8px;float:right;">â¤ï¸ è½¬è½½æ–‡ç« è¯·æ³¨æ˜å‡ºå¤„ï¼Œè°¢è°¢ï¼â¤ï¸</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">è¯„è®º</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright Â© <span id="copyrightYear"></span> <a href="https://feeday.cn/">feeday</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="ç½‘ç«™è¿è¡Œ "+diffDay+" å¤©"+" â€¢ ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z', 'copy': 'M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z', 'check': 'M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.disabled=true;
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","tcq233/feeday");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    const createClipboardHTML = (codeContent, additionalClasses = '') => `
        <pre class="notranslate"><code class="notranslate">${codeContent}</code></pre>
        <div class="clipboard-container position-absolute right-0 top-0 ${additionalClasses}">
            <clipboard-copy class="ClipboardButton btn m-2 p-0" role="button" style="display: inherit;">
                <svg height="16" width="16" class="octicon octicon-copy m-2"><path d="${IconList["copy"]}"></path></svg>
                <svg height="16" width="16" class="octicon octicon-check color-fg-success m-2 d-none"><path d="${IconList["check"]}"></path></svg>
            </clipboard-copy>
            <div class="copy-feedback">Copied!</div>
        </div>
    `;

    const handleCodeElements = (selector = '') => {
        document.querySelectorAll(selector).forEach(codeElement => {
            const codeContent = codeElement.innerHTML;
            const newStructure = document.createElement('div');
            newStructure.className = 'snippet-clipboard-content position-relative overflow-auto';
            newStructure.innerHTML = createClipboardHTML(codeContent);

            const parentElement = codeElement.parentElement;
            if (selector.includes('highlight')) {
                parentElement.insertBefore(newStructure, codeElement.nextSibling);
                parentElement.removeChild(codeElement);
            } else {
                parentElement.parentElement.replaceChild(newStructure, parentElement);
            }
        });
    };

    handleCodeElements('pre.notranslate > code.notranslate');
    handleCodeElements('div.highlight > pre.notranslate');

    let currentFeedback = null;
    document.querySelectorAll('clipboard-copy').forEach(copyButton => {
        copyButton.addEventListener('click', () => {
            const codeContent = copyButton.closest('.snippet-clipboard-content').innerText;
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = codeContent;
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            document.execCommand('copy');
            document.body.removeChild(tempTextArea);

            const copyIcon = copyButton.querySelector('.octicon-copy');
            const checkIcon = copyButton.querySelector('.octicon-check');
            const copyFeedback = copyButton.nextElementSibling;

            if (currentFeedback && currentFeedback !== copyFeedback) {currentFeedback.style.display = 'none';}
            currentFeedback = copyFeedback;

            copyIcon.classList.add('d-none');
            checkIcon.classList.remove('d-none');
            copyFeedback.style.display = 'block';
            copyButton.style.borderColor = 'var(--color-success-fg)';

            setTimeout(() => {
                copyIcon.classList.remove('d-none');
                checkIcon.classList.add('d-none');
                copyFeedback.style.display = 'none';
                copyButton.style.borderColor = '';
            }, 2000);
        });
    });
});

</script>
<script src='/gmeek/GmeekTOC.js'></script>

</html>
